ctk_11_1: &ctk_11_1 '11.1'
ctk_11_8: &ctk_11_8 '11.8'
ctk_12_0: &ctk_12_0 '12.0'
ctk_curr: &ctk_curr '12.4'

# Needed until cudacxx refactors into string:
llvm-newest: &llvm-newest { name: 'llvm', version: '17', exe: 'clang++' }

# GHA Workflow job matrices:
workflows:
  # If any jobs appear here, they will be executed instead of `pull_request' for PRs.
  # This is useful for limiting resource usage when a full matrix is not needed.
  # The branch protection checks will fail when using this override workflow.
  #
  # Example:
  # override:
  #   - {jobs: ['build'], project: 'thrust', std: 17, ctk: *ctk_curr, cxx: [*gcc12, *llvm16]}
  #
  override:

  pull_request:
    # Old CTK
    - {jobs: ['build'], std: 'all', ctk: *ctk_11_1, cxx: ['gcc6', 'gcc7', 'gcc8', 'gcc9', 'clang9', 'msvc2017']}
    - {jobs: ['build'], std: 'all', ctk: *ctk_11_8, cxx: ['gcc11'], sm: '60;70;80;90'}
    # Current CTK
    - {jobs: ['build'], std: 'all', cxx: ['gcc7', 'gcc8', 'gcc9', 'gcc10', 'gcc11', 'gcc12']}
    - {jobs: ['build'], std: 'all', cxx: ['clang9', 'clang10', 'clang11', 'clang12', 'clang13', 'clang14', 'clang15', 'clang16']}
    - {jobs: ['build'], std: 'all', cxx: ['intel', 'msvc2019']}
    - {jobs: ['test'],  std: 'all', cxx: ['gcc13', 'clang17', 'msvc2022']}
    # Modded builds:
    - {jobs: ['build'], std: 'all', cxx: ['gcc', 'clang'], cpu: 'arm64'}
    - {jobs: ['build'], std: 'all', cxx: ['gcc'], sm: '90a'}
    # default_projects: clang-cuda
    - {jobs: ['build'], std: [17, 20], cudacxx: *llvm-newest, cxx: 'clang'}
    # nvrtc:
    - {jobs: ['nvrtc'], project: 'libcudacxx', std: 'all'}
    # verify-codegen:
    - {jobs: ['verify_codegen'], project: 'libcudacxx'}
    # cudax has different CTK reqs:
    # - {jobs: ['build'], project: 'cudax', ctk: [*ctk_12_0, *ctk_curr], std: 'all', cxx: ['gcc9', 'gcc10, 'gcc11']}
    # - {jobs: ['build'], project: 'cudax', ctk: [*ctk_12_0, *ctk_curr], std: 'all', cxx: ['clang9, 'clang10', 'clang11', 'clang12', 'clang13', 'clang14']}
    # - {jobs: ['build'], project: 'cudax', ctk: [           *ctk_curr], std: 'all', cxx: ['clang15']}
    # - {jobs: ['build'], project: 'cudax', ctk: [*ctk_12_0,          ], std: 'all', cxx: ['msvc2022_1436']}
    # - {jobs: ['build'], project: 'cudax', ctk: [           *ctk_curr], std: 'all', cxx: ['msvc2022']}
    # - {jobs: ['build'], project: 'cudax', ctk: [*ctk_12_0           ], std: 17,    cxx: ['gcc12'], sm: "90"}
    # - {jobs: ['build'], project: 'cudax', ctk: [           *ctk_curr], std: 17,    cxx: ['gcc12'], sm: "90a"}
    # - {jobs: ['build'], project: 'cudax', ctk: [           *ctk_curr], std: 'all', cxx: ['gcc12', 'clang16'], cpu: 'arm64'}
    # - {jobs: ['build'], project: 'cudax', ctk: [           *ctk_curr], std: 17,    cxx: ['intel']}
    # - {jobs: ['test'],  project: 'cudax', ctk: [*ctk_12_0, *ctk_curr], std: 'all', cxx: ['gcc12']}
    # - {jobs: ['test'],  project: 'cudax', ctk: [*ctk_12_0           ], std: 'all', cxx: ['clang14']}
    # - {jobs: ['test'],  project: 'cudax', ctk: [           *ctk_curr], std: 'all', cxx: ['clang16']}
    # cccl-infra:
    - {jobs: ['infra'], project: 'cccl', ctk: *ctk_11_1, cxx: ['gcc6', 'clang9']}
    - {jobs: ['infra'], project: 'cccl', ctk: *ctk_curr, cxx: ['gcc', 'clang']}
  nightly:
  # libcudacxx build fails, CUB tests fail:
    - {jobs: ['build'], ctk: *ctk_11_1, gpu: 'v100',     sm: 'gpu', cxx: 'gcc6',   std: [11],     project: ['cub']}
    - {jobs: ['test'],  ctk: *ctk_11_1, gpu: 'v100',     sm: 'gpu', cxx: 'gcc6',   std: [11],     project: ['thrust']}
  # - {jobs: ['test'],  ctk: *ctk_11_1, gpu: 'v100',     sm: 'gpu', cxx: 'gcc6',   std: [11]      }

  # libcudacxx build fails, CUB tests fail:
    - {jobs: ['build'], ctk: *ctk_11_1, gpu: 't4',       sm: 'gpu', cxx: 'clang9',  std: [17],     project: ['cub']}
    - {jobs: ['test'],  ctk: *ctk_11_1, gpu: 't4',       sm: 'gpu', cxx: 'clang9',  std: [17],     project: ['thrust']}
  # - {jobs: ['test'],  ctk: *ctk_11_1, gpu: 't4',       sm: 'gpu', cxx: 'clang9',  std: [17]      }

  # CUB + libcudacxx tests fails:
    - {jobs: ['build'], ctk: *ctk_11_8, gpu: 'rtx2080',  sm: 'gpu', cxx: 'gcc11',  std: [17],     project: ['libcudacxx', 'cub']}
    - {jobs: ['test'],  ctk: *ctk_11_8, gpu: 'rtx2080',  sm: 'gpu', cxx: 'gcc11',  std: [17],     project: ['thrust']}
  # - {jobs: ['test'],  ctk: *ctk_11_8, gpu: 'rtx2080',  sm: 'gpu', cxx: 'gcc11',  std: [17]      }

  # libcudacxx tests fail:
    - {jobs: ['build'], ctk: *ctk_curr, gpu: 'rtxa6000', sm: 'gpu', cxx: 'gcc7',   std: [14],     project: ['libcudacxx']}
    - {jobs: ['build'], ctk: *ctk_curr, gpu: 'l4',       sm: 'gpu', cxx: 'gcc12',  std: 'all',    project: ['libcudacxx']}
    - {jobs: ['build'], ctk: *ctk_curr, gpu: 'rtx4090',  sm: 'gpu', cxx: 'clang9',  std: [11],     project: ['libcudacxx']}
    - {jobs: ['build'], ctk: *ctk_curr, gpu: 'h100',     sm: 'gpu', cxx: 'gcc12',  std: [11, 20], project: ['libcudacxx']}
    - {jobs: ['build'], ctk: *ctk_curr, gpu: 'h100',     sm: 'gpu', cxx: 'clang16', std: [17],     project: ['libcudacxx']}
    - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'rtxa6000', sm: 'gpu', cxx: 'gcc7',   std: [14],     project: ['cub', 'thrust']}
    - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'l4',       sm: 'gpu', cxx: 'gcc12',  std: 'all',    project: ['cub', 'thrust']}
    - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'rtx4090',  sm: 'gpu', cxx: 'clang9',  std: [11],     project: ['cub', 'thrust']}
    - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'h100',     sm: 'gpu', cxx: 'gcc12',  std: [11, 20], project: ['cub', 'thrust']}
    - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'h100',     sm: 'gpu', cxx: 'clang16', std: [17],     project: ['cub', 'thrust']}
   # - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'rtxa6000', sm: 'gpu', cxx: 'gcc7',   std: [14]     }
   # - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'l4',       sm: 'gpu', cxx: 'gcc12',  std: 'all'    }
   # - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'rtx4090',  sm: 'gpu', cxx: 'clang9',  std: [11]     }
   # - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'h100',     sm: 'gpu', cxx: 'gcc12',  std: [11, 20] }
   # - {jobs: ['test'],  ctk: *ctk_curr, gpu: 'h100',     sm: 'gpu', cxx: 'clang16', std: [17]     }

    # nvrtc:
    - {jobs: ['nvrtc'], ctk: *ctk_curr, gpu: 't4',       sm: 'gpu', cxx: 'gcc12',  std: [20],     project: ['libcudacxx']}
    - {jobs: ['nvrtc'], ctk: *ctk_curr, gpu: 'rtxa6000', sm: 'gpu', cxx: 'gcc12',  std: [20],     project: ['libcudacxx']}
    - {jobs: ['nvrtc'], ctk: *ctk_curr, gpu: 'l4',       sm: 'gpu', cxx: 'gcc12',  std: 'all',    project: ['libcudacxx']}
  # Fails on h100:
  # - {jobs: ['nvrtc'], ctk: *ctk_curr, gpu: 'h100',     sm: 'gpu', cxx: 'gcc12',  std: [11, 20], project: ['libcudacxx']}

  # Any generated jobs that match the entries in `exclude` will be removed from the final matrix for all workflows.
  exclude:
    # Ubuntu 18.04 is EOL and we only use it to get access to CTK 11.1 containers for CUDA testing.
    # Disable non-CUDA tests on this platform.
    - {jobs: ['test_cpu'], os: 'ubuntu18.04'}
    # GPU runners are not available on Windows.
    - {jobs: ['test', 'test_gpu', 'test_nolid', 'test_lid0', 'test_lid1', 'test_lid2'], cxx: ['msvc2017', 'msvc2019', 'msvc14.36', 'msvc2022']}

#
# Resources for compute_matrix.py. These can be modified to add new jobs, etc.
#
# Jobs are executed by running scripts:
# - Linux:   'ci/<job>_<project>.sh`
# - Windows: `ci/windows/<job>_<project>.ps1`

# A matrix entry must have the following tag.
required_tags:
  - 'jobs' # A list of job types to run (e.g. 'build', 'test', 'nvrtc', 'infra', 'verify_codegen', ...) for
           # the specified configuration(s).

# If a matrix entry omits these tags, a default value (defined later in `default_<tag>`) is used.
defaulted_tags:
 - 'ctk'             # CUDA ToolKit version. Will be exploded if a list.
 - 'cpu'             # CPU architecture. Will be exploded if a list.
 - 'gpu'             # GPU model. Will be exploded if a list.
 - 'cxx'             # Host compiler {name, version, exe}. Will be exploded if a list.
 - 'cudacxx'         # Device compiler as {name, version, exe} or 'nvcc' to use nvcc from the specified `ctk`.
                     # Will be exploded if a list.
 - 'project'         # Project name (e.g. libcudacxx, cub, thrust, cccl). Will be exploded if a list.

# These tags will only exist if needed:
optional_tags:
  - 'std'             # C++ standard. Passed to script with `-std <std>`. Will be exploded if a list.
                      # If set to 'all', all stds supported by the host/device compiler are used.
  - 'sm'              # `CMAKE_CUDA_ARCHITECTURES` Passed to script with `-arch <sm>`.
                      # Defaults to use the settings in the CMakePresets.json file.
                      # Set to 'gpu' to only target the GPU in the `gpu` tag.
                      # Can pass multiple architectures via "60;70-real;80-virtual"
                      # Will be exploded if a list (e.g. `sm: ['60;70;80;90', '90a']` creates two jobs)
  - 'cmake_options'   # Additional CMake options to pass to the build. Passed to script with `-cmake_options "<cmake_options>"`.
                      # Will be exploded if a list.

# `default_<tag>`: Used when the tag is omitted.
default_ctk: *ctk_curr
default_cudacxx: 'nvcc'
default_cxx: 'gcc'
default_cpu: 'amd64'
default_gpu: 'v100'
default_project:
  - 'libcudacxx'
  - 'cub'
  - 'thrust'

# Lookup supported C++ standards for a given compiler when `std: 'all'`.
lookup_cudacxx_supported_stds:
  'nvcc11.1':       [11, 14, 17    ]
  'nvcc11.8':       [11, 14, 17    ]
  'nvcc12.0':       [11, 14, 17, 20]
  'nvcc12.4':       [11, 14, 17, 20]
  'llvm16':         [11, 14, 17, 20]
lookup_project_supported_stds:
  'cccl':           [11, 14, 17, 20]
  'libcudacxx':     [11, 14, 17, 20]
  'cub':            [11, 14, 17, 20]
  'thrust':         [11, 14, 17, 20]
  'cudax':          [        17, 20]

# Tags that aren't exploded:
non_exploded_tags:
  - 'jobs' # Keeping jobs as a list allows for dependency handling of build->test steps.

# Jobs that have an implied prerequisite 'build' job:
build_required_jobs:
  - 'test'
  - 'test_gpu'
  - 'test_cpu'
  - 'test_nolid'
  - 'test_lid0'
  - 'test_lid1'
  - 'test_lid2'

# Jobs that require a GPU
gpu_required_jobs:
  - 'test'
  - 'test_gpu'
  - 'test_nolid'
  - 'test_lid0'
  - 'test_lid1'
  - 'test_lid2'
  - 'nvrtc'
  - 'infra' # cccl infra's example project test launches a kernel

# When --skip-tests is given to compute-matrix.py, these jobs are ignored.
skip_test_jobs:
  - 'test'
  - 'test_cpu'
  - 'test_gpu'
  - 'test_nolid'
  - 'test_lid0'
  - 'test_lid1'
  - 'test_lid2'
  - 'nvrtc'
  - 'infra'

# Map the job type to the script invocation spec:
# The script is invoked as `ci/<spec[prefix]>_<project>.sh <spec[args]>`.
# 'prefix' is required. 'args' is optional.
# If a job is not specified explicitly, the default is { 'prefix': '<job>' }.
job_invoke:
  'test_cpu'   : { 'prefix': 'test', 'args': '-cpu-only' }
  'test_gpu'   : { 'prefix': 'test', 'args': '-gpu-only' }
  'test_nolid' : { 'prefix': 'test', 'args': '-no-lid' }
  'test_lid0'  : { 'prefix': 'test', 'args': '-lid0' }
  'test_lid1'  : { 'prefix': 'test', 'args': '-lid1' }
  'test_lid2'  : { 'prefix': 'test', 'args': '-lid2' }

# When a listed project has a `test` job, it will be replaced with the specified list of finer-grain jobs.
project_expanded_tests:
  'thrust' : ['test_gpu', 'test_cpu']
  'cub'    : ['test_nolid', 'test_lid0', 'test_lid1', 'test_lid2']

# Human readable name for jobs. Default behavior is to capitalize the first letter.
formatted_jobs:
  'nvrtc':          'NVRTC'
  'verify_codegen': 'VerifyCodegen'
  'test_cpu':       'TestCPU'
  'test_gpu':       'TestGPU'
  'test_nolid':     'TestGPU'
  'test_lid0':      'HostLaunch'
  'test_lid1':      'DeviceLaunch'
  'test_lid2':      'GraphCapture'

# Human readable name for projects. Default behavior uses the project name as-is.
formatted_project_names:
  'libcudacxx': 'libcu++'
  'cub':        'CUB'
  'thrust':     'Thrust'
  'cccl':       'CCCL'

# All known GPUs
gpus:
  - 'v100'     # 40 runners
  - 't4'       #  8 runners
  - 'rtx2080'  #  8 runners
  - 'rtxa6000' # 12 runners
  - 'l4'       # 48 runners
  - 'rtx4090'  # 10 runners
  - 'h100'     # 16 runners

# SM versions of GPUs
gpu_sm:
  'v100':     '70'
  't4':       '75'
  'rtx2080':  '75'
  'rtxa6000': '86'
  'l4':       '89'
  'rtx4090':  '89'
  'h100':     '90'

# Memory size of GPUs
gpu_mem_gb:
  'v100':     '32'
  't4':       '16'
  'rtx2080':  '8'
  'rtxa6000': '48'
  'l4':       '24'
  'rtx4090':  '24'
  'h100':     '80'

# GPUs that require `-testing` at the end of the runner pool name.
testing_pool_gpus:
  - 't4'
  - 'rtx2080'
  - 'rtxa6000'
  - 'l4'
  - 'rtx4090'

# The version of the devcontainer images to use from https://hub.docker.com/r/rapidsai/devcontainers
devcontainer_version: '24.06'

# All supported C++ standards:
all_stds: [11, 14, 17, 20]

host_compilers:
  gcc:
    name: 'GCC'
    container_tag: 'gcc'
    exe: 'g++'
    versions:
      6:  { stds: [11, 14,       ] }
      7:  { stds: [11, 14, 17,   ] }
      8:  { stds: [11, 14, 17,   ] }
      9:  { stds: [11, 14, 17,   ] }
      10: { stds: [11, 14, 17, 20] }
      11: { stds: [11, 14, 17, 20] }
      12: { stds: [11, 14, 17, 20] }
      13: { stds: [11, 14, 17, 20] }
  clang:
    name: 'Clang'
    container_tag: 'llvm'
    exe: 'clang++'
    versions:
      9:  { stds: [11, 14, 17,   ] }
      10: { stds: [11, 14, 17,   ] }
      11: { stds: [11, 14, 17, 20] }
      12: { stds: [11, 14, 17, 20] }
      13: { stds: [11, 14, 17, 20] }
      14: { stds: [11, 14, 17, 20] }
      15: { stds: [11, 14, 17, 20] }
      16: { stds: [11, 14, 17, 20] }
      17: { stds: [11, 14, 17, 20] }
  msvc:
    name: 'MSVC'
    container_tag: 'cl'
    exe: cl
    versions:
      14.16: { stds: [    14,       ], aka: '2017' }
      14.29: { stds: [    14, 17,   ], aka: '2019' }
      14.36: { stds: [    14, 17, 20]              }
      14.39: { stds: [    14, 17, 20], aka: '2022' }
  intel:
    name: 'Intel'
    container_tag: 'oneapi'
    exe: icpc
    versions:
      2023.2.0: { stds: [11, 14, 17,   ] }

