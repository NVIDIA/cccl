name: "Workflow/Dispatch/Job"

defaults:
  run:
    shell: bash --noprofile --norc -euo pipefail {0}

on:
  workflow_call:
    outputs:
      success:
        value: ${{ contains(toJSON(jobs.*.outputs.success), 'true') }}
    inputs:
      cuda: {type: string, required: true}
      host: {type: string, required: true}
      name: {type: string, required: true}
      image: {type: string, required: true}
      runner: {type: string, required: true}
      command: {type: string, required: true}
      id: {type: string, required: true}
      env: {type: string, required: false}

permissions:
  contents: read

jobs:
  linux:
    name: ${{inputs.name}}
    if: ${{ startsWith(inputs.runner, 'linux') }}
    outputs:
      success: ${{ steps.done.outputs.SUCCESS }}
    permissions:
      id-token: write
      contents: read
    runs-on: ${{inputs.runner}}
    container:
      # This job now uses a docker-outside-of-docker (DOOD) strategy.
      #
      # The GitHub Actions runner application mounts the host's docker socket `/var/run/docker.sock` into the
      # container. By using a container with the `docker` CLI, this container can launch docker containers
      # using the host's docker daemon.
      #
      # This allows us to run actions that require node v20 in the `cruizba/ubuntu-dind:jammy-26.1.3` container, and
      # then launch our Ubuntu18.04-based GCC 6/7 containers to build and test CCCL.
      #
      # The main inconvenience to this approach is that any container mounts have to match the paths of the runner host,
      # not the paths as seen in the intermediate (`cruizba/ubuntu-dind`) container.
      #
      # Note: I am using `cruizba/ubuntu-dind:jammy-26.1.3` instead of `docker:latest`, because GitHub doesn't support
      # JS actions in alpine aarch64 containers, instead failing actions with this error:
      # ```
      # Error: JavaScript Actions in Alpine containers are only supported on x64 Linux runners. Detected Linux Arm64
      # ```
      image: cruizba/ubuntu-dind:jammy-26.1.3
      env:
        NVIDIA_VISIBLE_DEVICES: ${{env.NVIDIA_VISIBLE_DEVICES}}
    steps:
      - name: Install dependencies
        shell: sh
        run: |
          # Install script dependencies
          apt update
          apt install -y --no-install-recommends tree git
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          path: ${{github.event.repository.name}}
          persist-credentials: false
      - name: Add NVCC problem matcher
        run: |
          echo "::add-matcher::${{github.event.repository.name}}/.github/problem-matchers/problem-matcher.json"
      - name: Get AWS credentials for sccache bucket
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::279114543810:role/gha-oidc-NVIDIA
          aws-region: us-east-2
          role-duration-seconds: 43200 # 12 hours)
      - name: Run command # Do not change this step's name, it is checked in parse-job-times.py
        env:
          CI: true
          RUNNER: "${{inputs.runner}}"
          # Dereferencing the command from an env var instead of a GHA input avoids issues with escaping
          # semicolons and other special characters (e.g. `-arch "60;70;80"`).
          COMMAND: "${{inputs.command}}"
          AWS_ACCESS_KEY_ID: "${{env.AWS_ACCESS_KEY_ID}}"
          AWS_SESSION_TOKEN: "${{env.AWS_SESSION_TOKEN}}"
          AWS_SECRET_ACCESS_KEY: "${{env.AWS_SECRET_ACCESS_KEY}}"
        run: |

          echo "[host]      github.workspace: ${{github.workspace}}"
          echo "[container] GITHUB_WORKSPACE: ${GITHUB_WORKSPACE:-}"
          echo "[container]              PWD: $(pwd)"

          # Necessary because we're doing docker-outside-of-docker:
          # Make a symlink in the container that matches the host's ${{github.workspace}}, so that way `$(pwd)`
          # in `.devcontainer/launch.sh` constructs volume paths relative to the hosts's ${{github.workspace}}.
          mkdir -p "$(dirname "${{github.workspace}}")"
          ln -s "$(pwd)" "${{github.workspace}}"
          cd "${{github.workspace}}"

          cat <<"EOF" > ci.sh
          #! /usr/bin/env bash
          set -eo pipefail
          echo -e "\e[1;34mRunning as '$(whoami)' user in $(pwd):\e[0m"
          echo -e "\e[1;34m${COMMAND}\e[0m"
          eval "${COMMAND}" || exit_code=$?
          if [ ! -z "$exit_code" ]; then
            echo -e "::group::️❗ \e[1;31mInstructions to Reproduce CI Failure Locally\e[0m"
            echo "::error:: To replicate this failure locally, follow the steps below:"
            echo "1. Clone the repository, and navigate to the correct branch and commit:"
            echo "   git clone --branch $GITHUB_REF_NAME --single-branch https://github.com/$GITHUB_REPOSITORY.git && cd $(echo $GITHUB_REPOSITORY | cut -d'/' -f2) && git checkout $GITHUB_SHA"
            echo ""
            echo "2. Run the failed command inside the same Docker container used by this CI job:"
            echo "   .devcontainer/launch.sh -d -c ${{inputs.cuda}} -H ${{inputs.host}} -- ${COMMAND}"
            echo ""
            echo "For additional information, see:"
            echo "   - DevContainer Documentation: https://github.com/NVIDIA/cccl/blob/main/.devcontainer/README.md"
            echo "   - Continuous Integration (CI) Overview: https://github.com/NVIDIA/cccl/blob/main/ci-overview.md"
            exit $exit_code
          fi
          EOF

          chmod +x ci.sh

          mkdir "$RUNNER_TEMP/.aws";

          cat <<EOF > "$RUNNER_TEMP/.aws/config"
          [default]
          bucket=rapids-sccache-devs
          region=us-east-2
          EOF

          cat <<EOF > "$RUNNER_TEMP/.aws/credentials"
          [default]
          aws_access_key_id=$AWS_ACCESS_KEY_ID
          aws_session_token=$AWS_SESSION_TOKEN
          aws_secret_access_key=$AWS_SECRET_ACCESS_KEY
          EOF

          chmod 0600 "$RUNNER_TEMP/.aws/credentials"
          chmod 0664 "$RUNNER_TEMP/.aws/config"

          declare -a gpu_request=()

          # Explicitly pass which GPU to use if on a GPU runner
          if [[ "${RUNNER}" = *"-gpu-"* ]]; then
            gpu_request+=(--gpus "device=${NVIDIA_VISIBLE_DEVICES}")
          fi

          host_path() {
            sed "s@/__w@$(dirname "$(dirname "${{github.workspace}}")")@" <<< "$1"
          }

          # Launch this container using the host's docker daemon
          ${{github.event.repository.name}}/.devcontainer/launch.sh \
            --docker \
            --cuda ${{inputs.cuda}} \
            --host ${{inputs.host}} \
            "${gpu_request[@]}" \
            --env "CI=$CI" \
            --env "VAULT_HOST=" \
            --env "COMMAND=$COMMAND" \
            --env "GITHUB_ENV=$GITHUB_ENV" \
            --env "GITHUB_SHA=$GITHUB_SHA" \
            --env "GITHUB_PATH=$GITHUB_PATH" \
            --env "GITHUB_OUTPUT=$GITHUB_OUTPUT" \
            --env "GITHUB_ACTIONS=$GITHUB_ACTIONS" \
            --env "GITHUB_REF_NAME=$GITHUB_REF_NAME" \
            --env "GITHUB_WORKSPACE=$GITHUB_WORKSPACE" \
            --env "GITHUB_REPOSITORY=$GITHUB_REPOSITORY" \
            --env "GITHUB_STEP_SUMMARY=$GITHUB_STEP_SUMMARY" \
            --volume "${{github.workspace}}/ci.sh:/ci.sh" \
            --volume "$(host_path "$RUNNER_TEMP")/.aws:/root/.aws" \
            --volume "$(dirname "$(dirname "${{github.workspace}}")"):/__w" \
            -- /ci.sh

      - name: Prepare job artifacts
        id: done
        run: |
          echo "SUCCESS=true" | tee -a "${GITHUB_OUTPUT}"

          result_dir="jobs/${{inputs.id}}"
          mkdir -p "$result_dir"

          touch "$result_dir/success"

          # Finds a matching file in the repo directory and copies it to the results directory.
          find_and_copy() {
            filename="$1"
            filepath="$(find ${{github.event.repository.name}} -name "${filename}" -print -quit)"
            if [[ -z "$filepath" ]]; then
              echo "${filename} does not exist in repo directory."
              return 1
            fi
            cp -v "$filepath" "$result_dir"
          }

          find_and_copy "sccache_stats.json" || true # Ignore failures

          echo "::group::Job artifacts"
          tree "$result_dir"
          echo "::endgroup::"
      - name: Upload job artifacts
        uses: actions/upload-artifact@v4
        with:
          name: jobs-${{inputs.id}}
          path: jobs
          compression-level: 0


  windows:
    name: ${{inputs.name}}
    if: ${{ startsWith(inputs.runner, 'windows') }}
    outputs:
      success: ${{ steps.done.outputs.SUCCESS }}
    permissions:
      id-token: write
      contents: read
    runs-on: ${{inputs.runner}}
    env:
      SCCACHE_BUCKET: rapids-sccache-devs
      SCCACHE_REGION: us-east-2
      SCCACHE_IDLE_TIMEOUT: 0
      SCCACHE_S3_USE_SSL: true
      SCCACHE_S3_NO_CREDENTIALS: false
    steps:
      - name: Get AWS credentials for sccache bucket
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::279114543810:role/gha-oidc-NVIDIA
          aws-region: us-east-2
          role-duration-seconds: 43200 # 12 hours
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          path: ${{github.event.repository.name}}
          persist-credentials: false
      - name: Fetch ${{ inputs.image }}
        run: docker pull ${{ inputs.image }}
      - name: Prepare paths for docker
        id: paths
        run: |
          echo "HOST_REPO=${{ github.workspace }}\${{ github.event.repository.name }}".Replace('\', '/') | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          echo "MOUNT_REPO=C:/${{ github.event.repository.name }}" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          cat $env:GITHUB_OUTPUT
        shell: powershell
      - name: Run command # Do not change this step's name, it is checked in parse-job-times.py
        run: |
          docker run \
            --mount type=bind,source="${{steps.paths.outputs.HOST_REPO}}",target="${{steps.paths.outputs.MOUNT_REPO}}" \
            --workdir "${{steps.paths.outputs.MOUNT_REPO}}" \
            ${{ inputs.image }} \
            powershell -c "
              [System.Environment]::SetEnvironmentVariable('AWS_ACCESS_KEY_ID','${{env.AWS_ACCESS_KEY_ID}}');
              [System.Environment]::SetEnvironmentVariable('AWS_SECRET_ACCESS_KEY','${{env.AWS_SECRET_ACCESS_KEY}}');
              [System.Environment]::SetEnvironmentVariable('AWS_SESSION_TOKEN','${{env.AWS_SESSION_TOKEN }}');
              [System.Environment]::SetEnvironmentVariable('SCCACHE_BUCKET','${{env.SCCACHE_BUCKET}}');
              [System.Environment]::SetEnvironmentVariable('SCCACHE_REGION','${{env.SCCACHE_REGION}}');
              [System.Environment]::SetEnvironmentVariable('SCCACHE_IDLE_TIMEOUT','${{env.SCCACHE_IDLE_TIMEOUT}}');
              [System.Environment]::SetEnvironmentVariable('SCCACHE_S3_USE_SSL','${{env.SCCACHE_S3_USE_SSL}}');
              [System.Environment]::SetEnvironmentVariable('SCCACHE_S3_NO_CREDENTIALS','${{env.SCCACHE_S3_NO_CREDENTIALS}}');
              git config --global --add safe.directory '${{steps.paths.outputs.MOUNT_REPO}}';
              ${{inputs.command}}"
      - name: Prepare job artifacts
        id: done
        run: |
          echo "SUCCESS=true" | tee -a "${GITHUB_OUTPUT}"

          result_dir="jobs/${{inputs.id}}"
          mkdir -p "$result_dir"

          touch "$result_dir/success"

          # Finds a matching file in the repo directory and copies it to the results directory.
          find_and_copy() {
            filename="$1"
            filepath="$(find ${{github.event.repository.name}} -name "${filename}" -print -quit)"
            if [[ -z "$filepath" ]]; then
              echo "${filename} does not exist in repo directory."
              return 1
            fi
            cp -v "$filepath" "$result_dir"
          }

          find_and_copy "sccache_stats.json" || true # Ignore failures

          echo "::group::Job artifacts"
          find "$result_dir" # Tree not available in this image.
          echo "::endgroup::"

      - name: Upload job artifacts
        uses: actions/upload-artifact@v4
        with:
          name: jobs-${{inputs.id}}
          path: jobs
          compression-level: 0
