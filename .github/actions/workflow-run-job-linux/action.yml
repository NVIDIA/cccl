name: "Run Linux Job"
description: "Run a job on a Linux runner."

inputs:
  id:
    description: "A unique identifier."
    required: true
  command:
    description: "The command to run."
    required: true
  image:
    description: "The Docker image to use."
    required: true
  runner:
    description: "The GHA runs-on value."
    required: true
  cuda:
    description: "The CUDA version to use when selecting a devcontainer."
    required: true
  host:
    description: "The host compiler to use when selecting a devcontainer."
    required: true
  # This token must have the "read:enterprise" scope
  dist-token:
    description: "The token used to authenticate with the sccache-dist build cluster."

runs:
  using: "composite"
  steps:
    - name: Define and log job details
      shell: bash --noprofile --norc -euo pipefail {0}
      env:
        # Dereferencing the command from an env var instead of a GHA input avoids issues with escaping
        # semicolons and other special characters (e.g. `-arch "60;70;80"`).
        COMMAND: "${{inputs.command}}"
      run: |
        echo -e "\e[1;34mMock with: ci/util/create_mock_job_env.sh $GITHUB_RUN_ID ${{inputs.id}}\e[0m"

        echo "::group::Ô∏èüîç Job Inputs"
        # Define the job input parameters as JOB_* environment variables that are visible in all steps:
        echo "JOB_ID=${{inputs.id}}"               | tee -a $GITHUB_ENV
        echo "JOB_RUNNER=${{inputs.runner}}"       | tee -a $GITHUB_ENV
        echo "JOB_IMAGE=${{inputs.image}}"         | tee -a $GITHUB_ENV
        echo "JOB_CUDA=${{inputs.cuda}}"           | tee -a $GITHUB_ENV
        echo "JOB_HOST=${{inputs.host}}"           | tee -a $GITHUB_ENV
        echo
        echo "Job command: ${COMMAND}" # Intentionally not passing to GITUB_ENV, arg handling is fragile.
        echo "::endgroup::"

    - name: Add NVCC problem matcher
      shell: bash --noprofile --norc -euo pipefail {0}
      run: |
        echo "::add-matcher::${{github.workspace}}/.github/problem-matchers/problem-matcher.json"
    - name: Get AWS credentials for sccache bucket
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::279114543810:role/gha-oidc-NVIDIA
        aws-region: us-east-2
        role-duration-seconds: 43200 # 12 hours
    - name: Run command # Do not change this step's name, it is checked in parse-job-times.py
      id: run
      shell: bash --noprofile --norc -euo pipefail {0}
      env:
        GH_TOKEN: ${{ github.token }}
        CI: true
        # Dereferencing the command from an env var instead of a GHA input avoids issues with escaping
        # semicolons and other special characters (e.g. `-arch "60;70;80"`).
        COMMAND: "${{inputs.command}}"
        DIST_TOKEN: "${{inputs.dist-token}}"
        AWS_ACCESS_KEY_ID: "${{env.AWS_ACCESS_KEY_ID}}"
        AWS_SESSION_TOKEN: "${{env.AWS_SESSION_TOKEN}}"
        AWS_SECRET_ACCESS_KEY: "${{env.AWS_SECRET_ACCESS_KEY}}"
      run: |
        cat <<'EOF' > ci.sh
        #! /usr/bin/env bash

        set -euo pipefail

        ulimit -n $(ulimit -Hn)
        sccache --stop-server >/dev/null 2>&1
        echo -e "\e[1;34mRunning as '$(whoami)' user in $(pwd):\e[0m"
        # Print current dist status to verify we're connected
        echo -e "::group::Ô∏è‚öôÔ∏è \e[1;34mBuild cluster status:\e[0m"
        ./ci/sccache_dist_status.sh | sed 's/\"//g' | column -t -s,
        echo -e "::endgroup::"
        echo -e "\e[1;34mMock with: ci/util/create_mock_job_env.sh $GITHUB_RUN_ID $JOB_ID\e[0m"
        echo -e "\e[1;34m${COMMAND}\e[0m"
        exit_code=0
        eval "${COMMAND}" || exit_code=$?
        if [[ "$exit_code" -ne 0 ]]; then
          echo -e "::group::Ô∏è‚ùó \e[1;31mInstructions to Reproduce CI Failure Locally\e[0m"
          echo "::error:: To replicate this failure locally, follow the steps below:"
          echo "1. Clone the repository, and navigate to the correct branch and commit:"
          echo "   git clone --branch $GITHUB_REF_NAME --single-branch https://github.com/$GITHUB_REPOSITORY.git && cd $(echo $GITHUB_REPOSITORY | cut -d'/' -f2) && git checkout $GITHUB_SHA"
          echo ""
          echo "2. Run the failed command inside the same Docker container used by this CI job:"
          echo "   .devcontainer/launch.sh -d -c ${{inputs.cuda}} -H ${{inputs.host}} -- ${COMMAND}"
          echo ""
          echo "For additional information, see:"
          echo "   - DevContainer Documentation: https://github.com/NVIDIA/cccl/blob/main/.devcontainer/README.md"
          echo "   - Continuous Integration (CI) Overview: https://github.com/NVIDIA/cccl/blob/main/ci-overview.md"
          echo -e "::endgroup::"
        fi

        ci/upload_job_result_artifacts.sh "${{inputs.id}}" $exit_code > /dev/null

        exit $exit_code
        EOF

        chmod +x ci.sh

        # The devcontainer will mount this path to the home directory:
        readonly aws_dir="${{github.workspace}}/.aws"
        readonly cfg_dir="${{github.workspace}}/.config"
        mkdir -p "${aws_dir}" "${cfg_dir}/sccache";

        cat <<EOF > "${aws_dir}/config"
        [default]
        bucket=rapids-sccache-devs
        region=us-east-2
        EOF

        cat <<EOF > "${aws_dir}/credentials"
        [default]
        aws_access_key_id=$AWS_ACCESS_KEY_ID
        aws_session_token=$AWS_SESSION_TOKEN
        aws_secret_access_key=$AWS_SECRET_ACCESS_KEY
        EOF

        # Configure the sccache client
        cat <<EOF > "${cfg_dir}/sccache/config"
        server_startup_timeout_ms = $((5 * 60 * 1000))
        [cache.disk]
        size = 0
        [cache.disk.preprocessor_cache_mode]
        use_preprocessor_cache_mode = false
        EOF

        chmod 0600 "${aws_dir}/credentials"
        chmod 0664 "${aws_dir}/config"
        chmod 0664 "${cfg_dir}/sccache/config"

        # Download new sccache binary
        mkdir -p "${{runner.temp}}/bin"
        curl -fsSL \
          "https://github.com/rapidsai/sccache/releases/download/v0.10.0-rapids.52/sccache-v0.10.0-rapids.52-$(uname -m)-unknown-linux-musl.tar.gz" \
        | tar -C "${{runner.temp}}/bin" -zf - --wildcards --strip-components=1 -x '*/sccache'

        declare -a extra_launch_args=(
          # Write debug logs to a file we can upload
          --env "SCCACHE_SERVER_LOG=sccache=debug"
          --env "SCCACHE_ERROR_LOG=/home/coder/cccl/sccache.log"
          # Cache in a separate S3 bucket prefix
          --env "SCCACHE_S3_KEY_PREFIX=cccl-test-sccache-dist"
          # Mount in new sccache binary
          --volume "${{runner.temp}}/bin/sccache:/usr/bin/sccache:ro"
        )

        OS="$(uname -s)"
        CPUS="$(nproc --all)"
        ARCH="$(dpkg --print-architecture)"

        # Use the build cluster
        if test -n "${DIST_TOKEN+x}"; then

          # Configure sccache client to talk to the build cluster
          cat <<EOF >> "${cfg_dir}/sccache/config"
        [dist]
        # Infinitely retry all retryable dist-compilation errors
        max_retries = inf
        # Never fallback to building locally, fail instead
        fallback_to_local_compile = false
        # Build cluster URL
        scheduler_url = "https://${ARCH}.${OS,,}.sccache.rapids.nvidia.com"

        # Build cluster auth
        [dist.auth]
        type = "token"
        token = "$DIST_TOKEN"

        # Build cluster network config
        [dist.net]
        connect_timeout = 30
        request_timeout = 4000

        [dist.net.keepalive]
        enabled = true
        interval = 20
        timeout = 600
        EOF

          if grep -q '"./ci/build_' <<< "$COMMAND"; then
            extra_launch_args+=(
              # Repopulate the cache
              # --env "SCCACHE_RECACHE=1"
              # Do not cache build products
              # --env "SCCACHE_NO_CACHE=1"
            )
          fi

          # Over-subscribe -j to keep the build cluster busy if _not_ ClangCUDA.
          # ClangCUDA can use the build cluster for C++ files, but _not_ CUDA,
          # and we'll OOM if we try to compile too many at once.
          if ! grep -q '\-cuda "clang' <<< "$COMMAND"; then
            if ! grep -q '_python.sh' <<< "$COMMAND"; then
              extra_launch_args+=(
                --env "PARALLEL_LEVEL=$((CPUS < 32 ? 32 : CPUS))"
                --ulimit "nofile=$(ulimit -Hn):$(ulimit -Hn)"
              )
            else
              extra_launch_args+=(
                --env "PARALLEL_LEVEL=${CPUS}"
              )
            fi
          fi

          if ! grep -q '11.1' <<< "${{inputs.cuda}}"; then
            # Compile device objects in parallel
            extra_launch_args+=(
              --env "NVCC_APPEND_FLAGS=-t=100"
            )
          fi
        fi

        # Explicitly pass which GPU to use if on a GPU runner
        if [[ "${JOB_RUNNER}" = *"-gpu-"* ]]; then
          extra_launch_args+=(--gpus "device=${NVIDIA_VISIBLE_DEVICES}")
        fi

        # If the image contains "cudaXX.Yext"...
        if [[ "${JOB_IMAGE}" =~ cuda[0-9.]+ext ]]; then
          extra_launch_args+=(--cuda-ext)
        fi

        # Initialize artifact paths, vars, etc shared with the devcontainer:
        source ci/util/artifacts/common.sh
        source ci/util/workflow/common.sh

        # Launch this container using the host's docker daemon
        ( # Subshell to contain the set -x log
          set -x
          .devcontainer/launch.sh \
            --docker \
            --cuda $JOB_CUDA \
            --host $JOB_HOST \
            "${extra_launch_args[@]}" \
            --env "AWS_ROLE_ARN=" \
            --env "CI=$CI" \
            --env "COMMAND=$COMMAND" \
            --env "SCCACHE_IDLE_TIMEOUT=0" \
            --env "GITHUB_ENV=$GITHUB_ENV" \
            --env "GITHUB_SHA=$GITHUB_SHA" \
            --env "GITHUB_PATH=$GITHUB_PATH" \
            --env "GITHUB_OUTPUT=$GITHUB_OUTPUT" \
            --env "GITHUB_ACTIONS=$GITHUB_ACTIONS" \
            --env "GITHUB_REF_NAME=$GITHUB_REF_NAME" \
            --env "GITHUB_RUN_ID=$GITHUB_RUN_ID" \
            --env "GITHUB_WORKSPACE=$GITHUB_WORKSPACE" \
            --env "GITHUB_REPOSITORY=$GITHUB_REPOSITORY" \
            --env "GITHUB_STEP_SUMMARY=$GITHUB_STEP_SUMMARY" \
            --env "GH_TOKEN=${{ github.token }}" \
            --env "HOST_WORKSPACE=${{github.workspace}}" \
            --env "NVIDIA_VISIBLE_DEVICES=$NVIDIA_VISIBLE_DEVICES" \
            --env "JOB_ID=$JOB_ID" \
            --volume "${ARTIFACT_ARCHIVES}:${ARTIFACT_ARCHIVES}" \
            --volume "${ARTIFACT_UPLOAD_STAGE}:${ARTIFACT_UPLOAD_STAGE}" \
            --volume "${WORKFLOW_DIR}:${WORKFLOW_DIR}" \
            -- ./ci.sh
        )

        # Dump artifact matrix for upload step:
        printf "ARTIFACTS=%s\n" "$(ci/util/artifacts/upload/print_matrix.sh)" >> "${GITHUB_OUTPUT}"

    - name: Upload job artifacts
      if: ${{ always() && steps.run.outputs.ARTIFACTS != '' && fromJson(steps.run.outputs.ARTIFACTS)[0] != null }}
      uses: ./.github/actions/upload-artifacts
      with:
        artifacts: ${{ steps.run.outputs.ARTIFACTS }}
