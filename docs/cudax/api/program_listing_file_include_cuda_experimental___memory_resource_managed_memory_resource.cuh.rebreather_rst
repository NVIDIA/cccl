include\/cuda\/experimental\/\_\_memory\_resource\/managed\_memory\_resource.cuh
================================================================================

File members: :ref:`include\/cuda\/experimental\/\_\_memory\_resource\/managed\_memory\_resource.cuh <managed__memory__resource_8cuh>`

.. code-block:: c++

   //===----------------------------------------------------------------------===//
   //
   // Part of CUDA Experimental in CUDA C++ Core Libraries,
   // under the Apache License v2.0 with LLVM Exceptions.
   // See https://llvm.org/LICENSE.txt for license information.
   // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
   // SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES.
   //
   //===----------------------------------------------------------------------===//

   #ifndef _CUDAX__MEMORY_RESOURCE_MANAGED_MEMORY_RESOURCE_CUH
   #define _CUDAX__MEMORY_RESOURCE_MANAGED_MEMORY_RESOURCE_CUH

   #include <cuda/std/detail/__config>

   #if defined(_CCCL_IMPLICIT_SYSTEM_HEADER_GCC)
   #  pragma GCC system_header
   #elif defined(_CCCL_IMPLICIT_SYSTEM_HEADER_CLANG)
   #  pragma clang system_header
   #elif defined(_CCCL_IMPLICIT_SYSTEM_HEADER_MSVC)
   #  pragma system_header
   #endif // no system header

   #if _CCCL_CUDA_COMPILER(CLANG)
   #  include <cuda_runtime_api.h>
   #endif // _CCCL_CUDA_COMPILER(CLANG)

   #include <cuda/__memory_resource/get_property.h>
   #include <cuda/__memory_resource/properties.h>
   #include <cuda/__memory_resource/resource.h>
   #include <cuda/std/__concepts/concept_macros.h>
   #include <cuda/std/__cuda/api_wrapper.h>
   #include <cuda/std/detail/libcxx/include/stdexcept>

   #include <cuda/experimental/__memory_resource/any_resource.cuh>
   #include <cuda/experimental/__memory_resource/properties.cuh>

   #include <cuda/std/__cccl/prologue.h>

   namespace cuda::experimental
   {

   class managed_memory_resource
   {
   private:
     unsigned int __flags_ = cudaMemAttachGlobal;

     static constexpr unsigned int __available_flags = cudaMemAttachGlobal | cudaMemAttachHost;

   public:
     constexpr managed_memory_resource(const unsigned int __flags = cudaMemAttachGlobal) noexcept
         : __flags_(__flags & __available_flags)
     {
       _CCCL_ASSERT(__flags_ == __flags, "Unexpected flags passed to managed_memory_resource");
     }

     [[nodiscard]] void* allocate_sync(const size_t __bytes,
                                       const size_t __alignment = _CUDA_VMR::default_cuda_malloc_alignment) const
     {
       // We need to ensure that the provided alignment matches the minimal provided alignment
       if (!__is_valid_alignment(__alignment))
       {
         _CUDA_VSTD::__throw_invalid_argument("Invalid alignment passed to managed_memory_resource::allocate_sync.");
       }

       void* __ptr{nullptr};
       _CCCL_TRY_CUDA_API(
         ::cudaMallocManaged, "Failed to allocate memory with cudaMallocManaged.", &__ptr, __bytes, __flags_);
       return __ptr;
     }

     [[nodiscard]] void*
     allocate([[maybe_unused]] const ::cuda::stream_ref __stream, const size_t __bytes, const size_t __alignment)
     {
       return allocate_sync(__bytes, __alignment);
     }

     [[nodiscard]] void* allocate([[maybe_unused]] const ::cuda::stream_ref __stream, const size_t __bytes)
     {
       return allocate_sync(__bytes);
     }

     void deallocate_sync(
       void* __ptr,
       const size_t,
       [[maybe_unused]] const size_t __alignment = _CUDA_VMR::default_cuda_malloc_alignment) const noexcept
     {
       // We need to ensure that the provided alignment matches the minimal provided alignment
       _CCCL_ASSERT(__is_valid_alignment(__alignment),
                    "Invalid alignment passed to managed_memory_resource::deallocate_sync.");
       _CCCL_ASSERT_CUDA_API(::cudaFree, "managed_memory_resource::deallocate_sync failed", __ptr);
     }

     void deallocate([[maybe_unused]] const ::cuda::stream_ref __stream,
                     void* __ptr,
                     const size_t __bytes,
                     [[maybe_unused]] const size_t __alignment)
     {
       deallocate_sync(__ptr, __bytes);
     }

     void deallocate([[maybe_unused]] const ::cuda::stream_ref __stream, void* __ptr, size_t __bytes)
     {
       deallocate_sync(__ptr, __bytes);
     }

     [[nodiscard]] constexpr bool operator==(managed_memory_resource const& __other) const noexcept
     {
       return __flags_ == __other.__flags_;
     }
   #if _CCCL_STD_VER <= 2017
     [[nodiscard]] constexpr bool operator!=(managed_memory_resource const& __other) const noexcept
     {
       return __flags_ != __other.__flags_;
     }
   #endif // _CCCL_STD_VER <= 2017

   #ifndef _CCCL_DOXYGEN_INVOKED // Do not document
     friend constexpr void get_property(managed_memory_resource const&, device_accessible) noexcept {}
     friend constexpr void get_property(managed_memory_resource const&, host_accessible) noexcept {}
   #endif // _CCCL_DOXYGEN_INVOKED

     static constexpr bool __is_valid_alignment(const size_t __alignment) noexcept
     {
       return __alignment <= _CUDA_VMR::default_cuda_malloc_alignment
           && (_CUDA_VMR::default_cuda_malloc_alignment % __alignment == 0);
     }

     using default_queries = properties_list<device_accessible, host_accessible>;
   };
   static_assert(_CUDA_VMR::resource_with<managed_memory_resource, device_accessible>, "");
   static_assert(_CUDA_VMR::resource_with<managed_memory_resource, host_accessible>, "");

   } // namespace cuda::experimental

   #include <cuda/std/__cccl/epilogue.h>

   #endif //_CUDAX__MEMORY_RESOURCE_MANAGED_MEMORY_RESOURCE_CUH

