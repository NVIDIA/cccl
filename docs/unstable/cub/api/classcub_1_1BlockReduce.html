

<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>cub::BlockReduce &#8212; CUDA Core Compute Libraries</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/nvidia-sphinx-theme.css?v=933278ad" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />



    <script src="../../_static/documentation_options.js?v=bbe6ed3a"></script>
    <script src="../../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=5ceeb459"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'cub/api/classcub_1_1BlockReduce';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://NVIDIA.github.io/cccl/nv-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'unstable';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>

    <link rel="canonical" href="https://NVIDIA.github.io/cccl/cub/api/classcub_1_1BlockReduce.html" />
    <link rel="icon" href="../../_static/favicon.png"/>

    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="cub::BlockRunLengthDecode" href="classcub_1_1BlockRunLengthDecode.html" />
    <link rel="prev" title="cub::BlockRakingLayout" href="structcub_1_1BlockRakingLayout.html" />


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="unstable" />


  </head>

  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>


  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="CUDA Core Compute Libraries - Home"/>
    <img src="../../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="CUDA Core Compute Libraries - Home"/>
  
  
    <p class="title logo__title">CUDA Core Compute Libraries</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/NVIDIA/cccl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="CUDA Core Compute Libraries - Home"/>
    <img src="../../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="CUDA Core Compute Libraries - Home"/>
  
  
    <p class="title logo__title">CUDA Core Compute Libraries</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/NVIDIA/cccl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../cpp.html">CUDA C++ Core Libraries</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../../libcudacxx/index.html">libcu++</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libcudacxx/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/setup.html">Setup</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/setup/requirements.html">Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/setup/getting.html">Getting libcu++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/setup/building_and_testing.html">Building &amp; Testing libcu++</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/releases.html">Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/releases/changelog.html">Changelog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/releases/versioning.html">Versioning</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/standard_api.html">Standard API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/algorithms_library.html">Algorithms Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/c_library.html">C Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/concepts_library.html">Concepts Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/container_library.html">Container Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/execution_library.html">Execution Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/numerics_library.html">Numerics Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/ranges_library.html">Ranges Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/synchronization_library.html">Synchronization Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/time_library.html">Time Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/type_support.html">Type Support Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/utility_library.html">Utility Library</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/extended_api.html">Extended API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/bit.html">Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/execution_model.html">Execution model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/exceptions.html">Exception Handling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/memory_model.html">Memory model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/thread_groups.html">Thread Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/synchronization_primitives.html">Synchronization Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/asynchronous_operations.html">Asynchronous Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/memory_access_properties.html">Memory access properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/functional.html">Functional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/iterators.html">Fancy Iterators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/type_traits.html">Type traits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/vector_tuple_protocol.html">Vector Tuple Protocol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/numeric.html">Numeric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/random.html">Random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/memory.html">Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/memory_resource.html">Memory Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/math.html">Math</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/mdspan.html">Mdspan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/tma.html">Tensor Memory Accelerator (TMA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/warp.html">Warp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/utility.html">Utility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/work_stealing.html">Work stealing</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/runtime.html">Runtime</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/cudart_interactions.html">CUDA Runtime interactions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/stream.html">Streams</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/event.html">Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/algorithm.html">Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/device.html">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/hierarchy.html">Hierarchy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/launch.html">Launch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/buffer.html">Buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/memory_pools.html">Memory Pools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/legacy_resources.html">Legacy resources</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/ptx_api.html">PTX API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/ptx/examples.html">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/ptx/instructions.html">PTX Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/ptx/pragmas.html">PTX Pragmas</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../../libcudacxx/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../index.html">CUB</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../test_overview.html">CUB Tests</a></li>
<li class="toctree-l3"><a class="reference internal" href="../benchmarking.html">CUB Benchmarks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tuning.html">CUB Tunings</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../developer_overview.html">CUB Developer Overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../developer/thread_level.html">Thread-level</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer/warp_level.html">Warp-level</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer/block_scope.html">Block-scope</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer/device_scope.html">Device-scope</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer/nvtx.html">NVTX</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../releases.html">CUB Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../releases/changelog.html">CUB 2.1.0</a></li>


















































</ul>
</details></li>
<li class="toctree-l3 current active has-children"><a class="reference internal" href="../api.html">API documentation</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../api_docs/thread_level.html">Thread-level Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/warp_wide.html">Warp-Wide “Collective” Primitives</a></li>
<li class="toctree-l4 current active"><a class="reference internal" href="../api_docs/block_wide.html">Block-Wide “Collective” Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/device_wide.html">Device-Wide Primitives</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="index.html">API reference</a></li>
</ul>
</details></li>










<li class="toctree-l2 has-children"><a class="reference internal" href="../../thrust/index.html">Thrust</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../thrust/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../thrust/developer_overview.html">Thrust Developer Overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/developer/cmake_options.html">Developer CMake Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/developer/systems.html">Thrust systems</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../thrust/releases.html">Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/releases/changelog.html">Changelog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/releases/versioning.html">Versioning</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../../thrust/release_process.html">Release Process</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../thrust/api.html">API documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/algorithms.html">Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/containers.html">Containers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/function_objects.html">Function Objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/iterators.html">Iterators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/memory_management.html">Memory Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/numerics.html">Numerics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/parallel_execution_policies.html">Parallel Execution Policies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/random.html">Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/system.html">System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/utility.html">Utility</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../../thrust/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../cudax/index.html">CUDA Experimental</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../cudax/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cudax/container.html">Containers library</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/classcuda_1_1experimental_1_1uninitialized__buffer.html">cuda::experimental::uninitialized_buffer</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cudax/memory_resource.html">Memory Resources</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/classcuda_1_1mr_1_1basic__any__resource.html">cuda::mr::basic_any_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1memory__pool__properties.html">cuda::memory_pool_properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1device__memory__pool.html">cuda::device_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1pinned__memory__pool.html">cuda::pinned_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1managed__memory__pool.html">cuda::managed_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/classcuda_1_1mr_1_1legacy__pinned__memory__resource.html">cuda::mr::legacy_pinned_memory_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/classcuda_1_1mr_1_1legacy__managed__memory__resource.html">cuda::mr::legacy_managed_memory_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1mr_1_1shared__resource.html">cuda::mr::shared_resource</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cudax/graph.html">Graphs library</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1graph.html">cuda::experimental::graph</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1graph__builder.html">cuda::experimental::graph_builder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1graph__builder__ref.html">cuda::experimental::graph_builder_ref</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1graph__node__ref.html">cuda::experimental::graph_node_ref</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of.html">cuda::experimental::stf::graphed_interface_of</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01mdspan_3_01T_00_01P_8_8_8_01_4_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; mdspan&lt; T, P… &gt; &gt;</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01scalar__view_3_01T_01_4_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; scalar_view&lt; T &gt; &gt;</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01void__interface_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; void_interface &gt;</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cudax/stf.html">CUDASTF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/stf/custom_data_interface.html">Implementation of the <code class="docutils literal notranslate"><span class="pre">matrix</span></code> class</a></li>





<li class="toctree-l4"><a class="reference internal" href="../../cudax/stf/lower_level_api.html">Lower-level API</a></li>

</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../../cudax/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../cccl/tma.html">Tensor Memory Accelerator (TMA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../cccl/3.0_migration_guide.html">CCCL 2.x ‐ CCCL 3.0 migration guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../cccl/development/index.html">CCCL Development Guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../cccl/development/macro.html">CCCL Internal Macros</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../cccl/development/testing.html">CCCL Testing Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../cccl/development/build_and_bisect_tools.html">Build and Bisect Utilities</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cccl/development/visibility.html">Symbol Visibility</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../cccl/development/visibility/host_stub_visibility.html">Host Stub Visibility Issue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cccl/development/visibility/device_kernel_visibility.html">Device Kernel Visibility Issue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cccl/development/visibility/different_architectures.html">Linking TUs compiled with different architectures</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../cccl/contributing.html">Contributing to the CUDA Core Compute Libraries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../cccl/contributing/code_of_conduct.html">Code of Conduct</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../cccl/license.html">License</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../python/index.html">CCCL Python Libraries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../python/setup.html">Setup and Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/compute.html"><code class="docutils literal notranslate"><span class="pre">cuda.compute</span></code>: Parallel Computing Primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/coop.html"><code class="docutils literal notranslate"><span class="pre">cuda.coop</span></code>: Cooperative Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/resources.html">Resources</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../python/api_reference.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../python/compute_api.html"><code class="docutils literal notranslate"><span class="pre">cuda.compute</span></code> API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../python/coop_api.html"><code class="docutils literal notranslate"><span class="pre">cuda.coop</span></code> API Reference</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../cpp.html" class="nav-link">CUDA C++ Core Libraries</a></li>
    
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">CUB</a></li>
    
    
    <li class="breadcrumb-item"><a href="../api.html" class="nav-link">CUB API documentation</a></li>
    
    
    <li class="breadcrumb-item"><a href="../api_docs/block_wide.html" class="nav-link">Block-Wide “Collective” Primitives</a></li>
    
    
    <li class="breadcrumb-item"><a href="block.html" class="nav-link">Block-wide Primitives</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">cub::BlockReduce</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="cub-blockreduce">
<h1>cub::BlockReduce<a class="headerlink" href="#cub-blockreduce" title="Link to this heading">#</a></h1>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">T</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">BlockDimX</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="namespacecub_1add0251c713859b8974806079e498d10a.html#_CPPv4N3cub20BlockReduceAlgorithmE" title="cub::BlockReduceAlgorithm"><span class="n"><span class="pre">BlockReduceAlgorithm</span></span></a><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">Algorithm</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><a class="reference internal" href="namespacecub_1add0251c713859b8974806079e498d10a.html#_CPPv4N3cub20BlockReduceAlgorithm28BLOCK_REDUCE_WARP_REDUCTIONSE" title="cub::BLOCK_REDUCE_WARP_REDUCTIONS"><span class="n"><span class="pre">BLOCK_REDUCE_WARP_REDUCTIONS</span></span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">BlockDimY</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">1</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">BlockDimZ</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">1</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classcub_1_1BlockReduce"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">BlockReduce</span></span></span><a class="headerlink" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="Link to this definition">#</a><br /></dt>
<dd><p><p>The BlockReduce class provides <a class="reference internal" href="../index.html#collective-primitives"><span class="std std-ref">collective</span></a> methods for computing a
parallel reduction of items partitioned across a CUDA thread block.</p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>A <a class="reference external" href="http://en.wikipedia.org/wiki/Reduce_(higher-order_function)">reduction</a> (or <em>fold</em>) uses a
binary combining operator to compute a single aggregate from a list of input elements.</p></li>
<li><p>For multi-dimensional blocks, threads are linearly ranked in row-major order.</p></li>
<li><p>BlockReduce can be optionally specialized by algorithm to accommodate different
latency/throughput workload profiles:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="namespacecub_1add0251c713859b8974806079e498d10a.html#_CPPv4N3cub20BlockReduceAlgorithm36BLOCK_REDUCE_RAKING_COMMUTATIVE_ONLYE" title="cub::BLOCK_REDUCE_RAKING_COMMUTATIVE_ONLY"><code class="xref cpp cpp-enumerator docutils literal notranslate"><span class="pre">cub::BLOCK_REDUCE_RAKING_COMMUTATIVE_ONLY</span></code></a>:
An efficient “raking” reduction algorithm that only supports commutative reduction operators.</p></li>
<li><p><a class="reference internal" href="namespacecub_1add0251c713859b8974806079e498d10a.html#_CPPv4N3cub20BlockReduceAlgorithm19BLOCK_REDUCE_RAKINGE" title="cub::BLOCK_REDUCE_RAKING"><code class="xref cpp cpp-enumerator docutils literal notranslate"><span class="pre">cub::BLOCK_REDUCE_RAKING</span></code></a>:
An efficient “raking” reduction algorithm that supports commutative and non-commutative
reduction operators.</p></li>
<li><p><a class="reference internal" href="namespacecub_1add0251c713859b8974806079e498d10a.html#_CPPv4N3cub20BlockReduceAlgorithm28BLOCK_REDUCE_WARP_REDUCTIONSE" title="cub::BLOCK_REDUCE_WARP_REDUCTIONS"><code class="xref cpp cpp-enumerator docutils literal notranslate"><span class="pre">cub::BLOCK_REDUCE_WARP_REDUCTIONS</span></code></a>:
A quick “tiled warp-reductions” reduction algorithm that supports commutative and
non-commutative reduction operators.</p></li>
<li><p><a class="reference internal" href="namespacecub_1add0251c713859b8974806079e498d10a.html#_CPPv4N3cub20BlockReduceAlgorithm45BLOCK_REDUCE_WARP_REDUCTIONS_NONDETERMINISTICE" title="cub::BLOCK_REDUCE_WARP_REDUCTIONS_NONDETERMINISTIC"><code class="xref cpp cpp-enumerator docutils literal notranslate"><span class="pre">cub::BLOCK_REDUCE_WARP_REDUCTIONS_NONDETERMINISTIC</span></code></a>:
A quick “tiled warp-reductions” reduction algorithm that supports commutative and
non-commutative reduction operators. This variant uses atomic operations to reduce the
warp-wide reduction results, making it non-deterministic, i.e. the order of reduction
operations is not guaranteed to be the same across different invocations of the same
kernel.</p></li>
</ol>
</li>
</ul>
</section>
<section id="performance-considerations">
<h2>Performance Considerations<a class="headerlink" href="#performance-considerations" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Efficiency is increased with increased granularity <code class="docutils literal notranslate"><span class="pre">ITEMS_PER_THREAD</span></code>. Performance is also typically increased until the additional register pressure or shared memory allocation size causes SM occupancy to fall too low. Consider variants of <code class="docutils literal notranslate"><span class="pre">cub::BlockLoad</span></code> for efficiently gathering a <a class="reference internal" href="../index.html#flexible-data-arrangement"><span class="std std-ref">blocked arrangement</span></a> of elements across threads.</p></li>
<li><p>Very efficient (only one synchronization barrier).</p></li>
<li><p>Incurs zero bank conflicts for most types</p></li>
<li><p>Computation is slightly more efficient (i.e., having lower instruction overhead) for:
- Summation (vs. generic reduction)
- <code class="docutils literal notranslate"><span class="pre">BLOCK_THREADS</span></code> is a multiple of the architecture’s warp size
- Every thread has a valid input (i.e., full vs. partial-tiles)</p></li>
<li><p>See cub::BlockReduceAlgorithm for performance details regarding algorithmic alternatives</p></li>
</ul>
</section>
<section id="a-simple-example">
<h2>A Simple Example<a class="headerlink" href="#a-simple-example" title="Link to this heading">#</a></h2>
<p>Every thread in the block uses the BlockReduce class by first specializing the BlockReduce type, then instantiating an instance with parameters for communication, and finally invoking one or more collective member functions.</p>
<p>The code snippet below illustrates a sum reduction of 512 integer items that are partitioned in
a <a class="reference internal" href="../index.html#flexible-data-arrangement"><span class="std std-ref">blocked arrangement</span></a> across 128 threads where each thread
owns 4 consecutive items.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1">   // or equivalently &lt;cub/block/block_reduce.cuh&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ExampleKernel</span><span class="p">(...)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Specialize BlockReduce for a 1D block of 128 threads of type int</span>
<span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="n">BlockReduce</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">BlockReduce</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate shared memory for BlockReduce</span>
<span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">BlockReduce</span><span class="o">::</span><span class="n">TempStorage</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Obtain a segment of consecutive items that are blocked across threads</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread_data</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="w">    </span><span class="p">...</span>

<span class="w">    </span><span class="c1">// Compute the block-wide sum for thread0</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">aggregate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Sum</span><span class="p">(</span><span class="n">thread_data</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="re-using-dynamically-allocating-shared-memory">
<h2>Re-using dynamically allocating shared memory<a class="headerlink" href="#re-using-dynamically-allocating-shared-memory" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">block/example_block_reduce_dyn_smem.cu</span></code> example illustrates usage of dynamically shared
memory with BlockReduce and how to re-purpose the same memory region.</p>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T</strong> – Data type being reduced</p></li>
<li><p><strong>BlockDimX</strong> – The thread block length in threads along the X dimension</p></li>
<li><p><strong>Algorithm</strong> – <strong>[optional]</strong> <a class="reference internal" href="namespacecub_1add0251c713859b8974806079e498d10a.html#namespacecub_1add0251c713859b8974806079e498d10a"><span class="std std-ref">cub::BlockReduceAlgorithm</span></a> enumerator specifying the underlying algorithm to use (default: <a class="reference internal" href="namespacecub_1add0251c713859b8974806079e498d10a.html#namespacecub_1add0251c713859b8974806079e498d10aa993903176f938273fa1ff5d4daa808e5"><span class="std std-ref">cub::BLOCK_REDUCE_WARP_REDUCTIONS</span></a>)</p></li>
<li><p><strong>BlockDimY</strong> – <strong>[optional]</strong> The thread block length in threads along the Y dimension (default: 1)</p></li>
<li><p><strong>BlockDimZ</strong> – <strong>[optional]</strong> The thread block length in threads along the Z dimension (default: 1) </p></li>
</ul>
</dd>
</dl>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-collective-constructors">Collective constructors</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N3cub11BlockReduce11BlockReduceEv">
<span class="target" id="classcub_1_1BlockReduce_1a42e0254fd4996e0330427471f2ee8f1c"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">BlockReduce</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N3cub11BlockReduce11BlockReduceEv" title="Link to this definition">#</a><br /></dt>
<dd><p>Collective constructor using a private static allocation of shared memory as temporary storage. </p>
<p><div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
</p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N3cub11BlockReduce11BlockReduceER11TempStorage">
<span class="target" id="classcub_1_1BlockReduce_1a414e8f57d3817190828f5ebd9317ade6"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">BlockReduce</span></span></span><span class="sig-paren">(</span><em class="sig-param"><a class="reference internal" href="#_CPPv4N3cub11BlockReduce11TempStorageE" title="cub::BlockReduce::TempStorage"><span class="n"><span class="pre">TempStorage</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N3cub11BlockReduce11BlockReduceER11TempStorage" title="Link to this definition">#</a><br /></dt>
<dd><p>Collective constructor using the specified memory allocation as temporary storage. </p>
<p><div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>temp_storage</strong> – <strong>[in]</strong> Reference to memory allocation having layout type <a class="reference internal" href="#structcub_1_1BlockReduce_1_1TempStorage"><span class="std std-ref">TempStorage</span></a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-generic-reductions">Generic reductions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0EN3cub11BlockReduce6ReduceE1T1T11ReductionOp">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ReductionOp</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classcub_1_1BlockReduce_1af1606d4876bdbd8cadf23f54ca7a3d5c"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Reduce</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">input</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0EN3cub11BlockReduce6ReduceE1T1T11ReductionOp" title="cub::BlockReduce::Reduce::ReductionOp"><span class="n"><span class="pre">ReductionOp</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">reduction_op</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0EN3cub11BlockReduce6ReduceE1T1T11ReductionOp" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a block-wide reduction for thread<sub>0</sub> using the specified binary reduction functor.
Each thread contributes one input element.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The return value is undefined in threads other than thread<sub>0</sub>.</p></li>
<li><p>For multi-dimensional blocks, threads are linearly ranked in row-major order.</p></li>
<li><p>A subsequent <code class="docutils literal notranslate"><span class="pre">__syncthreads()</span></code> threadblock barrier should be invoked after calling this method if the collective’s temporary storage (e.g., <code class="docutils literal notranslate"><span class="pre">temp_storage</span></code>) is to be reused or repurposed.</p></li>
</ul>
<section id="snippet">
<h2>Snippet<a class="headerlink" href="#snippet" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a max reduction of 128 integer items that are partitioned
across 128 threads.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1">   // or equivalently &lt;cub/block/block_reduce.cuh&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ExampleKernel</span><span class="p">(...)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Specialize BlockReduce for a 1D block of 128 threads of type int</span>
<span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="n">BlockReduce</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">BlockReduce</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate shared memory for BlockReduce</span>
<span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">BlockReduce</span><span class="o">::</span><span class="n">TempStorage</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Each thread obtains an input item</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread_data</span><span class="p">;</span>
<span class="w">    </span><span class="p">...</span>

<span class="w">    </span><span class="c1">// Compute the block-wide max for thread0</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">aggregate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Reduce</span><span class="p">(</span><span class="n">thread_data</span><span class="p">,</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">maximum</span><span class="o">&lt;&gt;</span><span class="p">{});</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ReductionOp</strong> – <strong>[inferred]</strong> Binary reduction functor type having member <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">operator()(const</span> <span class="pre">T</span> <span class="pre">&amp;a,</span> <span class="pre">const</span> <span class="pre">T</span> <span class="pre">&amp;b)</span></code></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>input</strong> – <strong>[in]</strong> Calling thread’s input</p></li>
<li><p><strong>reduction_op</strong> – <strong>[in]</strong> Binary reduction functor </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I_i0EN3cub11BlockReduce6ReduceE1TRA16ITEMS_PER_THREAD_1T11ReductionOp">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ITEMS_PER_THREAD</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ReductionOp</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classcub_1_1BlockReduce_1a6084ac7cfe388a68dce1ea54dfc8efa0"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Reduce</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="p"><span class="pre">(</span></span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">inputs</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#_CPPv4I_i0EN3cub11BlockReduce6ReduceE1TRA16ITEMS_PER_THREAD_1T11ReductionOp" title="cub::BlockReduce::Reduce::ITEMS_PER_THREAD"><span class="n"><span class="pre">ITEMS_PER_THREAD</span></span></a><span class="p"><span class="pre">]</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I_i0EN3cub11BlockReduce6ReduceE1TRA16ITEMS_PER_THREAD_1T11ReductionOp" title="cub::BlockReduce::Reduce::ReductionOp"><span class="n"><span class="pre">ReductionOp</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">reduction_op</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I_i0EN3cub11BlockReduce6ReduceE1TRA16ITEMS_PER_THREAD_1T11ReductionOp" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a block-wide reduction for thread<sub>0</sub> using the specified binary reduction
functor. Each thread contributes an array of consecutive input elements.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The return value is undefined in threads other than thread<sub>0</sub>.</p></li>
<li><p>Efficiency is increased with increased granularity <code class="docutils literal notranslate"><span class="pre">ITEMS_PER_THREAD</span></code>. Performance is also typically increased until the additional register pressure or shared memory allocation size causes SM occupancy to fall too low. Consider variants of <code class="docutils literal notranslate"><span class="pre">cub::BlockLoad</span></code> for efficiently gathering a <a class="reference internal" href="../index.html#flexible-data-arrangement"><span class="std std-ref">blocked arrangement</span></a> of elements across threads.</p></li>
<li><p>A subsequent <code class="docutils literal notranslate"><span class="pre">__syncthreads()</span></code> threadblock barrier should be invoked after calling this method if the collective’s temporary storage (e.g., <code class="docutils literal notranslate"><span class="pre">temp_storage</span></code>) is to be reused or repurposed.</p></li>
</ul>
<section id="id1">
<h2>Snippet<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a max reduction of 512 integer items that are partitioned in a
<a class="reference internal" href="../index.html#flexible-data-arrangement"><span class="std std-ref">blocked arrangement</span></a> across 128 threads where each thread owns
4 consecutive items.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1">   // or equivalently &lt;cub/block/block_reduce.cuh&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ExampleKernel</span><span class="p">(...)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Specialize BlockReduce for a 1D block of 128 threads of type int</span>
<span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="n">BlockReduce</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">BlockReduce</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate shared memory for BlockReduce</span>
<span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">BlockReduce</span><span class="o">::</span><span class="n">TempStorage</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Obtain a segment of consecutive items that are blocked across threads</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread_data</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="w">    </span><span class="p">...</span>

<span class="w">    </span><span class="c1">// Compute the block-wide max for thread0</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">aggregate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Reduce</span><span class="p">(</span><span class="n">thread_data</span><span class="p">,</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">maximum</span><span class="o">&lt;&gt;</span><span class="p">{});</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ITEMS_PER_THREAD</strong> – <strong>[inferred]</strong> The number of consecutive items partitioned onto each thread.</p></li>
<li><p><strong>ReductionOp</strong> – <strong>[inferred]</strong> Binary reduction functor type having member <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">operator()(const</span> <span class="pre">T</span> <span class="pre">&amp;a,</span> <span class="pre">const</span> <span class="pre">T</span> <span class="pre">&amp;b)</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>inputs</strong> – <strong>[in]</strong> Calling thread’s input segment</p></li>
<li><p><strong>reduction_op</strong> – <strong>[in]</strong> Binary reduction functor </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0EN3cub11BlockReduce6ReduceE1T1T11ReductionOpi">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ReductionOp</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classcub_1_1BlockReduce_1a37c4b6112370873ab73bc5e440ebeedd"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Reduce</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">input</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0EN3cub11BlockReduce6ReduceE1T1T11ReductionOpi" title="cub::BlockReduce::Reduce::ReductionOp"><span class="n"><span class="pre">ReductionOp</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">reduction_op</span></span></em>,</dd>
<dd><em class="sig-param"><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">num_valid</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0EN3cub11BlockReduce6ReduceE1T1T11ReductionOpi" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a block-wide reduction for thread<sub>0</sub> using the specified binary reduction
functor. The first <code class="docutils literal notranslate"><span class="pre">num_valid</span></code> threads each contribute one input element.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The return value is undefined in threads other than thread&lt;sub&gt;0&lt;/sub&gt;.</p></li>
<li><p>For multi-dimensional blocks, threads are linearly ranked in row-major order.</p></li>
<li><p>A subsequent <code class="docutils literal notranslate"><span class="pre">__syncthreads()</span></code> threadblock barrier should be invoked after calling this method if the collective’s temporary storage (e.g., <code class="docutils literal notranslate"><span class="pre">temp_storage</span></code>) is to be reused or repurposed.</p></li>
</ul>
<section id="id2">
<h2>Snippet<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a max reduction of a partially-full tile of integer items
that are partitioned across 128 threads.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1">   // or equivalently &lt;cub/block/block_reduce.cuh&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ExampleKernel</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">num_valid</span><span class="p">,</span><span class="w"> </span><span class="p">...)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Specialize BlockReduce for a 1D block of 128 threads of type int</span>
<span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="n">BlockReduce</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">BlockReduce</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate shared memory for BlockReduce</span>
<span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">BlockReduce</span><span class="o">::</span><span class="n">TempStorage</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Each thread obtains an input item</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread_data</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_valid</span><span class="p">)</span><span class="w"> </span><span class="n">thread_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...</span>

<span class="w">    </span><span class="c1">// Compute the block-wide max for thread0</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">aggregate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Reduce</span><span class="p">(</span><span class="n">thread_data</span><span class="p">,</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">maximum</span><span class="o">&lt;&gt;</span><span class="p">{},</span><span class="w"> </span><span class="n">num_valid</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ReductionOp</strong> – <strong>[inferred]</strong> Binary reduction functor type having member <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">operator()(const</span> <span class="pre">T</span> <span class="pre">&amp;a,</span> <span class="pre">const</span> <span class="pre">T</span> <span class="pre">&amp;b)</span></code></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>input</strong> – <strong>[in]</strong> Calling thread’s input</p></li>
<li><p><strong>reduction_op</strong> – <strong>[in]</strong> Binary reduction functor</p></li>
<li><p><strong>num_valid</strong> – <strong>[in]</strong> Number of threads containing valid elements (may be less than BLOCK_THREADS) </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-summation-reductions">Summation reductions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N3cub11BlockReduce3SumE1T">
<span class="target" id="classcub_1_1BlockReduce_1ae113a80de5f5638c5d91bdd9c68ef823"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Sum</span></span></span><span class="sig-paren">(</span><em class="sig-param"><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N3cub11BlockReduce3SumE1T" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a block-wide reduction for thread<sub>0</sub> using addition (+) as the reduction operator.
Each thread contributes one input element.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The return value is undefined in threads other than thread<sub>0</sub>.</p></li>
<li><p>For multi-dimensional blocks, threads are linearly ranked in row-major order.</p></li>
<li><p>A subsequent <code class="docutils literal notranslate"><span class="pre">__syncthreads()</span></code> threadblock barrier should be invoked after calling this method if the collective’s temporary storage (e.g., <code class="docutils literal notranslate"><span class="pre">temp_storage</span></code>) is to be reused or repurposed.</p></li>
</ul>
<section id="id3">
<h2>Snippet<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a sum reduction of 128 integer items that are partitioned
across 128 threads.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1">   // or equivalently &lt;cub/block/block_reduce.cuh&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ExampleKernel</span><span class="p">(...)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Specialize BlockReduce for a 1D block of 128 threads of type int</span>
<span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="n">BlockReduce</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">BlockReduce</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate shared memory for BlockReduce</span>
<span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">BlockReduce</span><span class="o">::</span><span class="n">TempStorage</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Each thread obtains an input item</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread_data</span><span class="p">;</span>
<span class="w">    </span><span class="p">...</span>

<span class="w">    </span><span class="c1">// Compute the block-wide sum for thread0</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">aggregate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Sum</span><span class="p">(</span><span class="n">thread_data</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> – <strong>[in]</strong> Calling thread’s input </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I_iEN3cub11BlockReduce3SumE1TRA16ITEMS_PER_THREAD_1T">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ITEMS_PER_THREAD</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classcub_1_1BlockReduce_1ab258541101a8b4360ccfeba64ae5b36e"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Sum</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="p"><span class="pre">(</span></span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">inputs</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#_CPPv4I_iEN3cub11BlockReduce3SumE1TRA16ITEMS_PER_THREAD_1T" title="cub::BlockReduce::Sum::ITEMS_PER_THREAD"><span class="n"><span class="pre">ITEMS_PER_THREAD</span></span></a><span class="p"><span class="pre">]</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I_iEN3cub11BlockReduce3SumE1TRA16ITEMS_PER_THREAD_1T" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a block-wide reduction for thread&lt;sub&gt;0&lt;/sub&gt; using addition (+) as the reduction
operator. Each thread contributes an array of consecutive input elements.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The return value is undefined in threads other than thread<sub>0</sub>.</p></li>
<li><p>Efficiency is increased with increased granularity <code class="docutils literal notranslate"><span class="pre">ITEMS_PER_THREAD</span></code>. Performance is also typically increased until the additional register pressure or shared memory allocation size causes SM occupancy to fall too low. Consider variants of <code class="docutils literal notranslate"><span class="pre">cub::BlockLoad</span></code> for efficiently gathering a <a class="reference internal" href="../index.html#flexible-data-arrangement"><span class="std std-ref">blocked arrangement</span></a> of elements across threads.</p></li>
<li><p>A subsequent <code class="docutils literal notranslate"><span class="pre">__syncthreads()</span></code> threadblock barrier should be invoked after calling this method if the collective’s temporary storage (e.g., <code class="docutils literal notranslate"><span class="pre">temp_storage</span></code>) is to be reused or repurposed.</p></li>
</ul>
<section id="id4">
<h2>Snippet<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a sum reduction of 512 integer items that are partitioned in a
<a class="reference internal" href="../index.html#flexible-data-arrangement"><span class="std std-ref">blocked arrangement</span></a> across 128 threads where each thread owns
4 consecutive items.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1">   // or equivalently &lt;cub/block/block_reduce.cuh&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ExampleKernel</span><span class="p">(...)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Specialize BlockReduce for a 1D block of 128 threads of type int</span>
<span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="n">BlockReduce</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">BlockReduce</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate shared memory for BlockReduce</span>
<span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">BlockReduce</span><span class="o">::</span><span class="n">TempStorage</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Obtain a segment of consecutive items that are blocked across threads</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread_data</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="w">    </span><span class="p">...</span>

<span class="w">    </span><span class="c1">// Compute the block-wide sum for thread0</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">aggregate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Sum</span><span class="p">(</span><span class="n">thread_data</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ITEMS_PER_THREAD</strong> – <strong>[inferred]</strong> The number of consecutive items partitioned onto each thread.</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>inputs</strong> – <strong>[in]</strong> Calling thread’s input segment </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N3cub11BlockReduce3SumE1Ti">
<span class="target" id="classcub_1_1BlockReduce_1a8072b19900b8dee1c0459ba55400b34e"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Sum</span></span></span><span class="sig-paren">(</span><em class="sig-param"><a class="reference internal" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE" title="cub::BlockReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">num_valid</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N3cub11BlockReduce3SumE1Ti" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a block-wide reduction for thread<sub>0</sub> using addition (+) as the reduction
operator. The first <code class="docutils literal notranslate"><span class="pre">num_valid</span></code> threads each contribute one input element.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The return value is undefined in threads other than thread<sub>0</sub>.</p></li>
<li><p>For multi-dimensional blocks, threads are linearly ranked in row-major order.</p></li>
<li><p>A subsequent <code class="docutils literal notranslate"><span class="pre">__syncthreads()</span></code> threadblock barrier should be invoked after calling this method if the collective’s temporary storage (e.g., <code class="docutils literal notranslate"><span class="pre">temp_storage</span></code>) is to be reused or repurposed.</p></li>
</ul>
<section id="id5">
<h2>Snippet<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a sum reduction of a partially-full tile of integer items
that are partitioned across 128 threads.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1">   // or equivalently &lt;cub/block/block_reduce.cuh&gt;</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">ExampleKernel</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">num_valid</span><span class="p">,</span><span class="w"> </span><span class="p">...)</span>
<span class="p">{</span>
<span class="w">    </span><span class="c1">// Specialize BlockReduce for a 1D block of 128 threads of type int</span>
<span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="n">BlockReduce</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">BlockReduce</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate shared memory for BlockReduce</span>
<span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">BlockReduce</span><span class="o">::</span><span class="n">TempStorage</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Each thread obtains an input item (up to num_items)</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread_data</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_valid</span><span class="p">)</span>
<span class="w">        </span><span class="n">thread_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...</span>

<span class="w">    </span><span class="c1">// Compute the block-wide sum for thread0</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">aggregate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Sum</span><span class="p">(</span><span class="n">thread_data</span><span class="p">,</span><span class="w"> </span><span class="n">num_valid</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> – <strong>[in]</strong> Calling thread’s input</p></li>
<li><p><strong>num_valid</strong> – <strong>[in]</strong> Number of threads containing valid elements (may be less than BLOCK_THREADS) </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<dl class="cpp struct">
<dt class="sig sig-object cpp" id="_CPPv4N3cub11BlockReduce11TempStorageE">
<span class="target" id="structcub_1_1BlockReduce_1_1TempStorage"></span><span class="k"><span class="pre">struct</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">TempStorage</span></span></span><span class="w"> </span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="k"><span class="pre">public</span></span><span class="w"> </span><span class="n"><span class="pre">Uninitialized</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">_TempStorage</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4N3cub11BlockReduce11TempStorageE" title="Link to this definition">#</a><br /></dt>
<dd><p>The operations exposed by <a class="reference internal" href="#classcub_1_1BlockReduce"><span class="std std-ref">BlockReduce</span></a> require a temporary memory allocation of this nested type for thread communication. This opaque storage can be allocated directly using the <code class="docutils literal notranslate"><span class="pre">__shared__</span></code> keyword. Alternatively, it can be aliased to externally allocated memory (shared or global) or <code class="docutils literal notranslate"><span class="pre">union</span></code>’d with other storage allocation types to facilitate memory reuse. </p>
</dd></dl>

</dd></dl>

</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="structcub_1_1BlockRakingLayout.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">cub::BlockRakingLayout</p>
      </div>
    </a>
    <a class="right-next"
       href="classcub_1_1BlockRunLengthDecode.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">cub::BlockRunLengthDecode</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            


              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0_i_20BlockReduceAlgorithm_i_iEN3cub11BlockReduceE"><code class="docutils literal notranslate"><span class="pre">cub::BlockReduce</span></code></a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4N3cub11BlockReduce11BlockReduceEv"><code class="docutils literal notranslate"><span class="pre">BlockReduce()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4N3cub11BlockReduce11BlockReduceER11TempStorage"><code class="docutils literal notranslate"><span class="pre">BlockReduce()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0EN3cub11BlockReduce6ReduceE1T1T11ReductionOp"><code class="docutils literal notranslate"><span class="pre">Reduce()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I_i0EN3cub11BlockReduce6ReduceE1TRA16ITEMS_PER_THREAD_1T11ReductionOp"><code class="docutils literal notranslate"><span class="pre">Reduce()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0EN3cub11BlockReduce6ReduceE1T1T11ReductionOpi"><code class="docutils literal notranslate"><span class="pre">Reduce()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4N3cub11BlockReduce3SumE1T"><code class="docutils literal notranslate"><span class="pre">Sum()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I_iEN3cub11BlockReduce3SumE1TRA16ITEMS_PER_THREAD_1T"><code class="docutils literal notranslate"><span class="pre">Sum()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4N3cub11BlockReduce3SumE1Ti"><code class="docutils literal notranslate"><span class="pre">Sum()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4N3cub11BlockReduce11TempStorageE"><code class="docutils literal notranslate"><span class="pre">cub::BlockReduce::TempStorage</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  

  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright © 2026, NVIDIA Corporation.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 9.1.0.
    <br/>
  </p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>