

<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>cub::DeviceReduce &#8212; CUDA Core Compute Libraries</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/nvidia-sphinx-theme.css?v=933278ad" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />



    <script src="../../_static/documentation_options.js?v=bbe6ed3a"></script>
    <script src="../../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=5ceeb459"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'cub/api/structcub_1_1DeviceReduce';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://NVIDIA.github.io/cccl/nv-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'unstable';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>

    <link rel="canonical" href="https://NVIDIA.github.io/cccl/cub/api/structcub_1_1DeviceReduce.html" />
    <link rel="icon" href="../../_static/favicon.png"/>

    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="cub::DeviceRleDispatch" href="structcub_1_1DeviceRleDispatch.html" />
    <link rel="prev" title="cub::DeviceRadixSort" href="structcub_1_1DeviceRadixSort.html" />


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="unstable" />


  </head>

  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>


  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="CUDA Core Compute Libraries - Home"/>
    <img src="../../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="CUDA Core Compute Libraries - Home"/>
  
  
    <p class="title logo__title">CUDA Core Compute Libraries</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/NVIDIA/cccl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="CUDA Core Compute Libraries - Home"/>
    <img src="../../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="CUDA Core Compute Libraries - Home"/>
  
  
    <p class="title logo__title">CUDA Core Compute Libraries</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/NVIDIA/cccl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../cpp.html">CUDA C++ Core Libraries</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../../libcudacxx/index.html">libcu++</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libcudacxx/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/setup.html">Setup</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/setup/requirements.html">Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/setup/getting.html">Getting libcu++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/setup/building_and_testing.html">Building &amp; Testing libcu++</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/releases.html">Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/releases/changelog.html">Changelog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/releases/versioning.html">Versioning</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/standard_api.html">Standard API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/algorithms_library.html">Algorithms Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/c_library.html">C Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/concepts_library.html">Concepts Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/container_library.html">Container Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/execution_library.html">Execution Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/numerics_library.html">Numerics Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/ranges_library.html">Ranges Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/synchronization_library.html">Synchronization Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/time_library.html">Time Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/type_support.html">Type Support Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/standard_api/utility_library.html">Utility Library</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/extended_api.html">Extended API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/bit.html">Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/execution_model.html">Execution model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/exceptions.html">Exception Handling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/memory_model.html">Memory model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/thread_groups.html">Thread Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/synchronization_primitives.html">Synchronization Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/asynchronous_operations.html">Asynchronous Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/memory_access_properties.html">Memory access properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/functional.html">Functional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/iterators.html">Fancy Iterators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/type_traits.html">Type traits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/vector_tuple_protocol.html">Vector Tuple Protocol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/numeric.html">Numeric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/random.html">Random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/memory.html">Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/memory_resource.html">Memory Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/math.html">Math</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/mdspan.html">Mdspan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/tma.html">Tensor Memory Accelerator (TMA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/warp.html">Warp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/utility.html">Utility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/extended_api/work_stealing.html">Work stealing</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/runtime.html">Runtime</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/cudart_interactions.html">CUDA Runtime interactions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/stream.html">Streams</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/event.html">Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/algorithm.html">Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/device.html">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/hierarchy.html">Hierarchy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/launch.html">Launch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/buffer.html">Buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/memory_pools.html">Memory Pools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/runtime/legacy_resources.html">Legacy resources</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../libcudacxx/ptx_api.html">PTX API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/ptx/examples.html">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/ptx/instructions.html">PTX Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/ptx/pragmas.html">PTX Pragmas</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../../libcudacxx/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../index.html">CUB</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../test_overview.html">CUB Tests</a></li>
<li class="toctree-l3"><a class="reference internal" href="../benchmarking.html">CUB Benchmarks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tuning.html">CUB Tunings</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../developer_overview.html">CUB Developer Overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../developer/thread_level.html">Thread-level</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer/warp_level.html">Warp-level</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer/block_scope.html">Block-scope</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer/device_scope.html">Device-scope</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer/nvtx.html">NVTX</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../releases.html">CUB Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../releases/changelog.html">CUB 2.1.0</a></li>


















































</ul>
</details></li>
<li class="toctree-l3 current active has-children"><a class="reference internal" href="../api.html">API documentation</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../api_docs/thread_level.html">Thread-level Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/warp_wide.html">Warp-Wide “Collective” Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/block_wide.html">Block-Wide “Collective” Primitives</a></li>
<li class="toctree-l4 current active"><a class="reference internal" href="../api_docs/device_wide.html">Device-Wide Primitives</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="index.html">API reference</a></li>
</ul>
</details></li>










<li class="toctree-l2 has-children"><a class="reference internal" href="../../thrust/index.html">Thrust</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../thrust/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../thrust/developer_overview.html">Thrust Developer Overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/developer/cmake_options.html">Developer CMake Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/developer/systems.html">Thrust systems</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../thrust/releases.html">Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/releases/changelog.html">Changelog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/releases/versioning.html">Versioning</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../../thrust/release_process.html">Release Process</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../thrust/api.html">API documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/algorithms.html">Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/containers.html">Containers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/function_objects.html">Function Objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/iterators.html">Iterators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/memory_management.html">Memory Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/numerics.html">Numerics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/parallel_execution_policies.html">Parallel Execution Policies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/random.html">Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/system.html">System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../thrust/api_docs/utility.html">Utility</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../../thrust/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../cudax/index.html">CUDA Experimental</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../cudax/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cudax/container.html">Containers library</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/classcuda_1_1experimental_1_1uninitialized__buffer.html">cuda::experimental::uninitialized_buffer</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cudax/memory_resource.html">Memory Resources</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/classcuda_1_1mr_1_1basic__any__resource.html">cuda::mr::basic_any_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1memory__pool__properties.html">cuda::memory_pool_properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1device__memory__pool.html">cuda::device_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1pinned__memory__pool.html">cuda::pinned_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1managed__memory__pool.html">cuda::managed_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/classcuda_1_1mr_1_1legacy__pinned__memory__resource.html">cuda::mr::legacy_pinned_memory_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/classcuda_1_1mr_1_1legacy__managed__memory__resource.html">cuda::mr::legacy_managed_memory_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libcudacxx/api/structcuda_1_1mr_1_1shared__resource.html">cuda::mr::shared_resource</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cudax/graph.html">Graphs library</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1graph.html">cuda::experimental::graph</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1graph__builder.html">cuda::experimental::graph_builder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1graph__builder__ref.html">cuda::experimental::graph_builder_ref</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1graph__node__ref.html">cuda::experimental::graph_node_ref</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of.html">cuda::experimental::stf::graphed_interface_of</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01mdspan_3_01T_00_01P_8_8_8_01_4_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; mdspan&lt; T, P… &gt; &gt;</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01scalar__view_3_01T_01_4_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; scalar_view&lt; T &gt; &gt;</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01void__interface_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; void_interface &gt;</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cudax/stf.html">CUDASTF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../cudax/stf/custom_data_interface.html">Implementation of the <code class="docutils literal notranslate"><span class="pre">matrix</span></code> class</a></li>





<li class="toctree-l4"><a class="reference internal" href="../../cudax/stf/lower_level_api.html">Lower-level API</a></li>

</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../../cudax/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../cccl/tma.html">Tensor Memory Accelerator (TMA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../cccl/3.0_migration_guide.html">CCCL 2.x ‐ CCCL 3.0 migration guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../cccl/development/index.html">CCCL Development Guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../cccl/development/macro.html">CCCL Internal Macros</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../cccl/development/testing.html">CCCL Testing Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../cccl/development/build_and_bisect_tools.html">Build and Bisect Utilities</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../cccl/development/visibility.html">Symbol Visibility</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../cccl/development/visibility/host_stub_visibility.html">Host Stub Visibility Issue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cccl/development/visibility/device_kernel_visibility.html">Device Kernel Visibility Issue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../cccl/development/visibility/different_architectures.html">Linking TUs compiled with different architectures</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../cccl/contributing.html">Contributing to the CUDA Core Compute Libraries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../cccl/contributing/code_of_conduct.html">Code of Conduct</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../cccl/license.html">License</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../python/index.html">CCCL Python Libraries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../python/setup.html">Setup and Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/compute.html"><code class="docutils literal notranslate"><span class="pre">cuda.compute</span></code>: Parallel Computing Primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/coop.html"><code class="docutils literal notranslate"><span class="pre">cuda.coop</span></code>: Cooperative Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/resources.html">Resources</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../python/api_reference.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../python/compute_api.html"><code class="docutils literal notranslate"><span class="pre">cuda.compute</span></code> API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../python/coop_api.html"><code class="docutils literal notranslate"><span class="pre">cuda.coop</span></code> API Reference</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../cpp.html" class="nav-link">CUDA C++ Core Libraries</a></li>
    
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">CUB</a></li>
    
    
    <li class="breadcrumb-item"><a href="../api.html" class="nav-link">CUB API documentation</a></li>
    
    
    <li class="breadcrumb-item"><a href="../api_docs/device_wide.html" class="nav-link">Device-Wide Primitives</a></li>
    
    
    <li class="breadcrumb-item"><a href="device.html" class="nav-link">Device-wide Primitives</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">cub::DeviceReduce</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="cub-devicereduce">
<h1>cub::DeviceReduce<a class="headerlink" href="#cub-devicereduce" title="Link to this heading">#</a></h1>
<dl class="cpp struct">
<dt class="sig sig-object cpp" id="_CPPv4N3cub12DeviceReduceE">
<span class="target" id="structcub_1_1DeviceReduce"></span><span class="k"><span class="pre">struct</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">DeviceReduce</span></span></span><a class="headerlink" href="#_CPPv4N3cub12DeviceReduceE" title="Link to this definition">#</a><br /></dt>
<dd><p><p>DeviceReduce provides device-wide, parallel operations for computing
a reduction across a sequence of data items residing within
device-accessible memory.</p>
<img alt="../../_images/reduce_logo.png" class="align-center" src="../../_images/reduce_logo.png" /><section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>A <a class="reference external" href="http://en.wikipedia.org/wiki/Reduce_(higher-order_function)">reduction</a>
(or <em>fold</em>) uses a binary combining operator to compute a single aggregate
from a sequence of input elements.</p>
</section>
<section id="usage-considerations">
<h2>Usage Considerations<a class="headerlink" href="#usage-considerations" title="Link to this heading">#</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Dynamic parallelism. DeviceReduce methods can be called within kernel code on devices in which CUDA dynamic parallelism is supported.</p></li>
</ul>
</div></blockquote>
</section>
<section id="performance">
<h2>Performance<a class="headerlink" href="#performance" title="Link to this heading">#</a></h2>
<p>The work-complexity of reduction, reduce-by-key, and run-length encode as a function of input size is linear, resulting in performance throughput that plateaus with problem sizes large enough to saturate the GPU.</p>
</section>
</p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-static-functions">Public Static Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I00000EN3cub12DeviceReduce6ReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ReductionOpT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">T</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1acafa8de272ca3fc9f9093645ad78fc5e"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Reduce</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00000EN3cub12DeviceReduce6ReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T12cudaStream_t" title="cub::DeviceReduce::Reduce::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00000EN3cub12DeviceReduce6ReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T12cudaStream_t" title="cub::DeviceReduce::Reduce::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00000EN3cub12DeviceReduce6ReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T12cudaStream_t" title="cub::DeviceReduce::Reduce::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00000EN3cub12DeviceReduce6ReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T12cudaStream_t" title="cub::DeviceReduce::Reduce::ReductionOpT"><span class="n"><span class="pre">ReductionOpT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">reduction_op</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00000EN3cub12DeviceReduce6ReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T12cudaStream_t" title="cub::DeviceReduce::Reduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">init</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I00000EN3cub12DeviceReduce6ReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a device-wide reduction using the specified binary <code class="docutils literal notranslate"><span class="pre">reduction_op</span></code> functor and initial value <code class="docutils literal notranslate"><span class="pre">init</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>Does not support binary reduction operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="snippet">
<h2>Snippet<a class="headerlink" href="#snippet" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a user-defined min-reduction of a
device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span>
<span class="c1">// or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>

<span class="c1">// CustomMin functor</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">CustomMin</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w">    </span><span class="n">__device__</span><span class="w"> </span><span class="n">__forceinline__</span>
<span class="w">    </span><span class="n">T</span><span class="w"> </span><span class="k">operator</span><span class="p">()(</span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="o">&amp;</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="o">&amp;</span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">a</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers for</span>
<span class="c1">// input and output</span>
<span class="kt">int</span><span class="w">          </span><span class="n">num_items</span><span class="p">;</span><span class="w">  </span><span class="c1">// e.g., 7</span>
<span class="kt">int</span><span class="w">          </span><span class="o">*</span><span class="n">d_in</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., [8, 6, 7, 5, 3, 0, 9]</span>
<span class="kt">int</span><span class="w">          </span><span class="o">*</span><span class="n">d_out</span><span class="p">;</span><span class="w">     </span><span class="c1">// e.g., [-]</span>
<span class="n">CustomMin</span><span class="w">    </span><span class="n">min_op</span><span class="p">;</span>
<span class="kt">int</span><span class="w">          </span><span class="n">init</span><span class="p">;</span><span class="w">       </span><span class="c1">// e.g., INT_MAX</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Reduce</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span>
<span class="w">  </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">,</span><span class="w"> </span><span class="n">min_op</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run reduction</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Reduce</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span>
<span class="w">  </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">,</span><span class="w"> </span><span class="n">min_op</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="p">);</span>

<span class="c1">// d_out &lt;-- [0]</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>ReductionOpT</strong> – <strong>[inferred]</strong> Binary reduction functor type having member <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">operator()(const</span> <span class="pre">T</span> <span class="pre">&amp;a,</span> <span class="pre">const</span> <span class="pre">T</span> <span class="pre">&amp;b)</span></code></p></li>
<li><p><strong>T</strong> – <strong>[inferred]</strong> Data element type that is convertible to the <code class="docutils literal notranslate"><span class="pre">value</span></code> type of <code class="docutils literal notranslate"><span class="pre">InputIteratorT</span></code></p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>reduction_op</strong> – <strong>[in]</strong> Binary reduction functor</p></li>
<li><p><strong>init</strong> – <strong>[in]</strong> Initial value of the reduction</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ReductionOpT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">T</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">EnvT</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">execution</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">&lt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1ad23b8c778765442bfe03fb2c0b2ab2c1"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Reduce</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT" title="cub::DeviceReduce::Reduce::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT" title="cub::DeviceReduce::Reduce::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT" title="cub::DeviceReduce::Reduce::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT" title="cub::DeviceReduce::Reduce::ReductionOpT"><span class="n"><span class="pre">ReductionOpT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">reduction_op</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT" title="cub::DeviceReduce::Reduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">init</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT" title="cub::DeviceReduce::Reduce::EnvT"><span class="n"><span class="pre">EnvT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">env</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">{</span></span><span class="p"><span class="pre">}</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a device-wide reduction using the specified binary <code class="docutils literal notranslate"><span class="pre">reduction_op</span></code> functor and initial value <code class="docutils literal notranslate"><span class="pre">init</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul>
<li><p>Does not support binary reduction operators that are non-commutative.</p></li>
<li><p>By default, provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.
To request “gpu-to-gpu” determinism, pass <code class="docutils literal notranslate"><span class="pre">cuda::execution::require(cuda::execution::determinism::gpu_to_gpu)</span></code>
as the <cite>env</cite> parameter.
To request “not-guaranteed” determinism, pass</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">cuda::execution::require(cuda::execution::determinism::not_guaranteed)</span></code> as the <cite>env</cite> parameter.</p>
</div></blockquote>
</li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
</ul>
<section id="id1">
<h2>Snippet<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a user-defined min-reduction of a
device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">op</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="p">{};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">input</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">init</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">env</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">require</span><span class="p">(</span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">determinism</span><span class="o">::</span><span class="n">run_to_run</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Reduce</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="n">op</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="p">,</span><span class="w"> </span><span class="n">env</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">error</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaSuccess</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;cub::DeviceReduce::Reduce failed with status: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expected</span><span class="p">{</span><span class="mf">6.0f</span><span class="p">};</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>ReductionOpT</strong> – <strong>[inferred]</strong> Binary reduction functor type having member <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">operator()(const</span> <span class="pre">T</span> <span class="pre">&amp;a,</span> <span class="pre">const</span> <span class="pre">T</span> <span class="pre">&amp;b)</span></code></p></li>
<li><p><strong>T</strong> – <strong>[inferred]</strong> Data element type that is convertible to the <code class="docutils literal notranslate"><span class="pre">value</span></code> type of <code class="docutils literal notranslate"><span class="pre">InputIteratorT</span></code></p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
<li><p><strong>EnvT</strong> – <strong>[inferred]</strong> Execution environment type. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env&lt;&gt;</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>reduction_op</strong> – <strong>[in]</strong> Binary reduction functor</p></li>
<li><p><strong>init</strong> – <strong>[in]</strong> Initial value of the reduction</p></li>
<li><p><strong>env</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> Execution environment. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env{}</span></code>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0000EN3cub12DeviceReduce3SumE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">EnvT</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">execution</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">&lt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a0e23989aec0e061017410468e6b999d5"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Sum</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3SumE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Sum::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3SumE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Sum::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3SumE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Sum::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3SumE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Sum::EnvT"><span class="n"><span class="pre">EnvT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">env</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">{</span></span><span class="p"><span class="pre">}</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0000EN3cub12DeviceReduce3SumE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a device-wide sum using the addition (<code class="docutils literal notranslate"><span class="pre">+</span></code>) operator.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul>
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">0</span></code> as the initial value of the reduction.</p></li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">+</span></code> operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.
To request “gpu-to-gpu” determinism, pass <code class="docutils literal notranslate"><span class="pre">cuda::execution::require(cuda::execution::determinism::gpu_to_gpu)</span></code>
as the <cite>env</cite> parameter.
To request “not-guaranteed” determinism, pass</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">cuda::execution::require(cuda::execution::determinism::not_guaranteed)</span></code> as the <cite>env</cite> parameter.</p>
</div></blockquote>
</li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
</ul>
<section id="id2">
<h2>Snippet<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a user-defined min-reduction of a
device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">input</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">env</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">require</span><span class="p">(</span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">determinism</span><span class="o">::</span><span class="n">run_to_run</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Sum</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="n">env</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">error</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaSuccess</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;cub::DeviceReduce::Sum failed with status: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expected</span><span class="p">{</span><span class="mf">6.0f</span><span class="p">};</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
<li><p><strong>EnvT</strong> – <strong>[inferred]</strong> Execution environment type. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env&lt;&gt;</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>env</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> Execution environment. Default is <cite>cuda::std::execution::env{}</cite>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000EN3cub12DeviceReduce3SumE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a66557f26ffeccf769bea79324a7dda3c"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Sum</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3SumE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Sum::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3SumE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Sum::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3SumE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Sum::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000EN3cub12DeviceReduce3SumE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a device-wide sum using the addition (<code class="docutils literal notranslate"><span class="pre">+</span></code>) operator.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">0</span></code> as the initial value of the reduction.</p></li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">+</span></code> operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id3">
<h2>Snippet<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the sum-reduction of a device vector
of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1"> // or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers</span>
<span class="c1">// for input and output</span>
<span class="kt">int</span><span class="w">  </span><span class="n">num_items</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., 7</span>
<span class="kt">int</span><span class="w">  </span><span class="o">*</span><span class="n">d_in</span><span class="p">;</span><span class="w">          </span><span class="c1">// e.g., [8, 6, 7, 5, 3, 0, 9]</span>
<span class="kt">int</span><span class="w">  </span><span class="o">*</span><span class="n">d_out</span><span class="p">;</span><span class="w">         </span><span class="c1">// e.g., [-]</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Sum</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run sum-reduction</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Sum</span><span class="p">(</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// d_out &lt;-- [38]</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000EN3cub12DeviceReduce3MinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a6416b27adb641edd579c621853f08b48"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Min</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3MinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Min::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3MinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Min::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3MinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Min::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000EN3cub12DeviceReduce3MinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a device-wide minimum using the less-than (<code class="docutils literal notranslate"><span class="pre">&lt;</span></code>) operator.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">cuda::std::numeric_limits&lt;T&gt;::max()</span></code> as the initial value of the reduction.</p></li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">&lt;</span></code> operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id4">
<h2>Snippet<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the min-reduction of a device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span>
<span class="c1">// or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers</span>
<span class="c1">// for input and output</span>
<span class="kt">int</span><span class="w">  </span><span class="n">num_items</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., 7</span>
<span class="kt">int</span><span class="w">  </span><span class="o">*</span><span class="n">d_in</span><span class="p">;</span><span class="w">          </span><span class="c1">// e.g., [8, 6, 7, 5, 3, 0, 9]</span>
<span class="kt">int</span><span class="w">  </span><span class="o">*</span><span class="n">d_out</span><span class="p">;</span><span class="w">         </span><span class="c1">// e.g., [-]</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Min</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run min-reduction</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Min</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_out</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// d_out &lt;-- [0]</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0000EN3cub12DeviceReduce3MinE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">EnvT</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">execution</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">&lt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1af7554d01453f210aa3f76cd998fe7378"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Min</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3MinE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Min::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3MinE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Min::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3MinE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Min::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3MinE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Min::EnvT"><span class="n"><span class="pre">EnvT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">env</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">{</span></span><span class="p"><span class="pre">}</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0000EN3cub12DeviceReduce3MinE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a device-wide minimum using the less-than (<code class="docutils literal notranslate"><span class="pre">&lt;</span></code>) operator. The result is written to the output
iterator.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">cuda::std::numeric_limits&lt;T&gt;::max()</span></code> as the initial value of the reduction.</p></li>
<li><p>Provides determinism based on the environment’s determinism requirements.
To request “run-to-run” determinism, pass <code class="docutils literal notranslate"><span class="pre">cuda::execution::require(cuda::execution::determinism::run_to_run)</span></code>
as the <cite>env</cite> parameter.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
</ul>
<section id="id5">
<h2>Snippet<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the min-reduction of a device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">input</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">env</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">require</span><span class="p">(</span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">determinism</span><span class="o">::</span><span class="n">not_guaranteed</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Min</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="n">env</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">error</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaSuccess</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;cub::DeviceReduce::Min failed with status: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expected</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">};</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
<li><p><strong>EnvT</strong> – <strong>[inferred]</strong> Execution environment type. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env&lt;&gt;</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>env</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> Execution environment. Default is <cite>cuda::std::execution::env{}</cite>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ExtremumOutIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">IndexOutIteratorT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a42821c452ad29ea0fc9da2b13259d09e"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ArgMin</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t" title="cub::DeviceReduce::ArgMin::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t" title="cub::DeviceReduce::ArgMin::ExtremumOutIteratorT"><span class="n"><span class="pre">ExtremumOutIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_min_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t" title="cub::DeviceReduce::ArgMin::IndexOutIteratorT"><span class="n"><span class="pre">IndexOutIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_index_out</span></span></em>,</dd>
<dd><em class="sig-param"><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">int64_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Finds the first device-wide minimum using the less-than (<code class="docutils literal notranslate"><span class="pre">&lt;</span></code>) operator and also returns the index of that item.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The minimum is written to <code class="docutils literal notranslate"><span class="pre">d_min_out</span></code></p></li>
<li><p>The offset of the returned item is written to <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>, the offset type being written is of type
<code class="docutils literal notranslate"><span class="pre">cuda::std::int64_t</span></code>.</p></li>
<li><p>For zero-length inputs, <code class="docutils literal notranslate"><span class="pre">cuda::std::numeric_limits&lt;T&gt;::max()}</span></code> is written to <code class="docutils literal notranslate"><span class="pre">d_min_out</span></code>  and the index
<code class="docutils literal notranslate"><span class="pre">1</span></code> is written to <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>.</p></li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">&lt;</span></code> operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_min_out</span></code> nor <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id6">
<h2>Snippet<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the argmin-reduction of a device vector
of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1"> // or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda/std/cstdint&gt;</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers</span>
<span class="c1">// for input and output</span>
<span class="kt">int</span><span class="w">                </span><span class="n">num_items</span><span class="p">;</span><span class="w">    </span><span class="c1">// e.g., 7</span>
<span class="kt">int</span><span class="w">                </span><span class="o">*</span><span class="n">d_in</span><span class="p">;</span><span class="w">        </span><span class="c1">// e.g., [8, 6, 7, 5, 3, 0, 9]</span>
<span class="kt">int</span><span class="w">                </span><span class="o">*</span><span class="n">d_min_out</span><span class="p">;</span><span class="w">   </span><span class="c1">// memory for the minimum value</span>
<span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="kt">int64_t</span><span class="w"> </span><span class="o">*</span><span class="n">d_index_out</span><span class="p">;</span><span class="w"> </span><span class="c1">// memory for the index of the returned value</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMin</span><span class="p">(</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_min_out</span><span class="p">,</span><span class="w"> </span><span class="n">d_index_out</span><span class="p">,</span>
<span class="n">num_items</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run argmin-reduction</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMin</span><span class="p">(</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_min_out</span><span class="p">,</span><span class="w"> </span><span class="n">d_index_out</span><span class="p">,</span>
<span class="n">num_items</span><span class="p">);</span>

<span class="c1">// d_min_out   &lt;-- 0</span>
<span class="c1">// d_index_out &lt;-- 5</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (of some type <code class="docutils literal notranslate"><span class="pre">T</span></code>) (may be a simple pointer type)</p></li>
<li><p><strong>ExtremumOutIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording minimum value</p></li>
<li><p><strong>IndexOutIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording index of the returned value</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Iterator to the input sequence of data items</p></li>
<li><p><strong>d_min_out</strong> – <strong>[out]</strong> Iterator to which the minimum value is written</p></li>
<li><p><strong>d_index_out</strong> – <strong>[out]</strong> Iterator to which the index of the returned value is written</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0000EN3cub12DeviceReduce6ArgMinE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ExtremumOutIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">IndexOutIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">EnvT</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">execution</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">&lt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a5a53e9b6eb1c584a0b8b954f14f1267b"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ArgMin</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMinE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="cub::DeviceReduce::ArgMin::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMinE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="cub::DeviceReduce::ArgMin::ExtremumOutIteratorT"><span class="n"><span class="pre">ExtremumOutIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_min_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMinE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="cub::DeviceReduce::ArgMin::IndexOutIteratorT"><span class="n"><span class="pre">IndexOutIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_index_out</span></span></em>,</dd>
<dd><em class="sig-param"><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">int64_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMinE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="cub::DeviceReduce::ArgMin::EnvT"><span class="n"><span class="pre">EnvT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">env</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">{</span></span><span class="p"><span class="pre">}</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMinE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Finds the first device-wide minimum using the less-than (<code class="docutils literal notranslate"><span class="pre">&lt;</span></code>) operator and also returns the index of that item.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The minimum is written to <code class="docutils literal notranslate"><span class="pre">d_min_out</span></code></p></li>
<li><p>The offset of the returned item is written to <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>, the offset type being written is of type
<code class="docutils literal notranslate"><span class="pre">cuda::std::int64_t</span></code>.</p></li>
<li><p>For zero-length inputs, <code class="docutils literal notranslate"><span class="pre">cuda::std::numeric_limits&lt;T&gt;::max()}</span></code> is written to <code class="docutils literal notranslate"><span class="pre">d_min_out</span></code>  and the index
<code class="docutils literal notranslate"><span class="pre">1</span></code> is written to <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>.</p></li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">&lt;</span></code> operators that are non-commutative.</p></li>
<li><p>Provides determinism based on the environment’s determinism requirements.
To request “run-to-run” determinism, pass <code class="docutils literal notranslate"><span class="pre">cuda::execution::require(cuda::execution::determinism::run_to_run)</span></code>
as the <cite>env</cite> parameter.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_min_out</span></code> nor <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>.</p></li>
</ul>
<section id="id7">
<h2>Snippet<a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the argmin-reduction of a device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">input</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">{</span><span class="mf">3.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">min_output</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">index_output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">env</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">require</span><span class="p">(</span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">determinism</span><span class="o">::</span><span class="n">run_to_run</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMin</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">min_output</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">index_output</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="n">env</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">error</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaSuccess</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;cub::DeviceReduce::ArgMin failed with status: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expected_min</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">};</span>
<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expected_index</span><span class="p">{</span><span class="mi">3</span><span class="p">};</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (of some type <code class="docutils literal notranslate"><span class="pre">T</span></code>) (may be a simple pointer type)</p></li>
<li><p><strong>ExtremumOutIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording minimum value</p></li>
<li><p><strong>IndexOutIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording index of the returned value</p></li>
<li><p><strong>EnvT</strong> – <strong>[inferred]</strong> Execution environment type. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env&lt;&gt;</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_in</strong> – <strong>[in]</strong> Iterator to the input sequence of data items</p></li>
<li><p><strong>d_min_out</strong> – <strong>[out]</strong> Iterator to which the minimum value is written</p></li>
<li><p><strong>d_index_out</strong> – <strong>[out]</strong> Iterator to which the index of the returned value is written</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>env</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> Execution environment. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env{}</span></code>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I00EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a0e4300a8b1fbaab0adca7775e0f352bf"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ArgMin</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t" title="cub::DeviceReduce::ArgMin::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t" title="cub::DeviceReduce::ArgMin::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I00EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Finds the first device-wide minimum using the less-than (<code class="docutils literal notranslate"><span class="pre">&lt;</span></code>) operator, also returning the index of that item.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The output value type of <code class="docutils literal notranslate"><span class="pre">d_out</span></code> is <code class="docutils literal notranslate"><span class="pre">cub::KeyValuePair&lt;int,</span> <span class="pre">T&gt;</span></code>
(assuming the value type of <code class="docutils literal notranslate"><span class="pre">d_in</span></code> is <code class="docutils literal notranslate"><span class="pre">T</span></code>)</p>
<ul>
<li><p>The minimum is written to <code class="docutils literal notranslate"><span class="pre">d_out.value</span></code> and its offset in the input array is written to <code class="docutils literal notranslate"><span class="pre">d_out.key</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">{1,</span> <span class="pre">cuda::std::numeric_limits&lt;T&gt;::max()}</span></code> tuple is produced for zero-length inputs</p></li>
</ul>
</li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">&lt;</span></code> operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id8">
<h2>Snippet<a class="headerlink" href="#id8" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the argmin-reduction of a device vector
of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1"> // or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers</span>
<span class="c1">// for input and output</span>
<span class="kt">int</span><span class="w">                      </span><span class="n">num_items</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., 7</span>
<span class="kt">int</span><span class="w">                      </span><span class="o">*</span><span class="n">d_in</span><span class="p">;</span><span class="w">          </span><span class="c1">// e.g., [8, 6, 7, 5, 3, 0, 9]</span>
<span class="n">KeyValuePair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;</span><span class="w">   </span><span class="o">*</span><span class="n">d_argmin</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., [{-,-}]</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMin</span><span class="p">(</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_argmin</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run argmin-reduction</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMin</span><span class="p">(</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_argmin</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// d_argmin &lt;-- [{5, 0}]</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (of some type <code class="docutils literal notranslate"><span class="pre">T</span></code>) (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (having value type <code class="docutils literal notranslate"><span class="pre">cub::KeyValuePair&lt;int,</span> <span class="pre">T&gt;</span></code>) (may be a simple pointer type)</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000EN3cub12DeviceReduce3MaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a228a05654b3b11bc98b3543435186470"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Max</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3MaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Max::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3MaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Max::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce3MaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::Max::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000EN3cub12DeviceReduce3MaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a device-wide maximum using the greater-than (<code class="docutils literal notranslate"><span class="pre">&gt;</span></code>) operator.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">cuda::std::numeric_limits&lt;T&gt;::lowest()</span></code> as the initial value of the reduction.</p></li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">&gt;</span></code> operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id9">
<h2>Snippet<a class="headerlink" href="#id9" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the max-reduction of a device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1"> // or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers</span>
<span class="c1">// for input and output</span>
<span class="kt">int</span><span class="w">  </span><span class="n">num_items</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., 7</span>
<span class="kt">int</span><span class="w">  </span><span class="o">*</span><span class="n">d_in</span><span class="p">;</span><span class="w">          </span><span class="c1">// e.g., [8, 6, 7, 5, 3, 0, 9]</span>
<span class="kt">int</span><span class="w">  </span><span class="o">*</span><span class="n">d_max</span><span class="p">;</span><span class="w">         </span><span class="c1">// e.g., [-]</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Max</span><span class="p">(</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_max</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run max-reduction</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Max</span><span class="p">(</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_max</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// d_max &lt;-- [9]</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0000EN3cub12DeviceReduce3MaxE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">EnvT</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">execution</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">&lt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1aa9dd9d257b9d05685d467f0a22c00bf1"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Max</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3MaxE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Max::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3MaxE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Max::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3MaxE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Max::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce3MaxE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="cub::DeviceReduce::Max::EnvT"><span class="n"><span class="pre">EnvT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">env</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">{</span></span><span class="p"><span class="pre">}</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0000EN3cub12DeviceReduce3MaxE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Computes a device-wide maximum using the greater-than (<code class="docutils literal notranslate"><span class="pre">&gt;</span></code>) operator. The result is written to the output
iterator.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">cuda::std::numeric_limits&lt;T&gt;::lowest()</span></code> as the initial value of the reduction.</p></li>
<li><p>Provides determinism based on the environment’s determinism requirements.
To request “run-to-run” determinism, pass <code class="docutils literal notranslate"><span class="pre">cuda::execution::require(cuda::execution::determinism::run_to_run)</span></code>
as the <cite>env</cite> parameter.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
</ul>
<section id="id10">
<h2>Snippet<a class="headerlink" href="#id10" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the max-reduction of a device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">input</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">env</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">require</span><span class="p">(</span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">determinism</span><span class="o">::</span><span class="n">run_to_run</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">Max</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="n">env</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">error</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaSuccess</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;cub::DeviceReduce::Max failed with status: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expected</span><span class="p">{</span><span class="mf">3.0f</span><span class="p">};</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
<li><p><strong>EnvT</strong> – <strong>[inferred]</strong> Execution environment type. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env&lt;&gt;</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>env</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> Execution environment. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env{}</span></code>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ExtremumOutIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">IndexOutIteratorT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a13648ad6bed5c58af723dd45762b4fc3"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ArgMax</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t" title="cub::DeviceReduce::ArgMax::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t" title="cub::DeviceReduce::ArgMax::ExtremumOutIteratorT"><span class="n"><span class="pre">ExtremumOutIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_max_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t" title="cub::DeviceReduce::ArgMax::IndexOutIteratorT"><span class="n"><span class="pre">IndexOutIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_index_out</span></span></em>,</dd>
<dd><em class="sig-param"><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">int64_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Finds the first device-wide maximum using the greater-than (<code class="docutils literal notranslate"><span class="pre">&gt;</span></code>) operator and also returns the index of that
item.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The maximum is written to <code class="docutils literal notranslate"><span class="pre">d_max_out</span></code></p></li>
<li><p>The offset of the returned item is written to <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>, the offset type being written is of type
<code class="docutils literal notranslate"><span class="pre">cuda::std::int64_t</span></code>.</p></li>
<li><p>For zero-length inputs, <code class="docutils literal notranslate"><span class="pre">cuda::std::numeric_limits&lt;T&gt;::max()}</span></code> is written to <code class="docutils literal notranslate"><span class="pre">d_max_out</span></code>  and the index
<code class="docutils literal notranslate"><span class="pre">1</span></code> is written to <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>.</p></li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">&gt;</span></code> operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id11">
<h2>Snippet<a class="headerlink" href="#id11" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the argmax-reduction of a device vector
of <cite>int</cite> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span><span class="c1"> // or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda/std/cstdint&gt;</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers</span>
<span class="c1">// for input and output</span>
<span class="kt">int</span><span class="w">                </span><span class="n">num_items</span><span class="p">;</span><span class="w">    </span><span class="c1">// e.g., 7</span>
<span class="kt">int</span><span class="w">                </span><span class="o">*</span><span class="n">d_in</span><span class="p">;</span><span class="w">        </span><span class="c1">// e.g., [8, 6, 7, 5, 3, 0, 9]</span>
<span class="kt">int</span><span class="w">                </span><span class="o">*</span><span class="n">d_max_out</span><span class="p">;</span><span class="w">   </span><span class="c1">// memory for the maximum value</span>
<span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="kt">int64_t</span><span class="w"> </span><span class="o">*</span><span class="n">d_index_out</span><span class="p">;</span><span class="w"> </span><span class="c1">// memory for the index of the returned value</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMax</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_max_out</span><span class="p">,</span><span class="w"> </span><span class="n">d_index_out</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run argmax-reduction</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMax</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_max_out</span><span class="p">,</span><span class="w"> </span><span class="n">d_index_out</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// d_max_out   &lt;-- 9</span>
<span class="c1">// d_index_out &lt;-- 6</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (of some type <code class="docutils literal notranslate"><span class="pre">T</span></code>) (may be a simple pointer type)</p></li>
<li><p><strong>ExtremumOutIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording maximum value</p></li>
<li><p><strong>IndexOutIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording index of the returned value</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_max_out</strong> – <strong>[out]</strong> Iterator to which the maximum value is written</p></li>
<li><p><strong>d_index_out</strong> – <strong>[out]</strong> Iterator to which the index of the returned value is written</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I00EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a7c35943637a3c3c956f2fff8b7942b95"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ArgMax</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t" title="cub::DeviceReduce::ArgMax::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I00EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t" title="cub::DeviceReduce::ArgMax::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I00EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Finds the first device-wide maximum using the greater-than (<code class="docutils literal notranslate"><span class="pre">&gt;</span></code>)
operator, also returning the index of that item</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The output value type of <code class="docutils literal notranslate"><span class="pre">d_out</span></code> is <code class="docutils literal notranslate"><span class="pre">cub::KeyValuePair&lt;int,</span> <span class="pre">T&gt;</span></code>
(assuming the value type of <code class="docutils literal notranslate"><span class="pre">d_in</span></code> is <code class="docutils literal notranslate"><span class="pre">T</span></code>)</p>
<ul>
<li><p>The maximum is written to <code class="docutils literal notranslate"><span class="pre">d_out.value</span></code> and its offset in the input
array is written to <code class="docutils literal notranslate"><span class="pre">d_out.key</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">{1,</span> <span class="pre">cuda::std::numeric_limits&lt;T&gt;::lowest()}</span></code> tuple is produced for zero-length inputs</p></li>
</ul>
</li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">&gt;</span></code> operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id12">
<h2>Snippet<a class="headerlink" href="#id12" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the argmax-reduction of a device vector
of <cite>int</cite> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span>
<span class="c1">// or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers</span>
<span class="c1">// for input and output</span>
<span class="kt">int</span><span class="w">                      </span><span class="n">num_items</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., 7</span>
<span class="kt">int</span><span class="w">                      </span><span class="o">*</span><span class="n">d_in</span><span class="p">;</span><span class="w">          </span><span class="c1">// e.g., [8, 6, 7, 5, 3, 0, 9]</span>
<span class="n">KeyValuePair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;</span><span class="w">   </span><span class="o">*</span><span class="n">d_argmax</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., [{-,-}]</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMax</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_argmax</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run argmax-reduction</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMax</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span><span class="w"> </span><span class="n">d_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_argmax</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// d_argmax &lt;-- [{6, 9}]</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (of some type <code class="docutils literal notranslate"><span class="pre">T</span></code>) (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (having value type <code class="docutils literal notranslate"><span class="pre">cub::KeyValuePair&lt;int,</span> <span class="pre">T&gt;</span></code>) (may be a simple pointer type)</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0000EN3cub12DeviceReduce6ArgMaxE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ExtremumOutIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">IndexOutIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">EnvT</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">execution</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">env</span></span><span class="p"><span class="pre">&lt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1af36b6c5d28b6ada081b54e26c00c08e9"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ArgMax</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMaxE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="cub::DeviceReduce::ArgMax::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMaxE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="cub::DeviceReduce::ArgMax::ExtremumOutIteratorT"><span class="n"><span class="pre">ExtremumOutIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_max_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMaxE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="cub::DeviceReduce::ArgMax::IndexOutIteratorT"><span class="n"><span class="pre">IndexOutIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_index_out</span></span></em>,</dd>
<dd><em class="sig-param"><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">cuda</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">int64_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMaxE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="cub::DeviceReduce::ArgMax::EnvT"><span class="n"><span class="pre">EnvT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">env</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">{</span></span><span class="p"><span class="pre">}</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMaxE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Finds the first device-wide maximum using the greater-than (<code class="docutils literal notranslate"><span class="pre">&gt;</span></code>) operator and also returns the index of that
item.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>The maximum is written to <code class="docutils literal notranslate"><span class="pre">d_max_out</span></code></p></li>
<li><p>The offset of the returned item is written to <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>, the offset type being written is of type
<code class="docutils literal notranslate"><span class="pre">cuda::std::int64_t</span></code>.</p></li>
<li><p>For zero-length inputs, <code class="docutils literal notranslate"><span class="pre">cuda::std::numeric_limits&lt;T&gt;::lowest()}</span></code> is written to <code class="docutils literal notranslate"><span class="pre">d_max_out</span></code>  and the index
<code class="docutils literal notranslate"><span class="pre">1</span></code> is written to <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>.</p></li>
<li><p>Does not support <code class="docutils literal notranslate"><span class="pre">&gt;</span></code> operators that are non-commutative.</p></li>
<li><p>Provides determinism based on the environment’s determinism requirements.
To request “run-to-run” determinism, pass <code class="docutils literal notranslate"><span class="pre">cuda::execution::require(cuda::execution::determinism::run_to_run)</span></code>
as the <cite>env</cite> parameter.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_max_out</span></code> nor <code class="docutils literal notranslate"><span class="pre">d_index_out</span></code>.</p></li>
</ul>
<section id="id13">
<h2>Snippet<a class="headerlink" href="#id13" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the argmax-reduction of a device vector of <code class="docutils literal notranslate"><span class="pre">int</span></code> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">input</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">{</span><span class="mf">3.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">max_output</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">index_output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">env</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">require</span><span class="p">(</span><span class="n">cuda</span><span class="o">::</span><span class="n">execution</span><span class="o">::</span><span class="n">determinism</span><span class="o">::</span><span class="n">not_guaranteed</span><span class="p">);</span>

<span class="k">auto</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ArgMax</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">max_output</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">index_output</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span><span class="w"> </span><span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="n">env</span><span class="p">);</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">error</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaSuccess</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;cub::DeviceReduce::ArgMax failed with status: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expected_max</span><span class="p">{</span><span class="mf">4.0f</span><span class="p">};</span>
<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expected_index</span><span class="p">{</span><span class="mi">2</span><span class="p">};</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (of some type <code class="docutils literal notranslate"><span class="pre">T</span></code>) (may be a simple pointer type)</p></li>
<li><p><strong>ExtremumOutIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording maximum value</p></li>
<li><p><strong>IndexOutIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording index of the returned value</p></li>
<li><p><strong>EnvT</strong> – <strong>[inferred]</strong> Execution environment type. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env&lt;&gt;</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_in</strong> – <strong>[in]</strong> Iterator to the input sequence of data items</p></li>
<li><p><strong>d_max_out</strong> – <strong>[out]</strong> Iterator to which the maximum value is written</p></li>
<li><p><strong>d_index_out</strong> – <strong>[out]</strong> Iterator to which the index of the returned value is written</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>env</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> Execution environment. Default is <code class="docutils literal notranslate"><span class="pre">cuda::std::execution::env{}</span></code>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">InputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">OutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ReductionOpT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">TransformOpT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">T</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1a5397a67b57221562a508cd1ed5aa4fae"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">TransformReduce</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t" title="cub::DeviceReduce::TransformReduce::InputIteratorT"><span class="n"><span class="pre">InputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t" title="cub::DeviceReduce::TransformReduce::OutputIteratorT"><span class="n"><span class="pre">OutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t" title="cub::DeviceReduce::TransformReduce::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t" title="cub::DeviceReduce::TransformReduce::ReductionOpT"><span class="n"><span class="pre">ReductionOpT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">reduction_op</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t" title="cub::DeviceReduce::TransformReduce::TransformOpT"><span class="n"><span class="pre">TransformOpT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">transform_op</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t" title="cub::DeviceReduce::TransformReduce::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">init</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Fuses transform and reduce operations</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<ul class="simple">
<li><p>Does not support binary reduction operators that are non-commutative.</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>The range <code class="docutils literal notranslate"><span class="pre">[d_in,</span> <span class="pre">d_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> shall not overlap <code class="docutils literal notranslate"><span class="pre">d_out</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id14">
<h2>Snippet<a class="headerlink" href="#id14" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates a user-defined min-reduction of a
device vector of <cite>int</cite> data elements.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span>
<span class="c1">// or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>

<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="p">};</span>
<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">out</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="kt">size_t</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>

<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">init</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">42</span><span class="p">;</span>

<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">TransformReduce</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span>
<span class="w">  </span><span class="n">temp_storage_bytes</span><span class="p">,</span>
<span class="w">  </span><span class="n">in</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
<span class="w">  </span><span class="n">out</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
<span class="w">  </span><span class="n">in</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span>
<span class="w">  </span><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="o">&lt;&gt;</span><span class="p">{},</span>
<span class="w">  </span><span class="n">square_t</span><span class="p">{},</span>
<span class="w">  </span><span class="n">init</span><span class="p">);</span>

<span class="n">thrust</span><span class="o">::</span><span class="n">device_vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">(</span><span class="n">temp_storage_bytes</span><span class="p">);</span>
<span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">.</span><span class="n">data</span><span class="p">().</span><span class="n">get</span><span class="p">();</span>

<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">TransformReduce</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span>
<span class="w">  </span><span class="n">temp_storage_bytes</span><span class="p">,</span>
<span class="w">  </span><span class="n">in</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
<span class="w">  </span><span class="n">out</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
<span class="w">  </span><span class="n">in</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span>
<span class="w">  </span><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">plus</span><span class="o">&lt;&gt;</span><span class="p">{},</span>
<span class="w">  </span><span class="n">square_t</span><span class="p">{},</span>
<span class="w">  </span><span class="n">init</span><span class="p">);</span>

<span class="c1">// out[0] &lt;-- 72</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>InputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input items (may be a simple pointer type)</p></li>
<li><p><strong>OutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the reduced aggregate (may be a simple pointer type)</p></li>
<li><p><strong>ReductionOpT</strong> – <strong>[inferred]</strong> Binary reduction functor type having member <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">operator()(const</span> <span class="pre">T</span> <span class="pre">&amp;a,</span> <span class="pre">const</span> <span class="pre">T</span> <span class="pre">&amp;b)</span></code></p></li>
<li><p><strong>TransformOpT</strong> – <strong>[inferred]</strong> Unary reduction functor type having member <code class="docutils literal notranslate"><span class="pre">auto</span> <span class="pre">operator()(const</span> <span class="pre">T</span> <span class="pre">&amp;a)</span></code></p></li>
<li><p><strong>T</strong> – <strong>[inferred]</strong> Data element type that is convertible to the <code class="docutils literal notranslate"><span class="pre">value</span></code> type of <code class="docutils literal notranslate"><span class="pre">InputIteratorT</span></code></p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_in</strong> – <strong>[in]</strong> Pointer to the input sequence of data items</p></li>
<li><p><strong>d_out</strong> – <strong>[out]</strong> Pointer to the output aggregate</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of input items (i.e., length of <code class="docutils literal notranslate"><span class="pre">d_in</span></code>)</p></li>
<li><p><strong>reduction_op</strong> – <strong>[in]</strong> Binary reduction functor</p></li>
<li><p><strong>transform_op</strong> – <strong>[in]</strong> Unary transform functor</p></li>
<li><p><strong>init</strong> – <strong>[in]</strong> Initial value of the reduction</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t">
<span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">KeysInputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">UniqueOutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ValuesInputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">AggregatesOutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumRunsOutputIteratorT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">ReductionOpT</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname sig-name-template"><span class="n"><span class="pre">NumItemsT</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="structcub_1_1DeviceReduce_1aa47b4d69a09ef1d804f1988ce698aed6"></span><span class="k"><span class="pre">static</span></span><span class="w"> </span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="n"><span class="pre">cudaError_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ReduceByKey</span></span></span><span class="sig-paren">(</span>

<dl>
<dd><em class="sig-param"><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">d_temp_storage</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">temp_storage_bytes</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::ReduceByKey::KeysInputIteratorT"><span class="n"><span class="pre">KeysInputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_keys_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::ReduceByKey::UniqueOutputIteratorT"><span class="n"><span class="pre">UniqueOutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_unique_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::ReduceByKey::ValuesInputIteratorT"><span class="n"><span class="pre">ValuesInputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_values_in</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::ReduceByKey::AggregatesOutputIteratorT"><span class="n"><span class="pre">AggregatesOutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_aggregates_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::ReduceByKey::NumRunsOutputIteratorT"><span class="n"><span class="pre">NumRunsOutputIteratorT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">d_num_runs_out</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::ReduceByKey::ReductionOpT"><span class="n"><span class="pre">ReductionOpT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">reduction_op</span></span></em>,</dd>
<dd><em class="sig-param"><a class="reference internal" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t" title="cub::DeviceReduce::ReduceByKey::NumItemsT"><span class="n"><span class="pre">NumItemsT</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">num_items</span></span></em>,</dd>
<dd><em class="sig-param"><span class="n"><span class="pre">cudaStream_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">stream</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span></em></dd>
</dl>

<span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t" title="Link to this definition">#</a><br /></dt>
<dd><p><p>Reduces segments of values, where segments are demarcated by corresponding runs of identical keys.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 2.2.0: </span>First appears in CUDA Toolkit 12.3.</p>
</div>
<p>This operation computes segmented reductions within <code class="docutils literal notranslate"><span class="pre">d_values_in</span></code> using the specified binary <code class="docutils literal notranslate"><span class="pre">reduction_op</span></code>
functor. The segments are identified by “runs” of corresponding keys in <cite>d_keys_in</cite>, where runs are maximal
ranges of consecutive, identical keys. For the <em>i</em><sup>th</sup> run encountered, the last key of the run and
the corresponding value aggregate of that run are written to <code class="docutils literal notranslate"><span class="pre">d_unique_out[i]</span></code> and <code class="docutils literal notranslate"><span class="pre">d_aggregates_out[i]</span></code>,
respectively. The total number of runs encountered is written to <code class="docutils literal notranslate"><span class="pre">d_num_runs_out</span></code>.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">==</span></code> equality operator is used to determine whether keys are equivalent</p></li>
<li><p>Provides “run-to-run” determinism for pseudo-associative reduction
(e.g., addition of floating point types) on the same GPU device.
However, results for pseudo-associative reduction may be inconsistent
from one device to a another device of a different compute-capability
because CUB can employ different tile-sizing for different architectures.</p></li>
<li><p>Let <code class="docutils literal notranslate"><span class="pre">out</span></code> be any of
<code class="docutils literal notranslate"><span class="pre">[d_unique_out,</span> <span class="pre">d_unique_out</span> <span class="pre">+</span> <span class="pre">*d_num_runs_out)</span></code>
<code class="docutils literal notranslate"><span class="pre">[d_aggregates_out,</span> <span class="pre">d_aggregates_out</span> <span class="pre">+</span> <span class="pre">*d_num_runs_out)</span></code>
<code class="docutils literal notranslate"><span class="pre">d_num_runs_out</span></code>. The ranges represented by <code class="docutils literal notranslate"><span class="pre">out</span></code> shall not overlap
<code class="docutils literal notranslate"><span class="pre">[d_keys_in,</span> <span class="pre">d_keys_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code>,
<code class="docutils literal notranslate"><span class="pre">[d_values_in,</span> <span class="pre">d_values_in</span> <span class="pre">+</span> <span class="pre">num_items)</span></code> nor <code class="docutils literal notranslate"><span class="pre">out</span></code> in any way.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> is <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, no work is done and the required allocation size is returned in <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code>. See <a class="reference internal" href="../api_docs/device_wide.html#device-temp-storage"><span class="std std-ref">Determining Temporary Storage Requirements</span></a> for usage guidance.</p></li>
</ul>
<section id="id15">
<h2>Snippet<a class="headerlink" href="#id15" title="Link to this heading">#</a></h2>
<p>The code snippet below illustrates the segmented reduction of <code class="docutils literal notranslate"><span class="pre">int</span></code> values grouped by runs of
associated <code class="docutils literal notranslate"><span class="pre">int</span></code> keys.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cub/cub.cuh&gt;</span>
<span class="c1">// or equivalently &lt;cub/device/device_reduce.cuh&gt;</span>

<span class="c1">// CustomMin functor</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">CustomMin</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w">    </span><span class="n">__device__</span><span class="w"> </span><span class="n">__forceinline__</span>
<span class="w">    </span><span class="n">T</span><span class="w"> </span><span class="k">operator</span><span class="p">()(</span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="o">&amp;</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="o">&amp;</span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">a</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>

<span class="c1">// Declare, allocate, and initialize device-accessible pointers</span>
<span class="c1">// for input and output</span>
<span class="kt">int</span><span class="w">          </span><span class="n">num_items</span><span class="p">;</span><span class="w">          </span><span class="c1">// e.g., 8</span>
<span class="kt">int</span><span class="w">          </span><span class="o">*</span><span class="n">d_keys_in</span><span class="p">;</span><span class="w">         </span><span class="c1">// e.g., [0, 2, 2, 9, 5, 5, 5, 8]</span>
<span class="kt">int</span><span class="w">          </span><span class="o">*</span><span class="n">d_values_in</span><span class="p">;</span><span class="w">       </span><span class="c1">// e.g., [0, 7, 1, 6, 2, 5, 3, 4]</span>
<span class="kt">int</span><span class="w">          </span><span class="o">*</span><span class="n">d_unique_out</span><span class="p">;</span><span class="w">      </span><span class="c1">// e.g., [-, -, -, -, -, -, -, -]</span>
<span class="kt">int</span><span class="w">          </span><span class="o">*</span><span class="n">d_aggregates_out</span><span class="p">;</span><span class="w">  </span><span class="c1">// e.g., [-, -, -, -, -, -, -, -]</span>
<span class="kt">int</span><span class="w">          </span><span class="o">*</span><span class="n">d_num_runs_out</span><span class="p">;</span><span class="w">    </span><span class="c1">// e.g., [-]</span>
<span class="n">CustomMin</span><span class="w">    </span><span class="n">reduction_op</span><span class="p">;</span>
<span class="p">...</span>

<span class="c1">// Determine temporary device storage requirements</span>
<span class="kt">void</span><span class="w">     </span><span class="o">*</span><span class="n">d_temp_storage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="kt">size_t</span><span class="w">   </span><span class="n">temp_storage_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ReduceByKey</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span>
<span class="w">  </span><span class="n">d_keys_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_unique_out</span><span class="p">,</span><span class="w"> </span><span class="n">d_values_in</span><span class="p">,</span>
<span class="w">  </span><span class="n">d_aggregates_out</span><span class="p">,</span><span class="w"> </span><span class="n">d_num_runs_out</span><span class="p">,</span><span class="w"> </span><span class="n">reduction_op</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// Allocate temporary storage</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">);</span>

<span class="c1">// Run reduce-by-key</span>
<span class="n">cub</span><span class="o">::</span><span class="n">DeviceReduce</span><span class="o">::</span><span class="n">ReduceByKey</span><span class="p">(</span>
<span class="w">  </span><span class="n">d_temp_storage</span><span class="p">,</span><span class="w"> </span><span class="n">temp_storage_bytes</span><span class="p">,</span>
<span class="w">  </span><span class="n">d_keys_in</span><span class="p">,</span><span class="w"> </span><span class="n">d_unique_out</span><span class="p">,</span><span class="w"> </span><span class="n">d_values_in</span><span class="p">,</span>
<span class="w">  </span><span class="n">d_aggregates_out</span><span class="p">,</span><span class="w"> </span><span class="n">d_num_runs_out</span><span class="p">,</span><span class="w"> </span><span class="n">reduction_op</span><span class="p">,</span><span class="w"> </span><span class="n">num_items</span><span class="p">);</span>

<span class="c1">// d_unique_out      &lt;-- [0, 2, 9, 5, 8]</span>
<span class="c1">// d_aggregates_out  &lt;-- [0, 1, 6, 2, 4]</span>
<span class="c1">// d_num_runs_out    &lt;-- [5]</span>
</pre></div>
</div>
</section>
</p>
<dl class="field-list simple">
<dt class="field-odd">Template Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>KeysInputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input keys (may be a simple pointer type)</p></li>
<li><p><strong>UniqueOutputIteratorT</strong> – <strong>[inferred]</strong> Random-access output iterator type for writing unique output keys (may be a simple pointer type)</p></li>
<li><p><strong>ValuesInputIteratorT</strong> – <strong>[inferred]</strong> Random-access input iterator type for reading input values (may be a simple pointer type)</p></li>
<li><p><strong>AggregatesOutputIterator</strong> – <strong>[inferred]</strong> Random-access output iterator type for writing output value aggregates (may be a simple pointer type)</p></li>
<li><p><strong>NumRunsOutputIteratorT</strong> – <strong>[inferred]</strong> Output iterator type for recording the number of runs encountered (may be a simple pointer type)</p></li>
<li><p><strong>ReductionOpT</strong> – <strong>[inferred]</strong> Binary reduction functor type having member <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">operator()(const</span> <span class="pre">T</span> <span class="pre">&amp;a,</span> <span class="pre">const</span> <span class="pre">T</span> <span class="pre">&amp;b)</span></code></p></li>
<li><p><strong>NumItemsT</strong> – <strong>[inferred]</strong> Type of num_items</p></li>
</ul>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>d_temp_storage</strong> – <strong>[in]</strong> Device-accessible allocation of temporary storage. When <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>, the required allocation size is written to <code class="docutils literal notranslate"><span class="pre">temp_storage_bytes</span></code> and no work is done.</p></li>
<li><p><strong>temp_storage_bytes</strong> – <strong>[inout]</strong> Reference to size in bytes of <code class="docutils literal notranslate"><span class="pre">d_temp_storage</span></code> allocation</p></li>
<li><p><strong>d_keys_in</strong> – <strong>[in]</strong> Pointer to the input sequence of keys</p></li>
<li><p><strong>d_unique_out</strong> – <strong>[out]</strong> Pointer to the output sequence of unique keys (one key per run)</p></li>
<li><p><strong>d_values_in</strong> – <strong>[in]</strong> Pointer to the input sequence of corresponding values</p></li>
<li><p><strong>d_aggregates_out</strong> – <strong>[out]</strong> Pointer to the output sequence of value aggregates (one aggregate per run)</p></li>
<li><p><strong>d_num_runs_out</strong> – <strong>[out]</strong> Pointer to total number of runs encountered (i.e., the length of <code class="docutils literal notranslate"><span class="pre">d_unique_out</span></code>)</p></li>
<li><p><strong>reduction_op</strong> – <strong>[in]</strong> Binary reduction functor</p></li>
<li><p><strong>num_items</strong> – <strong>[in]</strong> Total number of associated key+value pairs (i.e., the length of <code class="docutils literal notranslate"><span class="pre">d_in_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">d_in_values</span></code>)</p></li>
<li><p><strong>stream</strong> – <strong>[in]</strong> <p><p><strong>[optional]</strong> CUDA stream to launch kernels within. Default is stream<sub>0</sub>.</p>
</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</dd></dl>

</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="structcub_1_1DeviceRadixSort.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">cub::DeviceRadixSort</p>
      </div>
    </a>
    <a class="right-next"
       href="structcub_1_1DeviceRleDispatch.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">cub::DeviceRleDispatch</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            


              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4N3cub12DeviceReduceE"><code class="docutils literal notranslate"><span class="pre">cub::DeviceReduce</span></code></a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I00000EN3cub12DeviceReduce6ReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">Reduce()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I000000EN3cub12DeviceReduce6ReduceE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT1T4EnvT"><code class="docutils literal notranslate"><span class="pre">Reduce()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0000EN3cub12DeviceReduce3SumE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT"><code class="docutils literal notranslate"><span class="pre">Sum()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I000EN3cub12DeviceReduce3SumE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">Sum()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I000EN3cub12DeviceReduce3MinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">Min()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0000EN3cub12DeviceReduce3MinE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT"><code class="docutils literal notranslate"><span class="pre">Min()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">ArgMin()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMinE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT"><code class="docutils literal notranslate"><span class="pre">ArgMin()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I00EN3cub12DeviceReduce6ArgMinE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">ArgMin()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I000EN3cub12DeviceReduce3MaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">Max()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0000EN3cub12DeviceReduce3MaxE11cudaError_t14InputIteratorT15OutputIteratorT9NumItemsT4EnvT"><code class="docutils literal notranslate"><span class="pre">Max()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I000EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">ArgMax()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I00EN3cub12DeviceReduce6ArgMaxE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorTi12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">ArgMax()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0000EN3cub12DeviceReduce6ArgMaxE11cudaError_t14InputIteratorT20ExtremumOutIteratorT17IndexOutIteratorTN4cudaSt7int64_tE4EnvT"><code class="docutils literal notranslate"><span class="pre">ArgMax()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I000000EN3cub12DeviceReduce15TransformReduceE11cudaError_tPvR6size_t14InputIteratorT15OutputIteratorT9NumItemsT12ReductionOpT12TransformOpT1T12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">TransformReduce()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#_CPPv4I0000000EN3cub12DeviceReduce11ReduceByKeyE11cudaError_tPvR6size_t18KeysInputIteratorT21UniqueOutputIteratorT20ValuesInputIteratorT25AggregatesOutputIteratorT22NumRunsOutputIteratorT12ReductionOpT9NumItemsT12cudaStream_t"><code class="docutils literal notranslate"><span class="pre">ReduceByKey()</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  

  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright © 2026, NVIDIA Corporation.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 9.1.0.
    <br/>
  </p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>