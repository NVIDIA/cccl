

<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>CUB Benchmarks &#8212; CUDA Core Compute Libraries</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/nvidia-sphinx-theme.css?v=933278ad" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />



    <script src="../_static/documentation_options.js?v=bbe6ed3a"></script>
    <script src="../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=5ceeb459"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'cub/benchmarking';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://NVIDIA.github.io/cccl/nv-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'unstable';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>

    <link rel="canonical" href="https://NVIDIA.github.io/cccl/cub/benchmarking.html" />
    <link rel="icon" href="../_static/favicon.png"/>

    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CUB Tunings" href="tuning.html" />
    <link rel="prev" title="CUB Tests" href="test_overview.html" />


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="unstable" />


  </head>

  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>


  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="CUDA Core Compute Libraries - Home"/>
    <img src="../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="CUDA Core Compute Libraries - Home"/>
  
  
    <p class="title logo__title">CUDA Core Compute Libraries</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/NVIDIA/cccl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="CUDA Core Compute Libraries - Home"/>
    <img src="../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="CUDA Core Compute Libraries - Home"/>
  
  
    <p class="title logo__title">CUDA Core Compute Libraries</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/NVIDIA/cccl" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../cpp.html">CUDA C++ Core Libraries</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../libcudacxx/index.html">libcu++</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../libcudacxx/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../libcudacxx/setup.html">Setup</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/setup/requirements.html">Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/setup/getting.html">Getting libcu++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/setup/building_and_testing.html">Building &amp; Testing libcu++</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../libcudacxx/releases.html">Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/releases/changelog.html">Changelog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/releases/versioning.html">Versioning</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../libcudacxx/standard_api.html">Standard API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/algorithms_library.html">Algorithms Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/c_library.html">C Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/concepts_library.html">Concepts Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/container_library.html">Container Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/execution_library.html">Execution Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/numerics_library.html">Numerics Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/ranges_library.html">Ranges Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/synchronization_library.html">Synchronization Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/time_library.html">Time Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/type_support.html">Type Support Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/standard_api/utility_library.html">Utility Library</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../libcudacxx/extended_api.html">Extended API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/bit.html">Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/execution_model.html">Execution model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/exceptions.html">Exception Handling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/memory_model.html">Memory model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/thread_groups.html">Thread Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/synchronization_primitives.html">Synchronization Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/asynchronous_operations.html">Asynchronous Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/memory_access_properties.html">Memory access properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/functional.html">Functional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/iterators.html">Fancy Iterators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/type_traits.html">Type traits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/vector_tuple_protocol.html">Vector Tuple Protocol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/numeric.html">Numeric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/random.html">Random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/memory.html">Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/memory_resource.html">Memory Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/math.html">Math</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/mdspan.html">Mdspan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/tma.html">Tensor Memory Accelerator (TMA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/warp.html">Warp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/utility.html">Utility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/extended_api/work_stealing.html">Work stealing</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../libcudacxx/runtime.html">Runtime</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/cudart_interactions.html">CUDA Runtime interactions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/stream.html">Streams</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/event.html">Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/algorithm.html">Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/device.html">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/hierarchy.html">Hierarchy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/launch.html">Launch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/buffer.html">Buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/memory_pools.html">Memory Pools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/runtime/legacy_resources.html">Legacy resources</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../libcudacxx/ptx_api.html">PTX API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/ptx/examples.html">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/ptx/instructions.html">PTX Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/ptx/pragmas.html">PTX Pragmas</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../libcudacxx/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="index.html">CUB</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="index.html">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="test_overview.html">CUB Tests</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">CUB Benchmarks</a></li>
<li class="toctree-l3"><a class="reference internal" href="tuning.html">CUB Tunings</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="developer_overview.html">CUB Developer Overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="developer/thread_level.html">Thread-level</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer/warp_level.html">Warp-level</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer/block_scope.html">Block-scope</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer/device_scope.html">Device-scope</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer/nvtx.html">NVTX</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="releases.html">CUB Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="releases/changelog.html">CUB 2.1.0</a></li>


















































</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="api.html">API documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="api_docs/thread_level.html">Thread-level Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_docs/warp_wide.html">Warp-Wide “Collective” Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_docs/block_wide.html">Block-Wide “Collective” Primitives</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_docs/device_wide.html">Device-Wide Primitives</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="api/index.html">API reference</a></li>
</ul>
</details></li>










<li class="toctree-l2 has-children"><a class="reference internal" href="../thrust/index.html">Thrust</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../thrust/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../thrust/developer_overview.html">Thrust Developer Overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../thrust/developer/cmake_options.html">Developer CMake Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/developer/systems.html">Thrust systems</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../thrust/releases.html">Releases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../thrust/releases/changelog.html">Changelog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/releases/versioning.html">Versioning</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../thrust/release_process.html">Release Process</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../thrust/api.html">API documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/algorithms.html">Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/containers.html">Containers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/function_objects.html">Function Objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/iterators.html">Iterators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/memory_management.html">Memory Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/numerics.html">Numerics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/parallel_execution_policies.html">Parallel Execution Policies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/random.html">Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/system.html">System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../thrust/api_docs/utility.html">Utility</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../thrust/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cudax/index.html">CUDA Experimental</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../cudax/index.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../cudax/container.html">Containers library</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/classcuda_1_1experimental_1_1uninitialized__buffer.html">cuda::experimental::uninitialized_buffer</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../cudax/memory_resource.html">Memory Resources</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/api/classcuda_1_1mr_1_1basic__any__resource.html">cuda::mr::basic_any_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/api/structcuda_1_1memory__pool__properties.html">cuda::memory_pool_properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/api/structcuda_1_1device__memory__pool.html">cuda::device_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/api/structcuda_1_1pinned__memory__pool.html">cuda::pinned_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/api/structcuda_1_1managed__memory__pool.html">cuda::managed_memory_pool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/api/classcuda_1_1mr_1_1legacy__pinned__memory__resource.html">cuda::mr::legacy_pinned_memory_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/api/classcuda_1_1mr_1_1legacy__managed__memory__resource.html">cuda::mr::legacy_managed_memory_resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../libcudacxx/api/structcuda_1_1mr_1_1shared__resource.html">cuda::mr::shared_resource</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../cudax/graph.html">Graphs library</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/structcuda_1_1experimental_1_1graph.html">cuda::experimental::graph</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/structcuda_1_1experimental_1_1graph__builder.html">cuda::experimental::graph_builder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/structcuda_1_1experimental_1_1graph__builder__ref.html">cuda::experimental::graph_builder_ref</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/structcuda_1_1experimental_1_1graph__node__ref.html">cuda::experimental::graph_node_ref</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of.html">cuda::experimental::stf::graphed_interface_of</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01mdspan_3_01T_00_01P_8_8_8_01_4_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; mdspan&lt; T, P… &gt; &gt;</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01scalar__view_3_01T_01_4_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; scalar_view&lt; T &gt; &gt;</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cudax/api/structcuda_1_1experimental_1_1stf_1_1graphed__interface__of_3_01void__interface_01_4.html">cuda::experimental::stf::graphed_interface_of&lt; void_interface &gt;</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../cudax/stf.html">CUDASTF</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../cudax/stf/custom_data_interface.html">Implementation of the <code class="docutils literal notranslate"><span class="pre">matrix</span></code> class</a></li>





<li class="toctree-l4"><a class="reference internal" href="../cudax/stf/lower_level_api.html">Lower-level API</a></li>

</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../cudax/api/index.html">API reference</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../cccl/tma.html">Tensor Memory Accelerator (TMA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cccl/3.0_migration_guide.html">CCCL 2.x ‐ CCCL 3.0 migration guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cccl/development/index.html">CCCL Development Guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../cccl/development/macro.html">CCCL Internal Macros</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cccl/development/testing.html">CCCL Testing Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cccl/development/build_and_bisect_tools.html">Build and Bisect Utilities</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../cccl/development/visibility.html">Symbol Visibility</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../cccl/development/visibility/host_stub_visibility.html">Host Stub Visibility Issue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cccl/development/visibility/device_kernel_visibility.html">Device Kernel Visibility Issue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cccl/development/visibility/different_architectures.html">Linking TUs compiled with different architectures</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cccl/contributing.html">Contributing to the CUDA Core Compute Libraries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../cccl/contributing/code_of_conduct.html">Code of Conduct</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../cccl/license.html">License</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../python/index.html">CCCL Python Libraries</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../python/setup.html">Setup and Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/compute.html"><code class="docutils literal notranslate"><span class="pre">cuda.compute</span></code>: Parallel Computing Primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/coop.html"><code class="docutils literal notranslate"><span class="pre">cuda.coop</span></code>: Cooperative Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/resources.html">Resources</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../python/api_reference.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/compute_api.html"><code class="docutils literal notranslate"><span class="pre">cuda.compute</span></code> API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/coop_api.html"><code class="docutils literal notranslate"><span class="pre">cuda.coop</span></code> API Reference</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../cpp.html" class="nav-link">CUDA C++ Core Libraries</a></li>
    
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">CUB</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">CUB Benchmarks</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="cub-benchmarks">
<h1>CUB Benchmarks<a class="headerlink" href="#cub-benchmarks" title="Link to this heading">#</a></h1>
<p>CUB comes with a set of <a class="reference external" href="https://github.com/NVIDIA/nvbench">NVBench</a>-based benchmarks for its algorithms,
which can be used to measure the performance of CUB on your system on a variety of workloads.
The integration with NVBench allows to archive and compare benchmark results,
which is useful for continuous performance testing, detecting regressions, tuning, and optimization.
This guide gives an introduction into CUB’s benchmarking infrastructure.</p>
<section id="building-benchmarks">
<h2>Building benchmarks<a class="headerlink" href="#building-benchmarks" title="Link to this heading">#</a></h2>
<p>CUB benchmarks are build as part of the CCCL CMake infrastructure.
Starting from scratch:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/NVIDIA/cccl.git
<span class="nb">cd</span><span class="w"> </span>cccl
mkdir<span class="w"> </span>build
<span class="nb">cd</span><span class="w"> </span>build
cmake<span class="w"> </span>..<span class="w"> </span>--preset<span class="o">=</span>cub-benchmark
</pre></div>
</div>
<p>You clone the repository, create a build directory and configure the build with CMake.
The preset <cite>cub-benchmark</cite> takes care of everything.</p>
<p>We use Ninja as CMake generator in this guide, but you can use any other generator you prefer.</p>
<p>You can then proceed to build the benchmarks.</p>
<p>You can list the available cmake build targets with, if you intend to only build selected benchmarks:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ninja<span class="w"> </span>-t<span class="w"> </span>targets<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span><span class="s1">&#39;\.bench\.&#39;</span>
cub.bench.adjacent_difference.subtract_left.base:<span class="w"> </span>phony
cub.bench.copy.memcpy.base:<span class="w"> </span>phony
...
cub.bench.transform.babelstream3.base:<span class="w"> </span>phony
cub.bench.transform_reduce.sum.base:<span class="w"> </span>phony
</pre></div>
</div>
<p>We also provide a target to build all benchmarks:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ninja<span class="w"> </span>cub.all.benches
</pre></div>
</div>
</section>
<section id="running-a-benchmark">
<span id="cub-benchmarking-running"></span><h2>Running a benchmark<a class="headerlink" href="#running-a-benchmark" title="Link to this heading">#</a></h2>
<p>After we built a benchmark, we can run it as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./bin/cub.bench.adjacent_difference.subtract_left.base<span class="se">\</span>
<span class="w">    </span>-d<span class="w"> </span><span class="m">0</span><span class="se">\</span>
<span class="w">    </span>--stopping-criterion<span class="w"> </span>entropy<span class="se">\</span>
<span class="w">    </span>--json<span class="w"> </span>base.json<span class="se">\</span>
<span class="w">    </span>--md<span class="w"> </span>base.md
</pre></div>
</div>
<p>In this command, <cite>-d 0</cite> indicates that we want to run on GPU 0 on our system.
Setting <cite>–stopping-criterion entropy</cite> is advisable since it reduces runtime
and increase confidence in the resulting data.
It’s not set as default yet, because NVBench is still evaluating it.
By default, NVBench will print the benchmark results to the terminal as Markdown.
<cite>–json base.json</cite> will save the detailed results in a JSON file as well for later use.
<cite>–md base.md</cite> will save the Markdown output to a file as well,
so you can easily view the results later without having to parse the JSON.
More information on what command line options are available can be found in the
<a class="reference external" href="https://github.com/NVIDIA/nvbench/blob/main/docs/cli_help.md">NVBench documentation</a>.</p>
<p>The expected terminal output is something along the following lines (also saved to <cite>base.md</cite>),
shortened for brevity:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Log</span>
Run:<span class="w">  </span><span class="o">[</span><span class="m">1</span>/8<span class="o">]</span><span class="w"> </span>base<span class="w"> </span><span class="o">[</span><span class="nv">Device</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>T<span class="o">{</span>ct<span class="o">}=</span>I32<span class="w"> </span>OffsetT<span class="o">{</span>ct<span class="o">}=</span>I32<span class="w"> </span>Elements<span class="o">{</span>io<span class="o">}=</span><span class="m">2</span>^16<span class="o">]</span>
Pass:<span class="w"> </span>Cold:<span class="w"> </span><span class="m">0</span>.004571ms<span class="w"> </span>GPU,<span class="w"> </span><span class="m">0</span>.009322ms<span class="w"> </span>CPU,<span class="w"> </span><span class="m">0</span>.00s<span class="w"> </span>total<span class="w"> </span>GPU,<span class="w"> </span><span class="m">0</span>.01s<span class="w"> </span>total<span class="w"> </span>wall,<span class="w"> </span>334x
Run:<span class="w">  </span><span class="o">[</span><span class="m">2</span>/8<span class="o">]</span><span class="w"> </span>base<span class="w"> </span><span class="o">[</span><span class="nv">Device</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>T<span class="o">{</span>ct<span class="o">}=</span>I32<span class="w"> </span>OffsetT<span class="o">{</span>ct<span class="o">}=</span>I32<span class="w"> </span>Elements<span class="o">{</span>io<span class="o">}=</span><span class="m">2</span>^20<span class="o">]</span>
Pass:<span class="w"> </span>Cold:<span class="w"> </span><span class="m">0</span>.015161ms<span class="w"> </span>GPU,<span class="w"> </span><span class="m">0</span>.023367ms<span class="w"> </span>CPU,<span class="w"> </span><span class="m">0</span>.01s<span class="w"> </span>total<span class="w"> </span>GPU,<span class="w"> </span><span class="m">0</span>.02s<span class="w"> </span>total<span class="w"> </span>wall,<span class="w"> </span>430x
...
<span class="c1"># Benchmark Results</span>
<span class="p">|</span><span class="w"> </span>T<span class="o">{</span>ct<span class="o">}</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>OffsetT<span class="o">{</span>ct<span class="o">}</span><span class="w"> </span><span class="p">|</span><span class="w">   </span>Elements<span class="o">{</span>io<span class="o">}</span><span class="w">   </span><span class="p">|</span><span class="w"> </span>Samples<span class="w"> </span><span class="p">|</span><span class="w">  </span>CPU<span class="w"> </span>Time<span class="w">  </span><span class="p">|</span><span class="w">  </span>Noise<span class="w">  </span><span class="p">|</span><span class="w">  </span>GPU<span class="w"> </span>Time<span class="w">  </span><span class="p">|</span><span class="w"> </span>Noise<span class="w">  </span><span class="p">|</span><span class="w"> </span>Elem/s<span class="w">  </span><span class="p">|</span><span class="w"> </span>GlobalMem<span class="w"> </span>BW<span class="w"> </span><span class="p">|</span><span class="w"> </span>BWUtil<span class="w"> </span><span class="p">|</span>
<span class="p">|</span>-------<span class="p">|</span>-------------<span class="p">|</span>------------------<span class="p">|</span>---------<span class="p">|</span>------------<span class="p">|</span>---------<span class="p">|</span>------------<span class="p">|</span>--------<span class="p">|</span>---------<span class="p">|</span>--------------<span class="p">|</span>--------<span class="p">|</span>
<span class="p">|</span><span class="w">   </span>I32<span class="w"> </span><span class="p">|</span><span class="w">         </span>I32<span class="w"> </span><span class="p">|</span><span class="w">     </span><span class="m">2</span>^16<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">65536</span><span class="w"> </span><span class="p">|</span><span class="w">    </span>334x<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">9</span>.322<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">104</span>.44%<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">4</span>.571<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">10</span>.87%<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">14</span>.337G<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">114</span>.696<span class="w"> </span>GB/s<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">14</span>.93%<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span>I32<span class="w"> </span><span class="p">|</span><span class="w">         </span>I32<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">2</span>^20<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1048576</span><span class="w"> </span><span class="p">|</span><span class="w">    </span>430x<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">23</span>.367<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">327</span>.68%<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">15</span>.161<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">3</span>.47%<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">69</span>.161G<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">553</span>.285<span class="w"> </span>GB/s<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">72</span>.03%<span class="w"> </span><span class="p">|</span>
...
</pre></div>
</div>
<p>If you are only interested in a subset of workloads, you can restrict benchmarking as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./bin/cub.bench.adjacent_difference.subtract_left.base<span class="w"> </span>...<span class="se">\</span>
<span class="w">    </span>-a<span class="w"> </span><span class="s1">&#39;T{ct}=I32&#39;</span><span class="se">\</span>
<span class="w">    </span>-a<span class="w"> </span><span class="s1">&#39;OffsetT{ct}=I32&#39;</span><span class="se">\</span>
<span class="w">    </span>-a<span class="w"> </span><span class="s1">&#39;Elements{io}[pow2]=[24,28]&#39;</span><span class="se">\</span>
</pre></div>
</div>
<p>The <cite>-a</cite> option allows you to restrict the values for each axis available for the benchmark.
See the <a class="reference external" href="https://github.com/NVIDIA/nvbench/blob/main/docs/cli_help_axis.md">NVBench documentation</a>.
for more information on how to specify the axis values.
If the specified axis does not exist, the benchmark will terminate with an error.</p>
</section>
<section id="comparing-benchmark-results">
<span id="cub-benchmarking-comparing"></span><h2>Comparing benchmark results<a class="headerlink" href="#comparing-benchmark-results" title="Link to this heading">#</a></h2>
<p>Let’s say you have a modification that you’d like to benchmark.
To compare the performance you have to build and run the benchmark as described above for the unmodified code,
saving the results to a JSON file, e.g. <cite>base.json</cite>.
Then, you apply your code changes (e.g., switch to a different branch, git stash pop, apply a patch file, etc.),
rebuild and rerun the benchmark, saving the results to a different JSON file, e.g. <cite>new.json</cite>.</p>
<p>You can now compare the two result JSON files using, assuming you are still in your build directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">PYTHONPATH</span><span class="o">=</span>./_deps/nvbench-src/scripts<span class="w"> </span>./_deps/nvbench-src/scripts/nvbench_compare.py<span class="w"> </span>base.json<span class="w"> </span>new.json
</pre></div>
</div>
<p>The <cite>PYTHONPATH</cite> environment variable may not be necessary in all cases.
The script will print a Markdown report showing the runtime differences between each variant of the two benchmark run.
This could look like this, again shortened for brevity:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="p">|</span><span class="w">  </span>T<span class="o">{</span>ct<span class="o">}</span><span class="w">  </span><span class="p">|</span><span class="w">  </span>OffsetT<span class="o">{</span>ct<span class="o">}</span><span class="w">  </span><span class="p">|</span><span class="w">  </span>Elements<span class="o">{</span>io<span class="o">}</span><span class="w">  </span><span class="p">|</span><span class="w">   </span>Ref<span class="w"> </span>Time<span class="w"> </span><span class="p">|</span><span class="w">   </span>Ref<span class="w"> </span>Noise<span class="w"> </span><span class="p">|</span><span class="w">   </span>Cmp<span class="w"> </span>Time<span class="w"> </span><span class="p">|</span><span class="w">   </span>Cmp<span class="w"> </span>Noise<span class="w"> </span><span class="p">|</span><span class="w">       </span>Diff<span class="w"> </span><span class="p">|</span><span class="w">   </span>%Diff<span class="w"> </span><span class="p">|</span><span class="w">  </span>Status<span class="w">  </span><span class="p">|</span>
<span class="p">|</span>---------<span class="p">|</span>---------------<span class="p">|</span>----------------<span class="p">|</span>------------<span class="p">|</span>-------------<span class="p">|</span>------------<span class="p">|</span>-------------<span class="p">|</span>------------<span class="p">|</span>---------<span class="p">|</span>----------<span class="p">|</span>
<span class="p">|</span><span class="w">   </span>I32<span class="w">   </span><span class="p">|</span><span class="w">      </span>I32<span class="w">      </span><span class="p">|</span><span class="w">      </span><span class="m">2</span>^16<span class="w">      </span><span class="p">|</span><span class="w">   </span><span class="m">4</span>.571<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w">      </span><span class="m">10</span>.87%<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">4</span>.096<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w">       </span><span class="m">0</span>.00%<span class="w"> </span><span class="p">|</span><span class="w">  </span>-0.475<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w"> </span>-10.39%<span class="w"> </span><span class="p">|</span><span class="w">   </span>FAIL<span class="w">   </span><span class="p">|</span>
<span class="p">|</span><span class="w">   </span>I32<span class="w">   </span><span class="p">|</span><span class="w">      </span>I32<span class="w">      </span><span class="p">|</span><span class="w">      </span><span class="m">2</span>^20<span class="w">      </span><span class="p">|</span><span class="w">  </span><span class="m">15</span>.161<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w">       </span><span class="m">3</span>.47%<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">15</span>.143<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w">       </span><span class="m">3</span>.55%<span class="w"> </span><span class="p">|</span><span class="w">  </span>-0.018<span class="w"> </span>us<span class="w"> </span><span class="p">|</span><span class="w">  </span>-0.12%<span class="w"> </span><span class="p">|</span><span class="w">   </span>PASS<span class="w">   </span><span class="p">|</span>
...
</pre></div>
</div>
<p>In addition to showing the absolute and relative runtime difference,
NVBench reports the noise of the measurements,
which corresponds to the relative standard deviation.
It then reports with statistical significance in the <cite>Status</cite> column
how the runtime changed from the base to the new version.</p>
</section>
<section id="running-all-benchmarks-directly-from-the-command-line">
<h2>Running all benchmarks directly from the command line<a class="headerlink" href="#running-all-benchmarks-directly-from-the-command-line" title="Link to this heading">#</a></h2>
<p>To get a full snapshot of CUB’s performance, you can run all benchmarks and save the results.
For example, inside a build directory you can run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ninja<span class="w"> </span>cub.all.benches
<span class="nv">benchmarks</span><span class="o">=</span><span class="k">$(</span>ls<span class="w"> </span>bin<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>cub.bench<span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="k">$(</span><span class="nb">echo</span><span class="w"> </span><span class="nv">$benchmarks</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>wc<span class="w"> </span>-w<span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="nv">i</span><span class="o">=</span><span class="m">1</span><span class="p">;</span><span class="w"> </span><span class="se">\</span>
<span class="k">for</span><span class="w"> </span>b<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nv">$benchmarks</span><span class="p">;</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;=== Running </span><span class="nv">$b</span><span class="s2"> (</span><span class="nv">$i</span><span class="s2">/</span><span class="nv">$n</span><span class="s2">) ===&quot;</span><span class="p">;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./bin/<span class="nv">$b</span><span class="w"> </span>-d<span class="w"> </span><span class="m">0</span><span class="w"> </span>--stopping-criterion<span class="w"> </span>entropy<span class="w"> </span>--json<span class="w"> </span><span class="nv">$b</span>.json<span class="w"> </span>--md<span class="w"> </span><span class="nv">$b</span>.md<span class="p">;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="o">((</span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="se">\</span>
<span class="k">done</span>
</pre></div>
</div>
<p>This will generate one JSON and one Markdown file for each benchmark.
You can archive those files for later comparison or analysis.</p>
</section>
<section id="running-all-benchmarks-via-tuning-scripts-alternative">
<h2>Running all benchmarks via tuning scripts (alternative)<a class="headerlink" href="#running-all-benchmarks-via-tuning-scripts-alternative" title="Link to this heading">#</a></h2>
<p>The benchmark suite can also be run using the <a class="reference internal" href="tuning.html#cub-tuning"><span class="std std-ref">tuning</span></a> infrastructure.
The tuning infrastructure handles building benchmarks itself, because it records the build times.
Therefore, it’s critical that you run it in a clean build directory without any build artifacts.
Running cmake is enough. Alternatively, you can also clean your build directory.
Furthermore, the tuning scripts require some additional python dependencies, which you have to install:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ninja<span class="w"> </span>clean
pip<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>fpzip<span class="w"> </span>pandas<span class="w"> </span>scipy
</pre></div>
</div>
<p>To select the appropriate CUDA GPU, first identify the GPU ID by running <cite>nvidia-smi</cite>, then set the
desired GPU using <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#cuda-environment-variables">export CUDA_VISIBLE_DEVICES=x</a>,
where <cite>x</cite> is the ID of the GPU you want to use (e.g., <cite>1</cite>).
This ensures your application uses only the specified GPU.
We can then run the full benchmark suite from the build directory with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="c1"># or any other GPU ID</span>
<span class="nv">PYTHONPATH</span><span class="o">=</span>../benchmarks/scripts<span class="w"> </span>../benchmarks/scripts/run.py
</pre></div>
</div>
<p>You can expect the output to look like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>RUNNING<span class="w"> </span>bench
ctk:<span class="w">  </span><span class="m">12</span>.2.140
cub:<span class="w">  </span>812ba98d1
<span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>PERF<span class="w"> </span>cub_bench_adjacent_difference_subtract_left_base_T_ct__I32___OffsetT_ct__I32___Elements_io__pow2__16<span class="w"> </span><span class="m">4</span>.095999884157209e-06<span class="w"> </span>-sec
<span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>PERF<span class="w"> </span>cub_bench_adjacent_difference_subtract_left_base_T_ct__I32___OffsetT_ct__I32___Elements_io__pow2__20<span class="w"> </span><span class="m">1</span>.2288000107218977e-05<span class="w"> </span>-sec
<span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>PERF<span class="w"> </span>cub_bench_adjacent_difference_subtract_left_base_T_ct__I32___OffsetT_ct__I32___Elements_io__pow2__24<span class="w"> </span><span class="m">0</span>.00016998399223666638<span class="w"> </span>-sec
<span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>PERF<span class="w"> </span>cub_bench_adjacent_difference_subtract_left_base_T_ct__I32___OffsetT_ct__I32___Elements_io__pow2__28<span class="w"> </span><span class="m">0</span>.002673664130270481<span class="w"> </span>-sec
...
</pre></div>
</div>
<p>The tuning infrastructure will build and execute all benchmarks and their variants one after each other,
reporting the time in seconds it took to execute the benchmarked region.</p>
<p>It’s also possible to benchmark a subset of algorithms and workloads, by running in a build directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="c1"># or any other GPU ID</span>
<span class="nv">PYTHONPATH</span><span class="o">=</span>../benchmarks/scripts<span class="w"> </span>../benchmarks/scripts/run.py<span class="w"> </span>-R<span class="w"> </span><span class="s1">&#39;.*scan.exclusive.sum.*&#39;</span><span class="w"> </span>-a<span class="w"> </span><span class="s1">&#39;Elements{io}[pow2]=[24,28]&#39;</span><span class="w"> </span>-a<span class="w"> </span><span class="s1">&#39;T{ct}=I32&#39;</span>
<span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>RUNNING<span class="w"> </span>bench
<span class="w"> </span>ctk:<span class="w">  </span><span class="m">12</span>.6.77
cccl:<span class="w">  </span>v2.7.0-rc0-265-g32aa6aa5a
<span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>PERF<span class="w"> </span>cub_bench_scan_exclusive_sum_base_T_ct__I32___OffsetT_ct__U32___Elements_io__pow2__28<span class="w"> </span><span class="m">0</span>.003194367978721857<span class="w"> </span>-sec
<span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>PERF<span class="w"> </span>cub_bench_scan_exclusive_sum_base_T_ct__I32___OffsetT_ct__U64___Elements_io__pow2__28<span class="w"> </span><span class="m">0</span>.00319383991882205<span class="w"> </span>-sec
<span class="o">&amp;&amp;&amp;&amp;</span><span class="w"> </span>PASSED<span class="w"> </span>bench
</pre></div>
</div>
<p>The <cite>-R</cite> option allows you to specify a regular expression for selecting benchmarks.
The <cite>-a</cite> restricts the values for an axis across all benchmarks
See the <a class="reference external" href="https://github.com/NVIDIA/nvbench/blob/main/docs/cli_help_axis.md">NVBench documentation</a>.
for more information on how to specify the axis values.
Contrary to running a benchmark directly,
the tuning infrastructure will just ignore an axis value if a benchmark does not support,
run the benchmark regardless, and continue.</p>
<p>The tuning infrastructure stores results in an SQLite database called <code class="code docutils literal notranslate"><span class="pre">cccl_meta_bench.db</span></code> in the build directory.
This database persists across tuning runs.
If you interrupt the benchmark script and then launch it again, only missing benchmark variants will be run.</p>
</section>
<section id="comparing-results-of-multiple-tuning-databases">
<h2>Comparing results of multiple tuning databases<a class="headerlink" href="#comparing-results-of-multiple-tuning-databases" title="Link to this heading">#</a></h2>
<p>Benchmark results captured in different tuning databases can be compared as well:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&lt;cccl_git_root&gt;/benchmarks/scripts/compare.py<span class="w"> </span>-o<span class="w"> </span>cccl_meta_bench1.db<span class="w"> </span>cccl_meta_bench2.db
</pre></div>
</div>
<p>This will print a Markdown report showing the runtime differences and noise for each variant.</p>
<p>Furthermore, you can plot the results, which requires additional python packages:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>fpzip<span class="w"> </span>pandas<span class="w"> </span>matplotlib<span class="w"> </span>seaborn<span class="w"> </span>tabulate<span class="w"> </span>PyQt5<span class="w"> </span>colorama
</pre></div>
</div>
<p>You can plot one or more tuning databases as a bar chart or a box plot (add <cite>–box</cite>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&lt;cccl_git_root&gt;/benchmarks/scripts/sol.py<span class="w"> </span>cccl_meta_bench.db<span class="w"> </span>...
</pre></div>
</div>
<p>This is useful to display the current performance of CUB as captured in a single tuning database,
or visually compare the performance of CUB across different tuning databases
(from different points in time, on different GPUs, etc.).</p>
</section>
<section id="dumping-benchmark-results-from-a-tuning-database">
<h2>Dumping benchmark results from a tuning database<a class="headerlink" href="#dumping-benchmark-results-from-a-tuning-database" title="Link to this heading">#</a></h2>
<p>The resulting database contains all samples, which can be extracted into JSON files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&lt;cccl_git_root&gt;/benchmarks/scripts/analyze.py<span class="w"> </span>-o<span class="w"> </span>./cccl_meta_bench.db
</pre></div>
</div>
<p>This will create a JSON file for each benchmark variant next to the database.
For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat<span class="w"> </span>cub_bench_scan_exclusive_sum_base_T_ct__I32___OffsetT_ct__U32___Elements_io__pow2__28.json
<span class="o">[</span>
<span class="w">  </span><span class="o">{</span>
<span class="w">    </span><span class="s2">&quot;variant&quot;</span>:<span class="w"> </span><span class="s2">&quot;base ()&quot;</span>,
<span class="w">    </span><span class="s2">&quot;elapsed&quot;</span>:<span class="w"> </span><span class="m">2</span>.6299014091,
<span class="w">    </span><span class="s2">&quot;center&quot;</span>:<span class="w"> </span><span class="m">0</span>.003194368,
<span class="w">    </span><span class="s2">&quot;bw&quot;</span>:<span class="w"> </span><span class="m">0</span>.8754671386,
<span class="w">    </span><span class="s2">&quot;samples&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">      </span><span class="m">0</span>.003152896,
<span class="w">      </span><span class="m">0</span>.0031549439,
<span class="w">      </span>...
<span class="w">    </span><span class="o">]</span>,
<span class="w">    </span><span class="s2">&quot;Elements{io}[pow2]&quot;</span>:<span class="w"> </span><span class="s2">&quot;28&quot;</span>,
<span class="w">    </span><span class="s2">&quot;base_samples&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">      </span><span class="m">0</span>.003152896,
<span class="w">      </span><span class="m">0</span>.0031549439,
<span class="w">      </span>...
<span class="w">    </span><span class="o">]</span>,
<span class="w">    </span><span class="s2">&quot;speedup&quot;</span>:<span class="w"> </span><span class="m">1</span>
<span class="w">  </span><span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
</section>
<section id="profiling-benchmarks-with-nsight-compute">
<h2>Profiling benchmarks with Nsight Compute<a class="headerlink" href="#profiling-benchmarks-with-nsight-compute" title="Link to this heading">#</a></h2>
<p>If you want to see profiling metrics on source code level,
you have to recompile your benchmarks with the <cite>-lineinfo</cite> option.
With cmake, you can just add <cite>-DCMAKE_CUDA_FLAGS=-lineinfo</cite> when invoking cmake in the <cite>build</cite> directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cmake<span class="w"> </span>..<span class="w"> </span>--preset<span class="o">=</span>cub-benchmark<span class="w"> </span>-DCMAKE_CUDA_FLAGS<span class="o">=</span>-lineinfo
</pre></div>
</div>
<p>To profile the kernels, use the <cite>ncu</cite> command.
A typical invocation, if you work on a remote cluster, could look like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ncu<span class="w"> </span>--set<span class="w"> </span>full<span class="w"> </span>--import-source<span class="w"> </span>yes<span class="w"> </span>-o<span class="w"> </span>base.ncu-rep<span class="w"> </span>-f<span class="w"> </span>./bin/thrust.bench.transform.basic.base<span class="w"> </span>-d<span class="w"> </span><span class="m">0</span><span class="w"> </span>--profile
</pre></div>
</div>
<p>The option <cite>–set full</cite> instructs <cite>ncu</cite> to collect all metrics.
This requires rerunning some kernels and takes more time.
<cite>–import-source yes</cite> imports the source code into the report file,
so you can see metrics not only in SASS but also in your source code,
even if you copy the resulting report away from the source code.
<cite>-o base.ncu-rep</cite> specifies the output file and <cite>-f</cite> overwrites the output file if it already exists.
<cite>–profile</cite> tells NVBench to run only one iteration, which speeds up profiling.</p>
<p>For inspecting the profiling report, we recommend using the GUI of Nsight Compute.
If you run on a remote machine, you may want to copy the report <cite>base.ncu-rep</cite> back to your local workstation,
before viewing the report using <cite>ncu-ui</cite>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>scp<span class="w"> </span>&lt;remote<span class="w"> </span>hostname&gt;:&lt;cccl<span class="w"> </span>repo<span class="w"> </span>directory&gt;/build/base.ncu-rep<span class="w"> </span>.
ncu-ui<span class="w"> </span>base.ncu-rep
</pre></div>
</div>
<p>The version of <cite>ncu-ui</cite> needs to be at least as high as the version of <cite>ncu</cite> used to create the report.</p>
</section>
<section id="authoring-benchmarks">
<h2>Authoring benchmarks<a class="headerlink" href="#authoring-benchmarks" title="Link to this heading">#</a></h2>
<p>CUB’s benchmarks serve a dual purpose.
They are used to measure and compare the performance of CUB and to tune CUB’s algorithms.
More information on how to create new benchmarks is provided in the <a class="reference internal" href="tuning.html#cub-tuning"><span class="std std-ref">CUB tuning guide</span></a>.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="test_overview.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">CUB Tests</p>
      </div>
    </a>
    <a class="right-next"
       href="tuning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">CUB Tunings</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            


              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-benchmarks">Building benchmarks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-a-benchmark">Running a benchmark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-benchmark-results">Comparing benchmark results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-all-benchmarks-directly-from-the-command-line">Running all benchmarks directly from the command line</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-all-benchmarks-via-tuning-scripts-alternative">Running all benchmarks via tuning scripts (alternative)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-results-of-multiple-tuning-databases">Comparing results of multiple tuning databases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dumping-benchmark-results-from-a-tuning-database">Dumping benchmark results from a tuning database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#profiling-benchmarks-with-nsight-compute">Profiling benchmarks with Nsight Compute</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#authoring-benchmarks">Authoring benchmarks</a></li>
</ul>
  </nav></div>

</div></div>
              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  

  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright © 2026, NVIDIA Corporation.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 9.1.0.
    <br/>
  </p>
</div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>