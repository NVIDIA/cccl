//===----------------------------------------------------------------------===//
//
// Part of libcu++, the C++ Standard Library for your entire system,
// under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES.
//
//===----------------------------------------------------------------------===//

#ifndef _LIBCUDACXX_ALGORITHM
#define _LIBCUDACXX_ALGORITHM

#include <cuda/std/detail/__config>

#if defined(_CCCL_IMPLICIT_SYSTEM_HEADER_GCC)
#  pragma GCC system_header
#elif defined(_CCCL_IMPLICIT_SYSTEM_HEADER_CLANG)
#  pragma clang system_header
#elif defined(_CCCL_IMPLICIT_SYSTEM_HEADER_MSVC)
#  pragma system_header
#endif // no system header

#include <cuda/std/__algorithm/adjacent_find.h>
#include <cuda/std/__algorithm/all_of.h>
#include <cuda/std/__algorithm/any_of.h>
#include <cuda/std/__algorithm/binary_search.h>
#include <cuda/std/__algorithm/clamp.h>
#include <cuda/std/__algorithm/comp.h>
#include <cuda/std/__algorithm/comp_ref_type.h>
#include <cuda/std/__algorithm/copy.h>
#include <cuda/std/__algorithm/copy_backward.h>
#include <cuda/std/__algorithm/copy_if.h>
#include <cuda/std/__algorithm/copy_n.h>
#include <cuda/std/__algorithm/count.h>
#include <cuda/std/__algorithm/count_if.h>
#include <cuda/std/__algorithm/equal.h>
#include <cuda/std/__algorithm/equal_range.h>
#include <cuda/std/__algorithm/fill.h>
#include <cuda/std/__algorithm/fill_n.h>
#include <cuda/std/__algorithm/find.h>
#include <cuda/std/__algorithm/find_end.h>
#include <cuda/std/__algorithm/find_first_of.h>
#include <cuda/std/__algorithm/find_if.h>
#include <cuda/std/__algorithm/find_if_not.h>
#include <cuda/std/__algorithm/for_each.h>
#include <cuda/std/__algorithm/for_each_n.h>
#include <cuda/std/__algorithm/generate.h>
#include <cuda/std/__algorithm/generate_n.h>
#include <cuda/std/__algorithm/half_positive.h>
#include <cuda/std/__algorithm/includes.h>
#include <cuda/std/__algorithm/is_heap.h>
#include <cuda/std/__algorithm/is_heap_until.h>
#include <cuda/std/__algorithm/is_partitioned.h>
#include <cuda/std/__algorithm/is_permutation.h>
#include <cuda/std/__algorithm/is_sorted.h>
#include <cuda/std/__algorithm/is_sorted_until.h>
#include <cuda/std/__algorithm/iter_swap.h>
#include <cuda/std/__algorithm/iterator_operations.h>
#include <cuda/std/__algorithm/lexicographical_compare.h>
#include <cuda/std/__algorithm/lower_bound.h>
#include <cuda/std/__algorithm/make_heap.h>
#include <cuda/std/__algorithm/make_projected.h>
#include <cuda/std/__algorithm/max.h>
#include <cuda/std/__algorithm/max_element.h>
#include <cuda/std/__algorithm/merge.h>
#include <cuda/std/__algorithm/min.h>
#include <cuda/std/__algorithm/min_element.h>
#include <cuda/std/__algorithm/minmax.h>
#include <cuda/std/__algorithm/minmax_element.h>
#include <cuda/std/__algorithm/mismatch.h>
#include <cuda/std/__algorithm/move.h>
#include <cuda/std/__algorithm/move_backward.h>
#include <cuda/std/__algorithm/next_permutation.h>
#include <cuda/std/__algorithm/none_of.h>
#include <cuda/std/__algorithm/partial_sort.h>
#include <cuda/std/__algorithm/partial_sort_copy.h>
#include <cuda/std/__algorithm/partition.h>
#include <cuda/std/__algorithm/partition_copy.h>
#include <cuda/std/__algorithm/partition_point.h>
#include <cuda/std/__algorithm/pop_heap.h>
#include <cuda/std/__algorithm/prev_permutation.h>
#include <cuda/std/__algorithm/push_heap.h>
#include <cuda/std/__algorithm/ranges_iterator_concept.h>
#include <cuda/std/__algorithm/ranges_min.h>
#include <cuda/std/__algorithm/ranges_min_element.h>
#include <cuda/std/__algorithm/remove.h>
#include <cuda/std/__algorithm/remove_copy.h>
#include <cuda/std/__algorithm/remove_copy_if.h>
#include <cuda/std/__algorithm/remove_if.h>
#include <cuda/std/__algorithm/replace.h>
#include <cuda/std/__algorithm/replace_copy.h>
#include <cuda/std/__algorithm/replace_copy_if.h>
#include <cuda/std/__algorithm/replace_if.h>
#include <cuda/std/__algorithm/reverse.h>
#include <cuda/std/__algorithm/reverse_copy.h>
#include <cuda/std/__algorithm/rotate.h>
#include <cuda/std/__algorithm/rotate_copy.h>
#include <cuda/std/__algorithm/sample.h>
#include <cuda/std/__algorithm/search.h>
#include <cuda/std/__algorithm/search_n.h>
#include <cuda/std/__algorithm/set_difference.h>
#include <cuda/std/__algorithm/set_intersection.h>
#include <cuda/std/__algorithm/set_symmetric_difference.h>
#include <cuda/std/__algorithm/set_union.h>
#include <cuda/std/__algorithm/shift_left.h>
#include <cuda/std/__algorithm/shift_right.h>
#include <cuda/std/__algorithm/shuffle.h>
#include <cuda/std/__algorithm/sift_down.h>
#include <cuda/std/__algorithm/sort.h>
#include <cuda/std/__algorithm/sort_heap.h>
#include <cuda/std/__algorithm/stable_partition.h>
#include <cuda/std/__algorithm/swap_ranges.h>
#include <cuda/std/__algorithm/transform.h>
#include <cuda/std/__algorithm/unique.h>
#include <cuda/std/__algorithm/unique_copy.h>
#include <cuda/std/__algorithm/upper_bound.h>
#include <cuda/std/__iterator/distance.h>
#include <cuda/std/__iterator/iterator_traits.h>
#include <cuda/std/__iterator/move_iterator.h>
#include <cuda/std/__iterator/next.h>
#include <cuda/std/__iterator/prev.h>
#include <cuda/std/__iterator/reverse_iterator.h>
#include <cuda/std/__iterator/wrap_iter.h>
#include <cuda/std/__memory/destruct_n.h>
#include <cuda/std/__memory/temporary_buffer.h>
#include <cuda/std/__random/linear_congruential_engine.h>
#include <cuda/std/__random/uniform_int_distribution.h>
#include <cuda/std/__type_traits/common_type.h>
#include <cuda/std/__type_traits/enable_if.h>
#include <cuda/std/__type_traits/is_integral.h>
#include <cuda/std/__type_traits/is_same.h>
#include <cuda/std/__type_traits/is_trivially_copy_assignable.h>
#include <cuda/std/__type_traits/make_unsigned.h>
#include <cuda/std/__type_traits/remove_const.h>
#include <cuda/std/bit>
#include <cuda/std/climits>
#include <cuda/std/cstddef>
#include <cuda/std/functional>
#include <cuda/std/initializer_list>
#include <cuda/std/type_traits>
#include <cuda/std/version>

#include <cuda/std/__cccl/prologue.h>

_LIBCUDACXX_BEGIN_NAMESPACE_STD

#ifndef __cuda_std__

template <class _Predicate>
class __invert // invert the sense of a comparison
{
private:
  _Predicate __p_;

public:
  _CCCL_API inline __invert() {}

  _CCCL_API inline explicit __invert(_Predicate __p)
      : __p_(__p)
  {}

  template <class _T1>
  _CCCL_API inline bool operator()(const _T1& __x)
  {
    return !__p_(__x);
  }

  template <class _T1, class _T2>
  _CCCL_API inline bool operator()(const _T1& __x, const _T2& __y)
  {
    return __p_(__y, __x);
  }
};

// inplace_merge

template <class _Compare, class _InputIterator1, class _InputIterator2, class _OutputIterator>
_CCCL_HOST_DEVICE void __half_inplace_merge(
  _InputIterator1 __first1,
  _InputIterator1 __last1,
  _InputIterator2 __first2,
  _InputIterator2 __last2,
  _OutputIterator __result,
  _Compare __comp)
{
  for (; __first1 != __last1; ++__result)
  {
    if (__first2 == __last2)
    {
      _CUDA_VSTD::move(__first1, __last1, __result);
      return;
    }

    if (__comp(*__first2, *__first1))
    {
      *__result = _CUDA_VSTD::move(*__first2);
      ++__first2;
    }
    else
    {
      *__result = _CUDA_VSTD::move(*__first1);
      ++__first1;
    }
  }
  // __first2 through __last2 are already in the right spot.
}

template <class _Compare, class _BidirectionalIterator>
_CCCL_HOST_DEVICE void __buffered_inplace_merge(
  _BidirectionalIterator __first,
  _BidirectionalIterator __middle,
  _BidirectionalIterator __last,
  _Compare __comp,
  typename iterator_traits<_BidirectionalIterator>::difference_type __len1,
  typename iterator_traits<_BidirectionalIterator>::difference_type __len2,
  typename iterator_traits<_BidirectionalIterator>::value_type* __buff)
{
  typedef typename iterator_traits<_BidirectionalIterator>::value_type value_type;
  __destruct_n __d(0);
  unique_ptr<value_type, __destruct_n&> __h2(__buff, __d);
  if (__len1 <= __len2)
  {
    value_type* __p = __buff;
    for (_BidirectionalIterator __i = __first; __i != __middle; __d.__incr((value_type*) 0), (void) ++__i, (void) ++__p)
    {
      ::new (__p) value_type(_CUDA_VSTD::move(*__i));
    }
    __half_inplace_merge(__buff, __p, __middle, __last, __first, __comp);
  }
  else
  {
    value_type* __p = __buff;
    for (_BidirectionalIterator __i = __middle; __i != __last; __d.__incr((value_type*) 0), (void) ++__i, (void) ++__p)
    {
      ::new (__p) value_type(_CUDA_VSTD::move(*__i));
    }
    typedef reverse_iterator<_BidirectionalIterator> _RBi;
    typedef reverse_iterator<value_type*> _Rv;
    __half_inplace_merge(_Rv(__p), _Rv(__buff), _RBi(__middle), _RBi(__first), _RBi(__last), __invert<_Compare>(__comp));
  }
}

template <class _Compare, class _BidirectionalIterator>
_CCCL_HOST_DEVICE void __inplace_merge(
  _BidirectionalIterator __first,
  _BidirectionalIterator __middle,
  _BidirectionalIterator __last,
  _Compare __comp,
  typename iterator_traits<_BidirectionalIterator>::difference_type __len1,
  typename iterator_traits<_BidirectionalIterator>::difference_type __len2,
  typename iterator_traits<_BidirectionalIterator>::value_type* __buff,
  ptrdiff_t __buff_size)
{
  typedef typename iterator_traits<_BidirectionalIterator>::difference_type difference_type;
  while (true)
  {
    // if __middle == __last, we're done
    if (__len2 == 0)
    {
      return;
    }
    if (__len1 <= __buff_size || __len2 <= __buff_size)
    {
      return __buffered_inplace_merge<_Compare>(__first, __middle, __last, __comp, __len1, __len2, __buff);
    }
    // shrink [__first, __middle) as much as possible (with no moves), returning if it shrinks to 0
    for (; true; ++__first, (void) --__len1)
    {
      if (__len1 == 0)
      {
        return;
      }
      if (__comp(*__middle, *__first))
      {
        break;
      }
    }
    // __first < __middle < __last
    // *__first > *__middle
    // partition [__first, __m1) [__m1, __middle) [__middle, __m2) [__m2, __last) such that
    //     all elements in:
    //         [__first, __m1)  <= [__middle, __m2)
    //         [__middle, __m2) <  [__m1, __middle)
    //         [__m1, __middle) <= [__m2, __last)
    //     and __m1 or __m2 is in the middle of its range
    _BidirectionalIterator __m1; // "median" of [__first, __middle)
    _BidirectionalIterator __m2; // "median" of [__middle, __last)
    difference_type __len11; // distance(__first, __m1)
    difference_type __len21; // distance(__middle, __m2)
    // binary search smaller range
    if (__len1 < __len2)
    { // __len >= 1, __len2 >= 2
      __len21 = __len2 / 2;
      __m2    = __middle;
      _CUDA_VSTD::advance(__m2, __len21);
      __m1    = __upper_bound<_Compare>(__first, __middle, *__m2, __comp);
      __len11 = _CUDA_VSTD::distance(__first, __m1);
    }
    else
    {
      if (__len1 == 1)
      { // __len1 >= __len2 && __len2 > 0, therefore __len2 == 1
        // It is known *__first > *__middle
        swap(*__first, *__middle);
        return;
      }
      // __len1 >= 2, __len2 >= 1
      __len11 = __len1 / 2;
      __m1    = __first;
      _CUDA_VSTD::advance(__m1, __len11);
      __m2    = __lower_bound<_Compare>(__middle, __last, *__m1, __comp);
      __len21 = _CUDA_VSTD::distance(__middle, __m2);
    }
    difference_type __len12 = __len1 - __len11; // distance(__m1, __middle)
    difference_type __len22 = __len2 - __len21; // distance(__m2, __last)
    // [__first, __m1) [__m1, __middle) [__middle, __m2) [__m2, __last)
    // swap middle two partitions
    __middle = _CUDA_VSTD::rotate(__m1, __middle, __m2);
    // __len12 and __len21 now have swapped meanings
    // merge smaller range with recursive call and larger with tail recursion elimination
    if (__len11 + __len21 < __len12 + __len22)
    {
      __inplace_merge<_Compare>(__first, __m1, __middle, __comp, __len11, __len21, __buff, __buff_size);
      //          __inplace_merge<_Compare>(__middle, __m2, __last, __comp, __len12, __len22, __buff, __buff_size);
      __first  = __middle;
      __middle = __m2;
      __len1   = __len12;
      __len2   = __len22;
    }
    else
    {
      __inplace_merge<_Compare>(__middle, __m2, __last, __comp, __len12, __len22, __buff, __buff_size);
      //          __inplace_merge<_Compare>(__first, __m1, __middle, __comp, __len11, __len21, __buff, __buff_size);
      __last   = __middle;
      __middle = __m1;
      __len1   = __len11;
      __len2   = __len21;
    }
  }
}

template <class _BidirectionalIterator, class _Compare>
_CCCL_API inline void inplace_merge(
  _BidirectionalIterator __first, _BidirectionalIterator __middle, _BidirectionalIterator __last, _Compare __comp)
{
  typedef typename iterator_traits<_BidirectionalIterator>::value_type value_type;
  typedef typename iterator_traits<_BidirectionalIterator>::difference_type difference_type;
  difference_type __len1             = _CUDA_VSTD::distance(__first, __middle);
  difference_type __len2             = _CUDA_VSTD::distance(__middle, __last);
  difference_type __buf_size         = _CUDA_VSTD::min(__len1, __len2);
  pair<value_type*, ptrdiff_t> __buf = _CUDA_VSTD::get_temporary_buffer<value_type>(__buf_size);
  unique_ptr<value_type, __return_temporary_buffer> __h(__buf.first);
  using _Comp_ref = __comp_ref_type<_Compare>;
  return _CUDA_VSTD::__inplace_merge<_Comp_ref>(
    __first, __middle, __last, __comp, __len1, __len2, __buf.first, __buf.second);
}

template <class _BidirectionalIterator>
_CCCL_API inline void
inplace_merge(_BidirectionalIterator __first, _BidirectionalIterator __middle, _BidirectionalIterator __last)
{
  _CUDA_VSTD::inplace_merge(__first, __middle, __last, __less{});
}

// stable_sort

template <class _Compare, class _InputIterator1, class _InputIterator2>
_CCCL_HOST_DEVICE void __merge_move_construct(
  _InputIterator1 __first1,
  _InputIterator1 __last1,
  _InputIterator2 __first2,
  _InputIterator2 __last2,
  typename iterator_traits<_InputIterator1>::value_type* __result,
  _Compare __comp)
{
  typedef typename iterator_traits<_InputIterator1>::value_type value_type;
  __destruct_n __d(0);
  unique_ptr<value_type, __destruct_n&> __h(__result, __d);
  for (; true; ++__result)
  {
    if (__first1 == __last1)
    {
      for (; __first2 != __last2; ++__first2, ++__result, (void) __d.__incr((value_type*) 0))
      {
        ::new (__result) value_type(_CUDA_VSTD::move(*__first2));
      }
      __h.release();
      return;
    }
    if (__first2 == __last2)
    {
      for (; __first1 != __last1; ++__first1, ++__result, (void) __d.__incr((value_type*) 0))
      {
        ::new (__result) value_type(_CUDA_VSTD::move(*__first1));
      }
      __h.release();
      return;
    }
    if (__comp(*__first2, *__first1))
    {
      ::new (__result) value_type(_CUDA_VSTD::move(*__first2));
      __d.__incr((value_type*) 0);
      ++__first2;
    }
    else
    {
      ::new (__result) value_type(_CUDA_VSTD::move(*__first1));
      __d.__incr((value_type*) 0);
      ++__first1;
    }
  }
}

template <class _Compare, class _InputIterator1, class _InputIterator2, class _OutputIterator>
_CCCL_HOST_DEVICE void __merge_move_assign(
  _InputIterator1 __first1,
  _InputIterator1 __last1,
  _InputIterator2 __first2,
  _InputIterator2 __last2,
  _OutputIterator __result,
  _Compare __comp)
{
  for (; __first1 != __last1; ++__result)
  {
    if (__first2 == __last2)
    {
      for (; __first1 != __last1; ++__first1, (void) ++__result)
      {
        *__result = _CUDA_VSTD::move(*__first1);
      }
      return;
    }
    if (__comp(*__first2, *__first1))
    {
      *__result = _CUDA_VSTD::move(*__first2);
      ++__first2;
    }
    else
    {
      *__result = _CUDA_VSTD::move(*__first1);
      ++__first1;
    }
  }
  for (; __first2 != __last2; ++__first2, (void) ++__result)
  {
    *__result = _CUDA_VSTD::move(*__first2);
  }
}

template <class _Compare, class _RandomAccessIterator>
_CCCL_HOST_DEVICE void __stable_sort(
  _RandomAccessIterator __first,
  _RandomAccessIterator __last,
  _Compare __comp,
  typename iterator_traits<_RandomAccessIterator>::difference_type __len,
  typename iterator_traits<_RandomAccessIterator>::value_type* __buff,
  ptrdiff_t __buff_size);

template <class _Compare, class _RandomAccessIterator>
_CCCL_HOST_DEVICE void __stable_sort_move(
  _RandomAccessIterator __first1,
  _RandomAccessIterator __last1,
  _Compare __comp,
  typename iterator_traits<_RandomAccessIterator>::difference_type __len,
  typename iterator_traits<_RandomAccessIterator>::value_type* __first2)
{
  typedef typename iterator_traits<_RandomAccessIterator>::value_type value_type;
  switch (__len)
  {
    case 0:
      return;
    case 1:
      ::new (__first2) value_type(_CUDA_VSTD::move(*__first1));
      return;
    case 2:
      __destruct_n __d(0);
      unique_ptr<value_type, __destruct_n&> __h2(__first2, __d);
      if (__comp(*--__last1, *__first1))
      {
        ::new (__first2) value_type(_CUDA_VSTD::move(*__last1));
        __d.__incr((value_type*) 0);
        ++__first2;
        ::new (__first2) value_type(_CUDA_VSTD::move(*__first1));
      }
      else
      {
        ::new (__first2) value_type(_CUDA_VSTD::move(*__first1));
        __d.__incr((value_type*) 0);
        ++__first2;
        ::new (__first2) value_type(_CUDA_VSTD::move(*__last1));
      }
      __h2.release();
      return;
  }
  if (__len <= 8)
  {
    __insertion_sort_move<_Compare>(__first1, __last1, __first2, __comp);
    return;
  }
  typename iterator_traits<_RandomAccessIterator>::difference_type __l2 = __len / 2;
  _RandomAccessIterator __m                                             = __first1 + __l2;
  __stable_sort<_Compare>(__first1, __m, __comp, __l2, __first2, __l2);
  __stable_sort<_Compare>(__m, __last1, __comp, __len - __l2, __first2 + __l2, __len - __l2);
  __merge_move_construct<_Compare>(__first1, __m, __m, __last1, __first2, __comp);
}

template <class _Tp>
struct __stable_sort_switch
{
  static const unsigned value = 128 * is_trivially_copy_assignable<_Tp>::value;
};

template <class _Compare, class _RandomAccessIterator>
_CCCL_HOST_DEVICE void __stable_sort(
  _RandomAccessIterator __first,
  _RandomAccessIterator __last,
  _Compare __comp,
  typename iterator_traits<_RandomAccessIterator>::difference_type __len,
  typename iterator_traits<_RandomAccessIterator>::value_type* __buff,
  ptrdiff_t __buff_size)
{
  typedef typename iterator_traits<_RandomAccessIterator>::value_type value_type;
  typedef typename iterator_traits<_RandomAccessIterator>::difference_type difference_type;
  switch (__len)
  {
    case 0:
    case 1:
      return;
    case 2:
      if (__comp(*--__last, *__first))
      {
        swap(*__first, *__last);
      }
      return;
  }
  if (__len <= static_cast<difference_type>(__stable_sort_switch<value_type>::value))
  {
    __insertion_sort<_Compare>(__first, __last, __comp);
    return;
  }
  typename iterator_traits<_RandomAccessIterator>::difference_type __l2 = __len / 2;
  _RandomAccessIterator __m                                             = __first + __l2;
  if (__len <= __buff_size)
  {
    __destruct_n __d(0);
    unique_ptr<value_type, __destruct_n&> __h2(__buff, __d);
    __stable_sort_move<_Compare>(__first, __m, __comp, __l2, __buff);
    __d.__set(__l2, (value_type*) 0);
    __stable_sort_move<_Compare>(__m, __last, __comp, __len - __l2, __buff + __l2);
    __d.__set(__len, (value_type*) 0);
    __merge_move_assign<_Compare>(__buff, __buff + __l2, __buff + __l2, __buff + __len, __first, __comp);
    //         __merge<_Compare>(move_iterator<value_type*>(__buff),
    //                           move_iterator<value_type*>(__buff + __l2),
    //                           move_iterator<_RandomAccessIterator>(__buff + __l2),
    //                           move_iterator<_RandomAccessIterator>(__buff + __len),
    //                           __first, __comp);
    return;
  }
  __stable_sort<_Compare>(__first, __m, __comp, __l2, __buff, __buff_size);
  __stable_sort<_Compare>(__m, __last, __comp, __len - __l2, __buff, __buff_size);
  __inplace_merge<_Compare>(__first, __m, __last, __comp, __l2, __len - __l2, __buff, __buff_size);
}

template <class _RandomAccessIterator, class _Compare>
_CCCL_API inline void stable_sort(_RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp)
{
  typedef typename iterator_traits<_RandomAccessIterator>::value_type value_type;
  typedef typename iterator_traits<_RandomAccessIterator>::difference_type difference_type;
  difference_type __len = __last - __first;
  pair<value_type*, ptrdiff_t> __buf(0, 0);
  unique_ptr<value_type, __return_temporary_buffer> __h;
  if (__len > static_cast<difference_type>(__stable_sort_switch<value_type>::value))
  {
    __buf = _CUDA_VSTD::get_temporary_buffer<value_type>(__len);
    __h.reset(__buf.first);
  }
  using _Comp_ref = __comp_ref_type<_Compare>;
  __stable_sort<_Comp_ref>(__first, __last, __comp, __len, __buf.first, __buf.second);
}

template <class _RandomAccessIterator>
_CCCL_API inline void stable_sort(_RandomAccessIterator __first, _RandomAccessIterator __last)
{
  _CUDA_VSTD::stable_sort(__first, __last, __less{});
}

// nth_element

template <class _Compare, class _RandomAccessIterator>
_CCCL_HOST_DEVICE void
__nth_element(_RandomAccessIterator __first, _RandomAccessIterator __nth, _RandomAccessIterator __last, _Compare __comp)
{
  // _Compare is known to be a reference type
  typedef typename iterator_traits<_RandomAccessIterator>::difference_type difference_type;
  const difference_type __limit = 7;
  while (true)
  {
  __restart:
    if (__nth == __last)
    {
      return;
    }
    difference_type __len = __last - __first;
    switch (__len)
    {
      case 0:
      case 1:
        return;
      case 2:
        if (__comp(*--__last, *__first))
        {
          swap(*__first, *__last);
        }
        return;
      case 3: {
        _RandomAccessIterator __m = __first;
        _CUDA_VSTD::__sort3<_Compare>(__first, ++__m, --__last, __comp);
        return;
      }
    }
    if (__len <= __limit)
    {
      __selection_sort<_Compare>(__first, __last, __comp);
      return;
    }
    // __len > __limit >= 3
    _RandomAccessIterator __m   = __first + __len / 2;
    _RandomAccessIterator __lm1 = __last;
    unsigned __n_swaps          = _CUDA_VSTD::__sort3<_Compare>(__first, __m, --__lm1, __comp);
    // *__m is median
    // partition [__first, __m) < *__m and *__m <= [__m, __last)
    // (this inhibits tossing elements equivalent to __m around unnecessarily)
    _RandomAccessIterator __i = __first;
    _RandomAccessIterator __j = __lm1;
    // j points beyond range to be tested, *__lm1 is known to be <= *__m
    // The search going up is known to be guarded but the search coming down isn't.
    // Prime the downward search with a guard.
    if (!__comp(*__i, *__m)) // if *__first == *__m
    {
      // *__first == *__m, *__first doesn't go in first part
      // manually guard downward moving __j against __i
      while (true)
      {
        if (__i == --__j)
        {
          // *__first == *__m, *__m <= all other elements
          // Partition instead into [__first, __i) == *__first and *__first < [__i, __last)
          ++__i; // __first + 1
          __j = __last;
          if (!__comp(*__first, *--__j)) // we need a guard if *__first == *(__last-1)
          {
            while (true)
            {
              if (__i == __j)
              {
                return; // [__first, __last) all equivalent elements
              }
              if (__comp(*__first, *__i))
              {
                swap(*__i, *__j);
                ++__n_swaps;
                ++__i;
                break;
              }
              ++__i;
            }
          }
          // [__first, __i) == *__first and *__first < [__j, __last) and __j == __last - 1
          if (__i == __j)
          {
            return;
          }
          while (true)
          {
            while (!__comp(*__first, *__i))
            {
              ++__i;
            }
            while (__comp(*__first, *--__j))
              ;
            if (__i >= __j)
            {
              break;
            }
            swap(*__i, *__j);
            ++__n_swaps;
            ++__i;
          }
          // [__first, __i) == *__first and *__first < [__i, __last)
          // The first part is sorted,
          if (__nth < __i)
          {
            return;
          }
          // __nth_element the second part
          // __nth_element<_Compare>(__i, __nth, __last, __comp);
          __first = __i;
          goto __restart;
        }
        if (__comp(*__j, *__m))
        {
          swap(*__i, *__j);
          ++__n_swaps;
          break; // found guard for downward moving __j, now use unguarded partition
        }
      }
    }
    ++__i;
    // j points beyond range to be tested, *__lm1 is known to be <= *__m
    // if not yet partitioned...
    if (__i < __j)
    {
      // known that *(__i - 1) < *__m
      while (true)
      {
        // __m still guards upward moving __i
        while (__comp(*__i, *__m))
        {
          ++__i;
        }
        // It is now known that a guard exists for downward moving __j
        while (!__comp(*--__j, *__m))
          ;
        if (__i >= __j)
        {
          break;
        }
        swap(*__i, *__j);
        ++__n_swaps;
        // It is known that __m != __j
        // If __m just moved, follow it
        if (__m == __i)
        {
          __m = __j;
        }
        ++__i;
      }
    }
    // [__first, __i) < *__m and *__m <= [__i, __last)
    if (__i != __m && __comp(*__m, *__i))
    {
      swap(*__i, *__m);
      ++__n_swaps;
    }
    // [__first, __i) < *__i and *__i <= [__i+1, __last)
    if (__nth == __i)
    {
      return;
    }
    if (__n_swaps == 0)
    {
      // We were given a perfectly partitioned sequence.  Coincidence?
      if (__nth < __i)
      {
        // Check for [__first, __i) already sorted
        __j = __m = __first;
        while (++__j != __i)
        {
          if (__comp(*__j, *__m))
          {
            // not yet sorted, so sort
            goto not_sorted;
          }
          __m = __j;
        }
        // [__first, __i) sorted
        return;
      }
      else
      {
        // Check for [__i, __last) already sorted
        __j = __m = __i;
        while (++__j != __last)
        {
          if (__comp(*__j, *__m))
          {
            // not yet sorted, so sort
            goto not_sorted;
          }
          __m = __j;
        }
        // [__i, __last) sorted
        return;
      }
    }
  not_sorted:
    // __nth_element on range containing __nth
    if (__nth < __i)
    {
      // __nth_element<_Compare>(__first, __nth, __i, __comp);
      __last = __i;
    }
    else
    {
      // __nth_element<_Compare>(__i+1, __nth, __last, __comp);
      __first = ++__i;
    }
  }
}

template <class _RandomAccessIterator, class _Compare>
_CCCL_API inline void
nth_element(_RandomAccessIterator __first, _RandomAccessIterator __nth, _RandomAccessIterator __last, _Compare __comp)
{
  using _Comp_ref = __comp_ref_type<_Compare>;
  __nth_element<_Comp_ref>(__first, __nth, __last, __comp);
}

template <class _RandomAccessIterator>
_CCCL_API inline void
nth_element(_RandomAccessIterator __first, _RandomAccessIterator __nth, _RandomAccessIterator __last)
{
  _CUDA_VSTD::nth_element(__first, __nth, __last, __less{});
}

#endif
_LIBCUDACXX_END_NAMESPACE_STD

#if defined(_LIBCUDACXX_HAS_PARALLEL_ALGORITHMS) && _CCCL_STD_VER >= 2017
#  include <__pstl_algorithm>
#endif

#include <cuda/std/__cccl/epilogue.h>

#endif // _LIBCUDACXX_ALGORITHM
